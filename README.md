<img src="assets/churnbot_icon.png" align="right" width="96">

# Project ChurnBot â€” Interpretable Customer Decision Intelligence
> *Proving that you can have your cake (performance) and eat it too (interpretability).*

**Current Application:** Predicting term deposit subscriptions using glass-box ML

*Predict, prevent, and proactively respond to customer behavior with a research-backed AI assistant*

**Tech Stack:**
<img src="https://cdn.simpleicons.org/sqlite/003B57" alt="SQLite" width="24"/> SQLite,Â 
<img src="https://cdn.simpleicons.org/jupyter/F37626" alt="Jupyter" width="24"/> Jupyter,Â 
<img src="https://cdn.simpleicons.org/python/3776AB" alt="Python" width="24"/> Python,Â 
<img src="https://cdn.simpleicons.org/pytorch/EE4C2C" alt="PyTorch" width="24"/> PyTorch,Â 
<img src="https://cdn.simpleicons.org/cplusplus/00599C" alt="C++" width="24"/> C++,Â 
<img src="https://cdn.simpleicons.org/typescript/3178C6" alt="TypeScript" width="24"/> TypeScript,Â 
<img src="https://cdn.simpleicons.org/docker/2496ED" alt="Docker" width="24"/> Docker,Â 
<img src="https://cdn.simpleicons.org/react/61DAFB" alt="React" width="24"/> React,Â 
<img src="https://cdn.simpleicons.org/nodedotjs/5FA04E" alt="Node.js" width="24"/> Node.js

**Author:** ğŸ‘¤ Phillip Harris

---
> âš ï¸ **Research Status & Dataset Transition Notice**
>
> This project is under active research and architectural refinement.
> While the core glass-box cascade methodology is now established,
> the current focus has shifted from architectural prototyping to
> rigorous application and validation on real-world data.
>
> Notable updates:
> - The system previously transitioned from the synthetic Telco churn dataset
>   (used for early architectural validation) to a real-world bank marketing
>   subscription dataset to improve external validity.
> - During deeper causal and leakage auditing of the bank marketing dataset,
>   multiple structural issues were identified that materially limit its suitability
>   for realistic deployment-oriented modeling:
>     - **`duration` encodes post-outcome information and constitutes direct label leakage.**
>     - **`poutcome` contains outcome-derived information from prior campaigns and behaves as a semi-leaky proxy.**
>     - **`pdays` strongly correlates with `poutcome` and acts as a numeric surrogate for the same leakage signal.**
>     - Approximately **82% of samples collapse into a single â€œunknownâ€ regime**, severely limiting meaningful
>       behavioral segmentation once leaky features are removed.
>     - Removing these features produces a large and irreversible performance drop, indicating that much of the
>       datasetâ€™s apparent predictive power is driven by post-event artifacts rather than causal drivers.
> - As a result, the project is **actively migrating to a new real-world subscriber / churn dataset that satisfies
>   strict data integrity, leakage, and interpretability requirements.**
> - **Notably, these issues were first surfaced by the system itself via the interpretable rule lattice.**  
>   Following removal of `duration`, rule generation became dominated by `poutcome_success` rules exhibiting
>   high precision but extremely low coverage â€” a signature of shortcut or proxy leakage rather than meaningful
>   behavioral structure. This anomaly triggered deeper causal inspection of `poutcome` and `pdays`, leading to
>   confirmation of proxy leakage and regime collapse.
> - The **core glass-box cascade architecture remains unchanged** and will be revalidated on the new dataset.
> - Performance metrics, feature attributions, and examples in this README will be updated once the next dataset
>   passes full audit and validation.
> - Earlier experimental components (e.g., RNN-based stages) remain in the repository for historical reference
>   but are not part of the canonical pipeline.
>
> **Current research objective:**  
> Develop and validate a fully interpretable, abstention-aware glass-box cascade for
> real-world customer decision modeling using rigorously audited, leakage-free data.

ğŸ“Š Leakage & Regime Collapse Diagnostics
<p align="center"> <img src="assets/pdays_vs_previous.png" width="32%"> <img src="assets/boxplot.png" width="32%"> <img src="assets/job_by_poutcome_conversion.png" width="32%"> </p>

Figure â€” Structural leakage and regime collapse in the bank marketing dataset.
(Left) pdays is tightly coupled with previous, indicating that recency largely encodes prior contact history rather than independent behavioral signal.
(Center) The dominant poutcome=unknown regime collapses near zero pdays, while non-unknown regimes exhibit wide separation â€” demonstrating that pdays acts as a numeric surrogate for campaign outcome state.
(Right) Conversion rates sharply diverge only when conditioning on known poutcome, while the dominant unknown regime exhibits weak and compressed signal across job segments â€” confirming proxy leakage and loss of meaningful segmentation once leaky features are removed.

---
## ğŸ“– Synopsis
Project ChurnBot is a research-driven, glass-box decision intelligence system for customer behavior prediction using fully interpretable cascade architectures. Instead of treating customer decisions as a single black-box prediction task, the system decomposes decision-making into explicit, interpretable stages that capture linear effects, interaction-driven rules, and non-linear response curves.

The cascade serves as the core reasoning engine, producing abstention-aware, fully explainable predictions. A lightweight NLP interface enables natural-language interaction with model outputs and explanations, while remaining optional to the core system.

The result is a transparent, high-performance ensemble where every decision can be traced to human-readable logicâ€”enabling trustworthy deployment without sacrificing predictive power.

![Dataset Overview](assets/dataset_overview.png)
*Dataset visualization from early Telco churn experiments; current bank marketing 
dataset analysis forthcoming.*

---
## ğŸš¨ Problem: The Interpretabilityâ€“Performance Trade-off Myth

The ML industry perpetuates a harmful misconception: **â€œYou must sacrifice accuracy for interpretability.â€**  
However, this trade-off is **not inherent**.

This belief leads to:
- Black-box models deployed in high-stakes retention settings where transparency is critical
- Business teams unable to understand or trust model decisions
- Missed opportunities for actionable retention strategies
- Increased regulatory and compliance risk in customer intervention policies

**Current Industry Practice**: Deploy XGBoost or neural networks and rely on post-hoc explanation methods (e.g., SHAP, LIME) that approximateâ€”rather than revealâ€”the underlying decision logic.

**Our Solution**: A fully interpretable glass-box cascade that can **compete with or outperform** traditional black-box approaches while providing complete transparency. Every prediction is grounded in explicit rules, linear coefficients, and additive shape functions, enabling **faithful, exact explanations** rather than approximations.

---
## ğŸ¯ Architecture: 100% Glass Box Four-Stage Cascade
```
Stage 1: Logistic Regression (Linear Signals)
  â†“ Captures global linear trends via interpretable coefficients

Stage 2: Sequential GLASS-BRW  
        (Gated Logistic Abstention Structured System â€” Best Rules Win)
  â†“ Routing-first, depth-aware rule lattice
  â†“ Explicitly isolates high false-negative risk regions
  â†“ Pass 1 routes risky samples forward; abstains on confident non-subscriber regions
  â†“ Pass 2 predicts SUBSCRIBE only when confident; otherwise abstains

Stage 3: Explainable Boosting Machine (EBM)
  â†“ Models non-linear effects via additive, interpretable shape functions
  â†“ Resolves uncertainty in routed or abstained samples

Stage 4: Meta-EBM (Abstention-Aware Decision Arbiter)
  â†“ Evaluates and arbitrates predictions from LR, GLASS-BRW, and EBM
  â†“ Selects the most reliable interpretable decision based on confidence and agreement
  â†“ Optionally abstains when no stage is sufficiently certain
  â†“ Emits a final decision (or abstention) signal to downstream consumers (e.g., NLP interface) 
  â†“ Explicitly communicates uncertainty rather than forcing a prediction

Customer-Level Predictions with End-to-End Explainability
```

### Key Innovation: Every Stage is Interpretable

- **Logistic Regression**: Direct coefficient inspection 
- **Sequential GLASS-BRW**: Explicit IFâ€“THEN rules with abstention and routing
- **EBM**: Additive shape functions exposing non-linear relationships in the data
- **Meta-EBM**: Interpretable weighting of stage outputs, revealing how and when each model is trusted

---

## ğŸ§  Core Thesis: Glass Boxes Can Outperform Black Boxes

**Research Hypothesis**: Carefully designed glass-box ensemble architectures can match or exceed black-box performance while preserving full interpretability; especially in structured decision domains such as customer retention and subscription modeling.

### Supporting Observations

- **Competitive performance** observed in prior experimental evaluations relative to black-box baselines
- **High stability** across validation splits due to deterministic routing and abstention mechanisms
- **Complete interpretability**: all predictions are decomposable into coefficients, explicit rules, and additive shape functions
- **Operational value**: transparent decision logic enables trust, auditability, and actionable intervention strategies

This work argues that the perceived **accuracyâ€“interpretability trade-off** is an architectural choice, not a fundamental limitation in structured decision-making domains.

---

## ğŸ—£ï¸ User Interface: NLP-Driven Interaction

Project ChurnBot features a natural language processing interface that streamlines user interaction. Users can input queries in plain language, and ChurnBot:

1. **Collects and preprocesses** user input  
2. **Routes the request** to the relevant model(s) with full glass box transparency
3. **Interprets model predictions** and provides actionable results with explicit reasoning

This allows analysts and executives to interact with complex ML pipelines effortlessly, turning raw predictions into meaningful insights with complete explainability.

---

## ğŸ¯ Choose Your Experience

âš¡ **Terminal Version (Light)**: For business analysts and technical teams â€” fast, efficient insights through command-line interaction with full rule/coefficient visibility.

ğŸ“ˆ **Dashboard Version (Heavy)**: For executives and decision-makers â€” rich visualizations of shape functions, rule networks, and model weights for executive-ready presentations.

Both versions maintain 100% interpretability and transparency. All computations run locally, keeping sensitive customer data on your network as opposed to a 3rd-party cloud.

---

## ğŸ”’ Privacy & Security: Local-First Philosophy

ChurnBot runs entirely on your machine with zero cloud dependencies:

âœ… No external data transfers â€” sensitive customer data never leaves your network  
âœ… No monthly fees or API costs  
âœ… Full data sovereignty â€” maintain compliance and avoid regulatory penalties  
âœ… Immediate analysis â€” no network latency or downtime  
âœ… Complete interpretability â€” every prediction fully explainable for audit trails

Compare this to black-box cloud APIs with inherent data exposure risks and unexplainable predictions.

---

### ğŸ’¼ Real-World Impact

**Business ROI**:
- ğŸ“‰ Reduce customer acquisition costs through precise sample targeting 
- ğŸ“ˆ Improve executive decision-making with actionable insights 
- ğŸ›¡ï¸ Maintain full data sovereignty â†’ avoid compliance penalties
- ğŸ’° Eliminate cloud API costs and subscription fees
- ğŸ¯ Reduce false positives leading to more focused marketing spend

**Security & Compliance ROI**:
- ğŸ”’ Complete data privacy â€” no external data exposure
- ğŸ“‹ Regulatory compliance through complete audit trail (every prediction can be traced)
- ğŸ¢ Enterprise-grade security through local execution
- ğŸ“Š Explainable AI for high-stakes decisions (GDPR, fair lending compliance)

---

## ğŸ¯ Current Research Focus

- âœ… Full glass box architecture achieved
- âœ… Rule extraction from Random Forest 
- âœ… EBM integration for non-linear patterns
- âœ… Meta-EBM for interpretable ensemble weighting
- ğŸ”„ Cross-dataset validation (telecom, SaaS, retail)
- ğŸ”„ Interactive visualization tools
- ğŸ”„ Research paper preparation

---

## âš ï¸ Limitations

- Dataset variability imposes generalization challenges
- Rule consolidation requires domain expertise for threshold tuning
- Glass box conversion adds one-time computational overhead
- Shape function interpretability requires statistical literacy

---

## ğŸ“š Dataset Sources & Citations

### **1) Bank Marketing â€“ Term Deposit Subscription (Current Benchmark)**

This project uses the **Bank Marketing** dataset for primary empirical evaluation.
The dataset is publicly available for research use via the UCI Machine Learning Repository.

**Dataset Source:**  
Moro, S., Rita, P., & Cortez, P. (2014).  
*Bank Marketing Dataset.*  
UCI Machine Learning Repository.  
DOI: https://doi.org/10.24432/C5K306

**Required Citation (Academic):**  
Moro, S., Laureano, R., & Cortez, P. (2011).  
*Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology.*  
In P. Novais et al. (Eds.), *Proceedings of the European Simulation and Modelling Conference â€“ ESMâ€™2011*,  
pp. 117â€“121, GuimarÃ£es, Portugal. EUROSIS.

Available at:  
- PDF: http://hdl.handle.net/1822/14838  
- BibTeX: http://www3.dsi.uminho.pt/pcortez/bib/2011-esm-1.txt

**Public Access:**  
- UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/bank+marketing

---

### **2) IBM Telco Customer Churn Dataset (Exploratory / Feasibility)**

The IBM Telco Customer Churn dataset was used during early experimentation to validate
the feasibility of the glass-box cascade architecture. Results derived from this dataset
should be interpreted as **architectural validation**, not final performance claims.

Originally published by IBM as part of the **IBM Analytics Accelerator Catalog**.

**Original Source (IBM):**  
https://www.ibm.com/communities/analytics/watson-analytics-blog/guide-to-customer-churn-dataset/

**Public Mirrors:**  
- Kaggle: https://www.kaggle.com/datasets/blastchar/telco-customer-churn  
- OpenML: https://www.openml.org/d/42178

## ğŸ“‚ Project Structure
```
prototype/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”‚   â””â”€â”€ test_splits/
â”œâ”€â”€ churn_pipeline/   # TODO: extract churn model interface into interfaces/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py            âœ…
â”‚   â”œâ”€â”€ preprocessor.py           âœ…
â”‚   â”œâ”€â”€ feature_engineer.py       # Optimizing
â”‚   â”œâ”€â”€ leakage_monitor.py        âœ…
â”‚   â”œâ”€â”€ cascade_model.py          âœ…
â”‚   â”œâ”€â”€ cascade_model_cpp_wrapper.py âœ…
â”‚   â””â”€â”€ experiment_runner.py      âœ…
â”œâ”€â”€ chatbot_pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ user_input_handler.py          # TODO: implement input parsing and validation
â”‚   â”œâ”€â”€ query_processor.py             # TODO: implement query formatting for each model
â”‚   â”œâ”€â”€ churn_prediction_interface.py  # TODO: connect to Churn model pipeline interface
â”‚   â”œâ”€â”€ security_model_interface.py    # TODO: connect to Security pipeline interface
â”‚   â”œâ”€â”€ it_model_interface.py          # TODO: connect to IT pipeline interface
â”‚   â””â”€â”€ response_generator.py          # TODO: implement response formatting and templates
â”œâ”€â”€ security_pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ threat_data_loader.py          # TODO: implement security data loading
â”‚   â”œâ”€â”€ threat_preprocessor.py         # TODO: implement cleaning and preprocessing
â”‚   â”œâ”€â”€ feature_engineer.py            # TODO: implement security-specific feature extraction
â”‚   â”œâ”€â”€ anomaly_detector.py            # TODO: implement anomaly detection model
â”‚   â”œâ”€â”€ security_model_cpp_wrapper.py  # TODO: implement C++ security model wrapper
â”‚   â””â”€â”€ experiment_runner.py           # TODO: implement experimentation framework
â”œâ”€â”€ it_pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ it_data_loader.py              # TODO: implement IT data loading
â”‚   â”œâ”€â”€ it_preprocessor.py             # TODO: implement IT data cleaning and preprocessing
â”‚   â”œâ”€â”€ feature_engineer.py            # TODO: implement IT-specific feature engineering
â”‚   â”œâ”€â”€ predictive_model.py            # TODO: implement predictive model for IT metrics/outages
â”‚   â”œâ”€â”€ it_model_cpp_wrapper.py        # TODO: implement C++ IT model wrapper
â”‚   â””â”€â”€ experiment_runner.py           # TODO: implement experimentation framework
â”œâ”€â”€ interfaces/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ churn_model_interface.py       # TODO: place extract churn model interface here
â”‚   â”œâ”€â”€ security_model_interface.py    # TODO: define standard methods like train(), predict(), evaluate()
â”‚   â”œâ”€â”€ it_model_interface.py          # TODO: define standard methods like train(), predict(), evaluate()
â”‚   â””â”€â”€ cpp_model_interface.py         # TODO: define standard C++ model interface
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ utils.py                       # TODO: add additional shared utility functions
â”‚   â””â”€â”€ cpp_utils.py                   # TODO: add C++ integration utilities
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ churn_pipeline_lab.ipynb       # TODO: Clean up
â”‚   â”œâ”€â”€ chatbot_pipeline_lab.ipynb     # TODO: set up lab for multi-model chatbot experimentation
â”‚   â”œâ”€â”€ security_pipeline_lab.ipynb    # TODO: set up lab for security experimentation
â”‚   â”œâ”€â”€ it_pipeline_lab.ipynb          # TODO: set up lab for IT experimentation
â”‚   â””â”€â”€ cpp_benchmarking_lab.ipynb     # TODO: create C++ vs Python benchmarking notebook
â”œâ”€â”€ cpp_models/                        # NEW: C++ optimized models directory
â”‚   â”œâ”€â”€ shared_cpp/                    # NEW: Common C++ optimizations
â”‚   â”‚   â”œâ”€â”€ include/
â”‚   â”‚   â”‚   â”œâ”€â”€ optimization_utils.h    # TODO: implement branch & bound, early termination
â”‚   â”‚   â”‚   â”œâ”€â”€ data_structures.h       # TODO: implement cache-friendly containers
â”‚   â”‚   â”‚   â”œâ”€â”€ memory_manager.h        # TODO: implement custom allocators
â”‚   â”‚   â”‚   â””â”€â”€ common_types.h          # TODO: define common data types
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ optimization_utils.cpp  # TODO: implement CS theory optimizations
â”‚   â”‚       â”œâ”€â”€ data_structures.cpp     # TODO: implement optimized data layouts
â”‚   â”‚       â””â”€â”€ memory_manager.cpp      # TODO: implement memory management
â”‚   â”œâ”€â”€ churn_pipeline_cpp/            # NEW: Churn C++ models
â”‚   â”‚   â”œâ”€â”€ include/
â”‚   â”‚   â”‚   â”œâ”€â”€ churn_cascade.h         âœ…
â”‚   â”‚   â”‚   â”œâ”€â”€ random_forest.h         # Building
â”‚   â”‚   â”‚   â”œâ”€â”€ neural_network.h        # Building
â”‚   â”‚   â”‚   â”œâ”€â”€ recurrent_network.h     âœ…
â”‚   â”‚   â”‚   â””â”€â”€ telecom_features.h      # Building
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ churn_cascade.cpp       # Building/Opitmizing
â”‚   â”‚   â”‚   â”œâ”€â”€ random_forest.cpp       # Building/Opitmizing
â”‚   â”‚   â”‚   â”œâ”€â”€ neural_network.cpp      # Building/Opitmizing
â”‚   â”‚   â”‚   â”œâ”€â”€ recurrent_network.cpp   # Building/Opitmizing
â”‚   â”‚   â”‚   â””â”€â”€ telecom_features.cpp    # Building
â”‚   â”‚   â”œâ”€â”€ bindings/
â”‚   â”‚   â”‚   â”œâ”€â”€ python_bindings.cpp     âœ…
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py             âœ…
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_rf.cpp             # TODO: implement unit tests for RF
â”‚   â”‚   â”‚   â”œâ”€â”€ test_ann.cpp            # TODO: implement unit tests for ANN
â”‚   â”‚   â”‚   â””â”€â”€ test_cascade.cpp        # TODO: implement integration tests
â”‚   â”‚   â””â”€â”€ CMakeLists.txt              # TODO: set up build configuration
â”‚   â”œâ”€â”€ security_pipeline_cpp/         # NEW: Security C++ models
â”‚   â”‚   â”œâ”€â”€ include/
â”‚   â”‚   â”‚   â”œâ”€â”€ security_cascade.h      # TODO: implement security model interface
â”‚   â”‚   â”‚   â”œâ”€â”€ anomaly_detector.h      # TODO: implement anomaly detection algorithms
â”‚   â”‚   â”‚   â”œâ”€â”€ bot_detector.h          # TODO: implement bot detection models
â”‚   â”‚   â”‚   â””â”€â”€ threat_classifier.h     # TODO: implement threat classification
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ security_cascade.cpp    # TODO: implement security pipeline orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ anomaly_detector.cpp    # TODO: implement real-time anomaly detection
â”‚   â”‚   â”‚   â”œâ”€â”€ bot_detector.cpp        # TODO: implement bot detection algorithms
â”‚   â”‚   â”‚   â””â”€â”€ threat_classifier.cpp   # TODO: implement threat classification
â”‚   â”‚   â”œâ”€â”€ bindings/
â”‚   â”‚   â”‚   â”œâ”€â”€ python_bindings.cpp     # TODO: implement pybind11 security interface
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py             # TODO: set up security Python module
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_anomaly.cpp        # TODO: implement anomaly detection tests
â”‚   â”‚   â”‚   â””â”€â”€ test_bot_detection.cpp  # TODO: implement bot detection tests
â”‚   â”‚   â””â”€â”€ CMakeLists.txt              # TODO: set up security build configuration
â”‚   â”œâ”€â”€ it_pipeline_cpp/               # NEW: IT C++ models
â”‚   â”‚   â”œâ”€â”€ include/
â”‚   â”‚   â”‚   â”œâ”€â”€ it_cascade.h            # TODO: implement IT model interface
â”‚   â”‚   â”‚   â”œâ”€â”€ outage_predictor.h      # TODO: implement outage prediction
â”‚   â”‚   â”‚   â”œâ”€â”€ performance_monitor.h   # TODO: implement performance monitoring
â”‚   â”‚   â”‚   â””â”€â”€ servicenow_interface.h  # TODO: implement ServiceNow integration
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ it_cascade.cpp          # TODO: implement IT pipeline orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ outage_predictor.cpp    # TODO: implement predictive maintenance
â”‚   â”‚   â”‚   â”œâ”€â”€ performance_monitor.cpp # TODO: implement system performance analysis
â”‚   â”‚   â”‚   â””â”€â”€ servicenow_interface.cpp # TODO: implement ServiceNow API integration
â”‚   â”‚   â”œâ”€â”€ bindings/
â”‚   â”‚   â”‚   â”œâ”€â”€ python_bindings.cpp     # TODO: implement pybind11 IT interface
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py             # TODO: set up IT Python module
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_outage_prediction.cpp # TODO: implement outage prediction tests
â”‚   â”‚   â”‚   â””â”€â”€ test_performance.cpp    # TODO: implement performance monitoring tests
â”‚   â”‚   â””â”€â”€ CMakeLists.txt              # TODO: set up IT build configuration
â”‚   â”œâ”€â”€ benchmarks/                    # NEW: Performance benchmarking
â”‚   â”‚   â”œâ”€â”€ churn_benchmark.cpp         # TODO: implement churn model benchmarking
â”‚   â”‚   â”œâ”€â”€ security_benchmark.cpp      # TODO: implement security model benchmarking
â”‚   â”‚   â”œâ”€â”€ it_benchmark.cpp            # TODO: implement IT model benchmarking
â”‚   â”‚   â”œâ”€â”€ memory_profiling.cpp        # TODO: implement memory usage profiling
â”‚   â”‚   â””â”€â”€ compare_all_pipelines.cpp   # TODO: implement comprehensive benchmarking
â”‚   â”œâ”€â”€ scripts/                       # NEW: Build and deployment scripts
â”‚   â”‚   â”œâ”€â”€ build_all.sh               # TODO: create master build script
â”‚   â”‚   â”œâ”€â”€ install_dependencies.sh    # TODO: create dependency installation script
â”‚   â”‚   â”œâ”€â”€ run_benchmarks.sh          # TODO: create benchmark execution script
â”‚   â”‚   â””â”€â”€ generate_bindings.sh       # TODO: create Python binding generation script
â”‚   â””â”€â”€ CMakeLists.txt                 âœ…
â”œâ”€â”€ BasePipeline.py                    # TODO: implement base class for pipelines
â””â”€â”€ README.md
```

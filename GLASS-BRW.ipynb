{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 1: IMPORTS\n",
        "# ============================================================\n",
        "\n",
        "# ============================================================\n",
        "# CORE NUMERICAL & DATA HANDLING\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ============================================================\n",
        "# STATISTICAL TESTING\n",
        "# ============================================================\n",
        "from scipy import stats\n",
        "\n",
        "# ============================================================\n",
        "# SKLEARN: MODEL SELECTION & VALIDATION\n",
        "# ============================================================\n",
        "from sklearn.model_selection import (\n",
        "    StratifiedKFold,\n",
        "    train_test_split\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# SKLEARN: MODELS\n",
        "# ============================================================\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ============================================================\n",
        "# SKLEARN: METRICS & FEATURE IMPORTANCE\n",
        "# ============================================================\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    mutual_info_score\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# ============================================================\n",
        "# GRADIENT BOOSTING\n",
        "# ============================================================\n",
        "import xgboost as xgb\n",
        "\n",
        "# ============================================================\n",
        "# RULE / ILP / STRUCTURAL UTILITIES\n",
        "# ============================================================\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple, Set\n",
        "\n",
        "# ============================================================\n",
        "# WARNINGS CONTROL\n",
        "# ============================================================\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "oo4pU9X9q8J1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "bLBZJTatN2gp",
        "outputId": "85d6d72b-7d03-4db9-afc8-f14ff38b853d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (45211, 17)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age           job  marital  education default  balance housing loan  \\\n",
              "0   58    management  married   tertiary      no     2143     yes   no   \n",
              "1   44    technician   single  secondary      no       29     yes   no   \n",
              "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
              "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
              "4   33       unknown   single    unknown      no        1      no   no   \n",
              "\n",
              "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
              "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
              "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
              "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
              "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
              "4  unknown    5   may       198         1     -1         0  unknown  no  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-205be30e-f064-48e6-b427-1ff6c446210b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>2143</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>technician</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>29</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1506</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>unknown</td>\n",
              "      <td>single</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-205be30e-f064-48e6-b427-1ff6c446210b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-205be30e-f064-48e6-b427-1ff6c446210b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-205be30e-f064-48e6-b427-1ff6c446210b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25258060-600b-464b-a188-2030df872510\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25258060-600b-464b-a188-2030df872510')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25258060-600b-464b-a188-2030df872510 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 45211,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 18,\n        \"max\": 95,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          35,\n          34,\n          53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"housemaid\",\n          \"unemployed\",\n          \"management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"married\",\n          \"single\",\n          \"divorced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"secondary\",\n          \"primary\",\n          \"tertiary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"default\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3044,\n        \"min\": -8019,\n        \"max\": 102127,\n        \"num_unique_values\": 7168,\n        \"samples\": [\n          3276,\n          43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"unknown\",\n          \"cellular\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 31,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          1,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"apr\",\n          \"mar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 0,\n        \"max\": 4918,\n        \"num_unique_values\": 1573,\n        \"samples\": [\n          835,\n          1135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"campaign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 63,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          41,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdays\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100,\n        \"min\": -1,\n        \"max\": 871,\n        \"num_unique_values\": 559,\n        \"samples\": [\n          249,\n          551\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"previous\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 275,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          17,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"poutcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"failure\",\n          \"success\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 2: LOAD & INSPECT DATA\n",
        "# ============================================================\n",
        "\n",
        "# Load dataset\n",
        "path = \"/content/sample_data/bank-full.csv\"\n",
        "df = pd.read_csv(path, sep=\";\")\n",
        "\n",
        "print(f\"Shape: {df.shape}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "DGSbAegdQMQu",
        "outputId": "6973dda6-f4a8-4cf1-85ff-d0e85bf9c3be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Œ COLUMN SCHEMA\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              column   dtype  n_unique\n",
              "age              age   int64        77\n",
              "job              job  object        12\n",
              "marital      marital  object         3\n",
              "education  education  object         4\n",
              "default      default  object         2\n",
              "balance      balance   int64      7168\n",
              "housing      housing  object         2\n",
              "loan            loan  object         2\n",
              "contact      contact  object         3\n",
              "day              day   int64        31\n",
              "month          month  object        12\n",
              "duration    duration   int64      1573\n",
              "campaign    campaign   int64        48\n",
              "pdays          pdays   int64       559\n",
              "previous    previous   int64        41\n",
              "poutcome    poutcome  object         4\n",
              "y                  y  object         2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63d87045-ec4a-47fd-a3b6-c9e3dc593da1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column</th>\n",
              "      <th>dtype</th>\n",
              "      <th>n_unique</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>age</td>\n",
              "      <td>int64</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job</th>\n",
              "      <td>job</td>\n",
              "      <td>object</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marital</th>\n",
              "      <td>marital</td>\n",
              "      <td>object</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education</th>\n",
              "      <td>education</td>\n",
              "      <td>object</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>default</th>\n",
              "      <td>default</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>balance</th>\n",
              "      <td>balance</td>\n",
              "      <td>int64</td>\n",
              "      <td>7168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing</th>\n",
              "      <td>housing</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loan</th>\n",
              "      <td>loan</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contact</th>\n",
              "      <td>contact</td>\n",
              "      <td>object</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day</th>\n",
              "      <td>day</td>\n",
              "      <td>int64</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>month</td>\n",
              "      <td>object</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>duration</td>\n",
              "      <td>int64</td>\n",
              "      <td>1573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>campaign</th>\n",
              "      <td>campaign</td>\n",
              "      <td>int64</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pdays</th>\n",
              "      <td>pdays</td>\n",
              "      <td>int64</td>\n",
              "      <td>559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>previous</th>\n",
              "      <td>previous</td>\n",
              "      <td>int64</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poutcome</th>\n",
              "      <td>poutcome</td>\n",
              "      <td>object</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y</th>\n",
              "      <td>y</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63d87045-ec4a-47fd-a3b6-c9e3dc593da1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63d87045-ec4a-47fd-a3b6-c9e3dc593da1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63d87045-ec4a-47fd-a3b6-c9e3dc593da1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b590a61b-5733-4758-8f6f-8580a8bd16b6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b590a61b-5733-4758-8f6f-8580a8bd16b6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b590a61b-5733-4758-8f6f-8580a8bd16b6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_21c2b983-4412-4fa0-bfcf-d3f7038a0643\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('schema')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_21c2b983-4412-4fa0-bfcf-d3f7038a0643 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('schema');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "schema",
              "summary": "{\n  \"name\": \"schema\",\n  \"rows\": 17,\n  \"fields\": [\n    {\n      \"column\": \"column\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"age\",\n          \"job\",\n          \"balance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dtype\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"object\",\n          \"int64\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_unique\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1746,\n        \"min\": 2,\n        \"max\": 7168,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          7168,\n          77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 3: CHECK INPUT TYPES\n",
        "# ============================================================\n",
        "print(\"ðŸ“Œ COLUMN SCHEMA\\n\" + \"-\"*60)\n",
        "schema = pd.DataFrame({\n",
        "    \"column\": df.columns,\n",
        "    \"dtype\": df.dtypes.astype(str),\n",
        "    \"n_unique\": [df[c].nunique() for c in df.columns]\n",
        "})\n",
        "schema\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrzcXIdZQbuH",
        "outputId": "632393f0-bb70-43a6-a5c2-bfd3a66277a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Œ CATEGORICAL COLUMNS\n",
            "------------------------------------------------------------\n",
            "\n",
            "ðŸ”Ž Column: job\n",
            "----------------------------------------\n",
            "job\n",
            "admin.           5171\n",
            "blue-collar      9732\n",
            "entrepreneur     1487\n",
            "housemaid        1240\n",
            "management       9458\n",
            "retired          2264\n",
            "self-employed    1579\n",
            "services         4154\n",
            "student           938\n",
            "technician       7597\n",
            "unemployed       1303\n",
            "unknown           288\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: marital\n",
            "----------------------------------------\n",
            "marital\n",
            "divorced     5207\n",
            "married     27214\n",
            "single      12790\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: education\n",
            "----------------------------------------\n",
            "education\n",
            "primary       6851\n",
            "secondary    23202\n",
            "tertiary     13301\n",
            "unknown       1857\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: default\n",
            "----------------------------------------\n",
            "default\n",
            "no     44396\n",
            "yes      815\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: housing\n",
            "----------------------------------------\n",
            "housing\n",
            "no     20081\n",
            "yes    25130\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: loan\n",
            "----------------------------------------\n",
            "loan\n",
            "no     37967\n",
            "yes     7244\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: contact\n",
            "----------------------------------------\n",
            "contact\n",
            "cellular     29285\n",
            "telephone     2906\n",
            "unknown      13020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: month\n",
            "----------------------------------------\n",
            "month\n",
            "apr     2932\n",
            "aug     6247\n",
            "dec      214\n",
            "feb     2649\n",
            "jan     1403\n",
            "jul     6895\n",
            "jun     5341\n",
            "mar      477\n",
            "may    13766\n",
            "nov     3970\n",
            "oct      738\n",
            "sep      579\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: poutcome\n",
            "----------------------------------------\n",
            "poutcome\n",
            "failure     4901\n",
            "other       1840\n",
            "success     1511\n",
            "unknown    36959\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: y\n",
            "----------------------------------------\n",
            "y\n",
            "no     39922\n",
            "yes     5289\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 5: EXAMINE CATAGORICAL COLUMNS\n",
        "# ============================================================\n",
        "categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "print(\"ðŸ“Œ CATEGORICAL COLUMNS\\n\" + \"-\"*60)\n",
        "categorical_cols\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nðŸ”Ž Column: {col}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    values = (\n",
        "        df[col]\n",
        "        .astype(str)\n",
        "        .value_counts(dropna=False)\n",
        "        .sort_index()\n",
        "    )\n",
        "\n",
        "    print(values)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 6: PREPROCESSING - CONTACT AS ORDINAL\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ”§ CLEAN PREPROCESSING FROM SCRATCH (NUMERIC-ONLY)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nOriginal data shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. CREATE CLEAN df_proc FRAME\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"1. CREATING CLEAN df_proc\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "df_proc = df.copy()\n",
        "\n",
        "print(f\"\\nInitial shape: {df_proc.shape}\")\n",
        "print(f\"Columns: {list(df_proc.columns)}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.1 Target encoding (STRICT)\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ” Target column 'y' before conversion:\")\n",
        "print(df_proc['y'].value_counts())\n",
        "\n",
        "df_proc['y'] = df_proc['y'].map({'yes': 1, 'no': 0})\n",
        "assert df_proc['y'].notna().all(), \"âŒ Unexpected values in target y\"\n",
        "df_proc['y'] = df_proc['y'].astype('int8')\n",
        "\n",
        "print(f\"\\nâœ… Target 'y' converted:\")\n",
        "print(df_proc['y'].value_counts())\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.2 Binary categorical encoding\n",
        "# --------------------------------------------------\n",
        "binary_cols = ['default', 'housing', 'loan']\n",
        "binary_map = {'no': 0, 'yes': 1}\n",
        "\n",
        "print(f\"\\nðŸ” Binary columns before conversion:\")\n",
        "for col in binary_cols:\n",
        "    print(f\"{col}:\\n{df_proc[col].value_counts()}\")\n",
        "\n",
        "for col in binary_cols:\n",
        "    df_proc[col] = df_proc[col].map(binary_map)\n",
        "    assert df_proc[col].notna().all(), f\"âŒ Unexpected values in {col}\"\n",
        "    df_proc[col] = df_proc[col].astype('int8')\n",
        "\n",
        "print(f\"\\nâœ… Binary columns converted:\")\n",
        "for col in binary_cols:\n",
        "    print(f\"{col}: {df_proc[col].unique()}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.3 Month â†’ ordinal (DROP RAW MONTH)\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ” Month column before conversion:\")\n",
        "print(df_proc['month'].value_counts().sort_index())\n",
        "\n",
        "month_map = {\n",
        "    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4,\n",
        "    'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,\n",
        "    'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
        "}\n",
        "\n",
        "df_proc['month_ordinal'] = df_proc['month'].map(month_map)\n",
        "assert df_proc['month_ordinal'].notna().all(), \"âŒ Unexpected month values\"\n",
        "df_proc['month_ordinal'] = df_proc['month_ordinal'].astype('int8')\n",
        "\n",
        "# DROP raw month (no objects allowed)\n",
        "df_proc.drop(columns=['month'], inplace=True)\n",
        "\n",
        "print(f\"\\nâœ… Month converted to ordinal and raw month dropped\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.4 POUTCOME - EXPLICIT MAPPING\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ” poutcome column before conversion:\")\n",
        "print(df_proc['poutcome'].value_counts())\n",
        "\n",
        "poutcome_map = {\n",
        "    'unknown': 0,\n",
        "    'failure': 1,\n",
        "    'other': 2,\n",
        "    'success': 3\n",
        "}\n",
        "\n",
        "df_proc['poutcome'] = df_proc['poutcome'].map(poutcome_map)\n",
        "assert df_proc['poutcome'].notna().all(), \"âŒ Unexpected poutcome values\"\n",
        "df_proc['poutcome'] = df_proc['poutcome'].astype('int8')\n",
        "\n",
        "print(f\"\\nâœ… poutcome converted:\")\n",
        "print(df_proc['poutcome'].value_counts())\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.5 CONTACT - ORDINAL MAPPING (NOT BINARY)\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ” contact column before conversion:\")\n",
        "print(df_proc['contact'].value_counts())\n",
        "\n",
        "# Map contact as ORDINAL: cellular=0, telephone=1, unknown=2\n",
        "contact_map = {\n",
        "    'cellular': 0,\n",
        "    'telephone': 1,\n",
        "    'unknown': 2\n",
        "}\n",
        "\n",
        "df_proc['contact'] = df_proc['contact'].map(contact_map)\n",
        "assert df_proc['contact'].notna().all(), \"âŒ Unexpected contact values\"\n",
        "df_proc['contact'] = df_proc['contact'].astype('int8')\n",
        "\n",
        "print(f\"\\nâœ… contact converted to ordinal (0=cellular, 1=telephone, 2=unknown):\")\n",
        "print(df_proc['contact'].value_counts().sort_index())\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.6 Ordinal / Label encoding REMAINING categoricals\n",
        "# --------------------------------------------------\n",
        "categorical_cols = df_proc.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f\"\\nðŸ” Ordinal-encoding remaining categoricals:\")\n",
        "print(categorical_cols)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df_proc[col] = df_proc[col].astype('category').cat.codes\n",
        "    df_proc[col] = df_proc[col].astype('int16')\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.7 HARD TYPE GUARANTEE\n",
        "# --------------------------------------------------\n",
        "non_numeric = df_proc.select_dtypes(exclude=['number']).columns.tolist()\n",
        "assert len(non_numeric) == 0, f\"âŒ NON-NUMERIC COLUMNS REMAIN: {non_numeric}\"\n",
        "\n",
        "print(\"\\nâœ… ALL COLUMNS ARE NUMERIC\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.8 Sanity checks\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ“Š Data types in df_proc:\")\n",
        "for dtype in df_proc.dtypes.unique():\n",
        "    cols = df_proc.columns[df_proc.dtypes == dtype].tolist()\n",
        "    print(f\"{dtype}: {cols}\")\n",
        "\n",
        "print(f\"\\nðŸ” Checking for null values:\")\n",
        "assert df_proc.isnull().sum().sum() == 0, \"âŒ Nulls detected\"\n",
        "print(\"âœ… No null values\")\n",
        "\n",
        "print(f\"\\nðŸ” Checking for duplicates:\")\n",
        "dup_count = df_proc.duplicated().sum()\n",
        "print(f\"Exact duplicate rows: {dup_count} ({dup_count/len(df_proc)*100:.2f}%)\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.9 Final confirmation\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nâœ… df_proc created successfully!\")\n",
        "print(f\"Shape: {df_proc.shape}\")\n",
        "print(f\"Memory usage: {df_proc.memory_usage().sum() / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8aO7-YIolhl",
        "outputId": "62722f1b-7b5c-4c7e-830d-e4f99b3e5590"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸ”§ CLEAN PREPROCESSING FROM SCRATCH (NUMERIC-ONLY)\n",
            "================================================================================\n",
            "\n",
            "Original data shape: (45211, 17)\n",
            "Columns: ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
            "\n",
            "========================================\n",
            "1. CREATING CLEAN df_proc\n",
            "========================================\n",
            "\n",
            "Initial shape: (45211, 17)\n",
            "Columns: ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
            "\n",
            "ðŸ” Target column 'y' before conversion:\n",
            "y\n",
            "no     39922\n",
            "yes     5289\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… Target 'y' converted:\n",
            "y\n",
            "0    39922\n",
            "1     5289\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ” Binary columns before conversion:\n",
            "default:\n",
            "default\n",
            "no     44396\n",
            "yes      815\n",
            "Name: count, dtype: int64\n",
            "housing:\n",
            "housing\n",
            "yes    25130\n",
            "no     20081\n",
            "Name: count, dtype: int64\n",
            "loan:\n",
            "loan\n",
            "no     37967\n",
            "yes     7244\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… Binary columns converted:\n",
            "default: [0 1]\n",
            "housing: [1 0]\n",
            "loan: [0 1]\n",
            "\n",
            "ðŸ” Month column before conversion:\n",
            "month\n",
            "apr     2932\n",
            "aug     6247\n",
            "dec      214\n",
            "feb     2649\n",
            "jan     1403\n",
            "jul     6895\n",
            "jun     5341\n",
            "mar      477\n",
            "may    13766\n",
            "nov     3970\n",
            "oct      738\n",
            "sep      579\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… Month converted to ordinal and raw month dropped\n",
            "\n",
            "ðŸ” poutcome column before conversion:\n",
            "poutcome\n",
            "unknown    36959\n",
            "failure     4901\n",
            "other       1840\n",
            "success     1511\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… poutcome converted:\n",
            "poutcome\n",
            "0    36959\n",
            "1     4901\n",
            "2     1840\n",
            "3     1511\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ” contact column before conversion:\n",
            "contact\n",
            "cellular     29285\n",
            "unknown      13020\n",
            "telephone     2906\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… contact converted to ordinal (0=cellular, 1=telephone, 2=unknown):\n",
            "contact\n",
            "0    29285\n",
            "1     2906\n",
            "2    13020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ” Ordinal-encoding remaining categoricals:\n",
            "['job', 'marital', 'education']\n",
            "\n",
            "âœ… ALL COLUMNS ARE NUMERIC\n",
            "\n",
            "ðŸ“Š Data types in df_proc:\n",
            "int64: ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
            "int16: ['job', 'marital', 'education']\n",
            "int8: ['default', 'housing', 'loan', 'contact', 'poutcome', 'y', 'month_ordinal']\n",
            "\n",
            "ðŸ” Checking for null values:\n",
            "âœ… No null values\n",
            "\n",
            "ðŸ” Checking for duplicates:\n",
            "Exact duplicate rows: 0 (0.00%)\n",
            "\n",
            "âœ… df_proc created successfully!\n",
            "Shape: (45211, 17)\n",
            "Memory usage: 2.98 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IMPORTANT NOTE ON DATA DISTRIBUTION & OUTLIERS:\n",
        "\n",
        "We deliberately do NOT scale or alter the natural distributions of the data at this stage.\n",
        "This includes not removing outliers, not applying normalization, and not transforming variables.\n",
        "\n",
        "RATIONALE:\n",
        "1. The observed skewness and extreme values represent real-world customer behavior where\n",
        "   outliers often encode meaningful business signals rather than noise.\n",
        "\n",
        "2. Overlapping spikes and distribution discontinuities may reflect:\n",
        "   - Behavioral threshold effects (e.g., call duration regimes)\n",
        "   - Temporal or seasonal campaign dynamics\n",
        "   - Distinct customer segments with non-linear response patterns\n",
        "\n",
        "3. Our feature engineering strategy (state-based binning and thresholds) is designed to\n",
        "   capture these effects explicitly while preserving semantic interpretability.\n",
        "\n",
        "4. The GLASS-BRW framework relies on discovering natural decision boundaries from data,\n",
        "   rather than imposing artificial smoothness through scaling or normalization.\n",
        "\n",
        "MODEL-SPECIFIC NOTE:\n",
        "This choice is intentional for rule-based, threshold-driven models.\n",
        "Scaling and outlier handling may be revisited for distance-based or linear models,\n",
        "but are avoided here to preserve interpretability and behavioral signal fidelity.\n",
        "\n",
        "NEXT STEPS:\n",
        "- Evaluate whether specific extreme values degrade rule stability\n",
        "- Apply targeted transformations only if they improve interpretability or robustness\n",
        "- Continue prioritizing temporal and behavioral signal discovery over distribution smoothing\n",
        "\n",
        "This approach reflects business reality, where extreme values often identify the most\n",
        "valuable, risky, or responsive customer segments.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "R-rZFfZJtMt_",
        "outputId": "ab2de359-1db1-453b-c95a-d4fc6b8107e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIMPORTANT NOTE ON DATA DISTRIBUTION & OUTLIERS:\\n\\nWe deliberately do NOT scale or alter the natural distributions of the data at this stage.\\nThis includes not removing outliers, not applying normalization, and not transforming variables.\\n\\nRATIONALE:\\n1. The observed skewness and extreme values represent real-world customer behavior where\\n   outliers often encode meaningful business signals rather than noise.\\n\\n2. Overlapping spikes and distribution discontinuities may reflect:\\n   - Behavioral threshold effects (e.g., call duration regimes)\\n   - Temporal or seasonal campaign dynamics\\n   - Distinct customer segments with non-linear response patterns\\n\\n3. Our feature engineering strategy (state-based binning and thresholds) is designed to\\n   capture these effects explicitly while preserving semantic interpretability.\\n\\n4. The GLASS-BRW framework relies on discovering natural decision boundaries from data,\\n   rather than imposing artificial smoothness through scaling or normalization.\\n\\nMODEL-SPECIFIC NOTE:\\nThis choice is intentional for rule-based, threshold-driven models.\\nScaling and outlier handling may be revisited for distance-based or linear models,\\nbut are avoided here to preserve interpretability and behavioral signal fidelity.\\n\\nNEXT STEPS:\\n- Evaluate whether specific extreme values degrade rule stability\\n- Apply targeted transformations only if they improve interpretability or robustness\\n- Continue prioritizing temporal and behavioral signal discovery over distribution smoothing\\n\\nThis approach reflects business reality, where extreme values often identify the most\\nvaluable, risky, or responsive customer segments.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gpu3NigHVD3J"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 11: GLASS-BRW STATE-BASED FEATURE ENGINEERING\n",
        "# ============================================================\n",
        "\n",
        "def engineer_features_bank(df_proc: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    State-based feature engineering for GLASS-BRW.\n",
        "    INPUT  : df_proc (FULLY NUMERIC preprocessed frame)\n",
        "    OUTPUT : df_eng  (binary engineered features ONLY + target y)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"ðŸ” Engineering state-based features for GLASS-BRW...\")\n",
        "\n",
        "    df_eng = pd.DataFrame(index=df_proc.index)\n",
        "    df_eng[\"y\"] = df_proc[\"y\"].astype(np.int8)\n",
        "\n",
        "    # =========================================================\n",
        "    # TIER 1 â€” BEHAVIORAL\n",
        "    # =========================================================\n",
        "    duration = pd.to_numeric(df_proc[\"duration\"], errors=\"coerce\").fillna(0)\n",
        "    duration_bin = pd.cut(\n",
        "        duration,\n",
        "        bins=[-1, 60, 180, 360, 600, np.inf],\n",
        "        labels=[\"very_short\", \"short\", \"medium\", \"long\", \"very_long\"]\n",
        "    )\n",
        "    for label in [\"very_short\", \"short\", \"medium\", \"long\", \"very_long\"]:\n",
        "        df_eng[f\"duration_{label}\"] = (duration_bin == label).astype(np.int8)\n",
        "\n",
        "    campaign = pd.to_numeric(df_proc[\"campaign\"], errors=\"coerce\").fillna(1)\n",
        "    campaign = np.clip(campaign, 1, campaign.quantile(0.98))\n",
        "    df_eng[\"campaign_single\"]   = (campaign == 1).astype(np.int8)\n",
        "    df_eng[\"campaign_light\"]    = ((campaign >= 2) & (campaign <= 3)).astype(np.int8)\n",
        "    df_eng[\"campaign_moderate\"] = ((campaign >= 4) & (campaign <= 6)).astype(np.int8)\n",
        "    df_eng[\"campaign_heavy\"]    = (campaign > 6).astype(np.int8)\n",
        "\n",
        "    previous = pd.to_numeric(df_proc[\"previous\"], errors=\"coerce\").fillna(0)\n",
        "    df_eng[\"previous_first_time\"]   = (previous == 0).astype(np.int8)\n",
        "    df_eng[\"previous_light_repeat\"] = ((previous >= 1) & (previous <= 2)).astype(np.int8)\n",
        "    df_eng[\"previous_heavy_repeat\"] = (previous >= 3).astype(np.int8)\n",
        "\n",
        "    # poutcome: unknown=0, failure=1, other=2, success=3\n",
        "    poutcome = df_proc[\"poutcome\"].astype(np.int8)\n",
        "    df_eng[\"poutcome_success\"] = (poutcome == 3).astype(np.int8)\n",
        "    df_eng[\"poutcome_failure\"] = (poutcome == 1).astype(np.int8)\n",
        "    df_eng[\"poutcome_other\"]   = (poutcome == 2).astype(np.int8)\n",
        "    df_eng[\"poutcome_unknown\"] = (poutcome == 0).astype(np.int8)\n",
        "\n",
        "    # =========================================================\n",
        "    # TIER 2 â€” TEMPORAL / MEMORY\n",
        "    # =========================================================\n",
        "    m = df_proc[\"month_ordinal\"].astype(np.int8)\n",
        "    df_eng[\"month_spring_lift\"]      = m.isin([2, 3, 4]).astype(np.int8)\n",
        "    df_eng[\"month_fall_lift\"]        = m.isin([9, 10, 11]).astype(np.int8)\n",
        "    df_eng[\"month_december_special\"] = (m == 12).astype(np.int8)\n",
        "    df_eng[\"month_may_volatile\"]     = (m == 5).astype(np.int8)\n",
        "    df_eng[\"month_summer_dead\"]      = m.isin([6, 7, 8]).astype(np.int8)\n",
        "    df_eng[\"month_jan_low\"]          = (m == 1).astype(np.int8)\n",
        "\n",
        "    day = pd.to_numeric(df_proc[\"day\"], errors=\"coerce\").fillna(15)\n",
        "    df_eng[\"day_early\"] = (day <= 10).astype(np.int8)\n",
        "    df_eng[\"day_mid\"]   = ((day > 10) & (day <= 20)).astype(np.int8)\n",
        "    df_eng[\"day_late\"]  = (day > 20).astype(np.int8)\n",
        "\n",
        "    pdays = pd.to_numeric(df_proc[\"pdays\"], errors=\"coerce\").fillna(-1)\n",
        "    df_eng[\"pdays_never_contacted\"] = (pdays == -1).astype(np.int8)\n",
        "    df_eng[\"pdays_recent_contact\"]  = ((pdays >= 0) & (pdays <= 30)).astype(np.int8)\n",
        "    df_eng[\"pdays_mid_recency\"]     = ((pdays > 30) & (pdays <= 180)).astype(np.int8)\n",
        "    df_eng[\"pdays_stale_contact\"]   = (pdays > 180).astype(np.int8)\n",
        "\n",
        "    # =========================================================\n",
        "    # TIER 3 â€” CONTEXTUAL\n",
        "    # =========================================================\n",
        "    age = pd.to_numeric(df_proc[\"age\"], errors=\"coerce\").fillna(40)\n",
        "    df_eng[\"age_young\"]         = (age < 30).astype(np.int8)\n",
        "    df_eng[\"age_prime_working\"] = ((age >= 30) & (age <= 45)).astype(np.int8)\n",
        "    df_eng[\"age_mature_stable\"] = ((age > 45) & (age <= 60)).astype(np.int8)\n",
        "    df_eng[\"age_senior\"]        = (age > 60).astype(np.int8)\n",
        "\n",
        "    balance = pd.to_numeric(df_proc[\"balance\"], errors=\"coerce\").fillna(0)\n",
        "    balance = np.clip(balance, balance.quantile(0.01), balance.quantile(0.99))\n",
        "    df_eng[\"balance_zero_or_negative\"] = (balance <= 0).astype(np.int8)\n",
        "    df_eng[\"balance_low\"]              = ((balance > 0) & (balance <= 500)).astype(np.int8)\n",
        "    df_eng[\"balance_mid\"]              = ((balance > 500) & (balance <= 5000)).astype(np.int8)\n",
        "    df_eng[\"balance_high\"]             = (balance > 5000).astype(np.int8)\n",
        "\n",
        "    # So contact_not_cellular is just (contact == 1)\n",
        "    contact = df_proc[\"contact\"].astype(np.int8)\n",
        "    df_eng[\"contact_not_cellular\"] = (contact == 1).astype(np.int8)\n",
        "\n",
        "    # housing/loan/default already binary int8 in df_proc\n",
        "    for col in [\"housing\", \"loan\", \"default\"]:\n",
        "        df_eng[col] = df_proc[col].astype(np.int8)\n",
        "\n",
        "    # =========================================================\n",
        "    # TIER 4 â€” HIGH-PRECISION CONDITIONAL SUBSCRIBE FLAGS\n",
        "    # Based on empirical triple-condition analysis\n",
        "    # =========================================================\n",
        "\n",
        "    # Base condition: successful previous outcome\n",
        "    success = df_eng[\"poutcome_success\"] == 1\n",
        "\n",
        "    # Duration regimes identified as high-signal\n",
        "    dur_medium = df_eng[\"duration_medium\"] == 1\n",
        "    dur_long   = df_eng[\"duration_long\"] == 1\n",
        "\n",
        "    base_zone = success & (dur_medium | dur_long)\n",
        "\n",
        "    # ---- Conditional flags (all binary, interpretable) ----\n",
        "    df_eng[\"flag_success_medlong_housing\"] = (\n",
        "        base_zone & (df_eng[\"housing\"] == 1)\n",
        "    ).astype(np.int8)\n",
        "\n",
        "    df_eng[\"flag_success_medlong_job\"] = (\n",
        "        base_zone & (df_proc[\"job\"] >= 0)  # ordinal job bucket already encoded\n",
        "    ).astype(np.int8)\n",
        "\n",
        "    df_eng[\"flag_success_medlong_education\"] = (\n",
        "        base_zone & (df_proc[\"education\"] >= 0)\n",
        "    ).astype(np.int8)\n",
        "\n",
        "    df_eng[\"flag_success_medlong_marital\"] = (\n",
        "        base_zone & (df_proc[\"marital\"] >= 0)\n",
        "    ).astype(np.int8)\n",
        "\n",
        "    df_eng[\"flag_success_medlong_loan\"] = (\n",
        "        base_zone & (df_eng[\"loan\"] == 0)\n",
        "    ).astype(np.int8)\n",
        "\n",
        "    df_eng[\"flag_success_medlong_default\"] = (\n",
        "        base_zone & (df_eng[\"default\"] == 0)\n",
        "    ).astype(np.int8)\n",
        "\n",
        "    df_eng[\"flag_success_medlong_contact_not_cell\"] = (\n",
        "        base_zone & (df_eng[\"contact_not_cellular\"] == 1)\n",
        "    ).astype(np.int8)\n",
        "\n",
        "    df_eng[\"flag_success_medlong_month_late\"] = (\n",
        "        base_zone & df_eng[\"month_fall_lift\"]\n",
        "    ).astype(np.int8)\n",
        "\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # FINAL: verify binary-only\n",
        "    # --------------------------------------------------\n",
        "    non_binary = []\n",
        "    for col in df_eng.columns:\n",
        "        if col == \"y\":\n",
        "            continue\n",
        "        u = pd.unique(df_eng[col])\n",
        "        if not set(u).issubset({0, 1}):\n",
        "            non_binary.append((col, u))\n",
        "\n",
        "    if non_binary:\n",
        "        print(f\"âŒ Found non-binary features: {len(non_binary)}\")\n",
        "        for c, u in non_binary[:10]:\n",
        "            print(f\"   {c}: {u}\")\n",
        "    else:\n",
        "        print(\"âœ“ All engineered features are binary 0/1\")\n",
        "\n",
        "    print(f\"âœ… Engineered {df_eng.shape[1]-1} binary features (+ y)\")\n",
        "    return df_eng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LKaecaPhS6Ky"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 12: RULE DATA STRUCTURE\n",
        "# ============================================================\n",
        "\n",
        "@dataclass\n",
        "class Rule:\n",
        "\n",
        "    rule_id: int\n",
        "    segment: Set[Tuple[str, str]]\n",
        "    predicted_class: int  # 0 = NOT_SUBSCRIBE, 1 = SUBSCRIBE\n",
        "    complexity: int\n",
        "\n",
        "    # Metrics computed during validation\n",
        "    precision: float = 0.0\n",
        "    recall: float = 0.0\n",
        "    coverage: float = 0.0\n",
        "    stability: float = 0.0\n",
        "    interpretability: float = 0.0\n",
        "    boundary_ambiguity: float = 0.0\n",
        "    ebm_overlap: float = 0.0\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.rule_id, frozenset(self.segment), self.predicted_class))\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.rule_id == other.rule_id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FIXED SEGMENT BUILDER - NO STRING CONVERSION\n",
        "# ============================================================\n",
        "class BankSegmentBuilder:\n",
        "    # =========================================================\n",
        "    # TIER 1 â€” BEHAVIORAL (direct interaction / outcome signals)\n",
        "    # =========================================================\n",
        "    TIER1_BEHAVIORAL = [\n",
        "        \"duration_very_long\",\n",
        "        \"duration_short\",\n",
        "        \"duration_long\",\n",
        "        \"duration_medium\",\n",
        "        \"campaign_single\",\n",
        "        \"poutcome_success\",\n",
        "\n",
        "        # --- High-precision conditional behavioral flags ---\n",
        "        \"flag_success_medlong_housing\",\n",
        "        \"flag_success_medlong_loan\",\n",
        "        \"flag_success_medlong_default\",\n",
        "        \"flag_success_medlong_contact_not_cell\",\n",
        "    ]\n",
        "\n",
        "    # =========================================================\n",
        "    # TIER 2 â€” TEMPORAL / MEMORY (when & cadence effects)\n",
        "    # =========================================================\n",
        "    TIER2_TEMPORAL = [\n",
        "        \"month_summer_dead\",\n",
        "        \"month_spring_lift\",\n",
        "        \"month_may_volatile\",\n",
        "        \"day_late\",\n",
        "        \"day_mid\",\n",
        "\n",
        "        # --- Conditional temporal amplification ---\n",
        "        \"flag_success_medlong_month_late\",\n",
        "    ]\n",
        "\n",
        "    # =========================================================\n",
        "    # TIER 3 â€” CONTEXTUAL (demographic / financial context)\n",
        "    # =========================================================\n",
        "    TIER3_CONTEXTUAL = [\n",
        "        \"balance_mid\",\n",
        "        \"age_prime_working\",\n",
        "        \"age_senior\",\n",
        "        \"contact_not_cellular\",\n",
        "\n",
        "        # --- Conditional context flags ---\n",
        "        \"flag_success_medlong_job\",\n",
        "        \"flag_success_medlong_education\",\n",
        "        \"flag_success_medlong_marital\",\n",
        "    ]\n",
        "\n",
        "\n",
        "    def __init__(self, mode=\"strict\"):\n",
        "        self.mode = mode\n",
        "\n",
        "    def assign_segments(self, X):\n",
        "        X = X.drop(columns=[\"y_bin\"], errors=\"ignore\")\n",
        "\n",
        "        if self.mode == \"strict\":\n",
        "            cols = self.TIER1_BEHAVIORAL + self.TIER2_TEMPORAL\n",
        "        elif self.mode == \"standard\":\n",
        "            cols = self.TIER1_BEHAVIORAL + self.TIER2_TEMPORAL + self.TIER3_CONTEXTUAL\n",
        "        else:\n",
        "            cols = self.TIER1_BEHAVIORAL + self.TIER2_TEMPORAL + self.TIER3_CONTEXTUAL\n",
        "\n",
        "        # Filter to available columns\n",
        "        cols = [c for c in cols if c in X.columns]\n",
        "\n",
        "        missing_tier1 = [c for c in self.TIER1_BEHAVIORAL if c not in X.columns]\n",
        "        if len(missing_tier1) > len(self.TIER1_BEHAVIORAL) * 0.5:\n",
        "            raise ValueError(f\"Too many missing Tier 1 features: {missing_tier1}\")\n",
        "\n",
        "        # Just select the columns - they're already 0/1\n",
        "        segments = X[cols].copy()\n",
        "\n",
        "        # Validate binary\n",
        "        for col in segments.columns:\n",
        "            vals = set(segments[col].dropna().unique())\n",
        "            if not vals.issubset({0, 1}):\n",
        "                raise ValueError(f\"Non-binary feature: {col} -> {vals}\")\n",
        "\n",
        "        # Fill any NULLs with 0\n",
        "        segments = segments.fillna(0).astype(int)\n",
        "\n",
        "        return segments\n",
        "\n",
        "    def validate_rule_composition(self, segment):\n",
        "        feature_names = {feat.lower() for feat, _ in segment}\n",
        "        tier1_names = {f.lower() for f in self.TIER1_BEHAVIORAL}\n",
        "        has_tier1 = bool(feature_names & tier1_names)\n",
        "\n",
        "        if not has_tier1:\n",
        "            tier3_names = {f.lower() for f in self.TIER3_CONTEXTUAL}\n",
        "            only_tier3 = feature_names.issubset(tier3_names)\n",
        "            if only_tier3:\n",
        "                return False\n",
        "\n",
        "        return has_tier1 or len(feature_names & {f.lower() for f in self.TIER2_TEMPORAL}) > 0"
      ],
      "metadata": {
        "id": "P4uARn2v5KrR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 14: RULE GENERATOR - FIXED FOR 0/1 VALUES\n",
        "# ============================================================\n",
        "\n",
        "class RuleGenerator:\n",
        "    def __init__(self, min_support=6, max_complexity=3, min_complexity=1,\n",
        "                 mode=\"strict\", beam_width=300, min_precision_gain=0.0,\n",
        "                 min_seed_precision_subscribe=0.70, min_seed_precision_not_subscribe=0.75,\n",
        "                 min_recall_subscribe=0.05, min_recall_not_subscribe=0.25,\n",
        "                 tier1_prefixes=(\"duration\", \"poutcome\", \"day\",\n",
        "                                 \"age\", \"contact\", \"campaign\",\n",
        "                                 \"flag\", \"poutcome\", \"balance\")):\n",
        "        self.min_support = min_support\n",
        "        self.max_complexity = max_complexity\n",
        "        self.min_complexity = min_complexity\n",
        "        self.mode = mode\n",
        "        self.beam_width = beam_width\n",
        "        self.min_precision_gain = min_precision_gain\n",
        "        self.min_seed_precision_subscribe = min_seed_precision_subscribe\n",
        "        self.min_seed_precision_not_subscribe = min_seed_precision_not_subscribe\n",
        "        self.min_recall_subscribe = min_recall_subscribe\n",
        "        self.min_recall_not_subscribe = min_recall_not_subscribe\n",
        "        self.tier1_prefixes = tier1_prefixes\n",
        "\n",
        "    def _compute_rule_mask(self, segment, segments_df):\n",
        "        mask = pd.Series(True, index=segments_df.index)\n",
        "        for f, l in segment:\n",
        "            mask &= (segments_df[f] == l)\n",
        "        return mask\n",
        "\n",
        "    def _compute_precision(self, mask, y, cls):\n",
        "        if mask.sum() == 0:\n",
        "            return 0.0\n",
        "        return (y[mask] == cls).mean()\n",
        "\n",
        "    def _compute_recall(self, mask, y, cls):\n",
        "        total_class = (y == cls).sum()\n",
        "        if total_class == 0:\n",
        "            return 0.0\n",
        "        true_positives = ((y == cls) & mask).sum()\n",
        "        return true_positives / total_class\n",
        "\n",
        "    def _has_tier1_feature(self, segment):\n",
        "        feats = {f for f, _ in segment}\n",
        "        return any(any(f.startswith(p) for p in self.tier1_prefixes) for f in feats)\n",
        "\n",
        "    def _is_valid_semantic(self, segment):\n",
        "        return self._has_tier1_feature(segment)\n",
        "\n",
        "    def _score(self, p, r, c):\n",
        "        return (p ** 2) * r * c\n",
        "\n",
        "    def generate_candidates(self, segments_df, y):\n",
        "        features = list(segments_df.columns)\n",
        "        N = len(segments_df)\n",
        "\n",
        "        print(f\"Using {len(features)} binary features\")\n",
        "        print(f\"Beam width: {self.beam_width}\")\n",
        "        print(f\"Rule complexity: {self.min_complexity}â€“{self.max_complexity}\")\n",
        "\n",
        "        rule_id = 0\n",
        "        all_candidates = []\n",
        "        current = {0: [], 1: []}\n",
        "\n",
        "        for f in features:\n",
        "            for l in (1, 0):  # FIXED: Use 1, 0 instead of \"yes\", \"no\"\n",
        "                seg = {(f, l)}\n",
        "                if not self._is_valid_semantic(seg):\n",
        "                    continue\n",
        "\n",
        "                mask = self._compute_rule_mask(seg, segments_df)\n",
        "                supp = mask.sum()\n",
        "                if supp < self.min_support:\n",
        "                    continue\n",
        "\n",
        "                cov = supp / N\n",
        "\n",
        "                for cls in (0, 1):\n",
        "                    p = self._compute_precision(mask, y, cls)\n",
        "                    r = self._compute_recall(mask, y, cls)\n",
        "\n",
        "                    if cls == 1 and p < self.min_seed_precision_subscribe:\n",
        "                        continue\n",
        "                    if cls == 0 and p < self.min_seed_precision_not_subscribe:\n",
        "                        continue\n",
        "                    if cls == 1 and r < self.min_recall_subscribe:\n",
        "                        continue\n",
        "                    if cls == 0 and r < self.min_recall_not_subscribe:\n",
        "                        continue\n",
        "\n",
        "                    rule = Rule(rule_id=rule_id, segment=seg, predicted_class=cls,\n",
        "                               complexity=1, interpretability=1.0)\n",
        "                    rule._p, rule._r, rule._c = p, r, cov\n",
        "                    rule._s = self._score(p, r, cov)\n",
        "                    current[cls].append(rule)\n",
        "                    rule_id += 1\n",
        "\n",
        "        for cls in (0, 1):\n",
        "            current[cls] = sorted(current[cls], key=lambda r: r._s, reverse=True)[:self.beam_width]\n",
        "\n",
        "        print(f\"[DEPTH 1] Seeds after beam prune: SUB={len(current[1])}, NOT_SUB={len(current[0])}\")\n",
        "\n",
        "        for depth in range(2, self.max_complexity + 1):\n",
        "            next_rules = {0: [], 1: []}\n",
        "            expansions = 0\n",
        "\n",
        "            for cls in (0, 1):\n",
        "                for parent in current[cls]:\n",
        "                    used = {f for f, _ in parent.segment}\n",
        "\n",
        "                    for f in features:\n",
        "                        if f in used:\n",
        "                            continue\n",
        "\n",
        "                        for l in (1, 0):  # FIXED: Use 1, 0 instead of \"yes\", \"no\"\n",
        "                            seg = parent.segment | {(f, l)}\n",
        "                            if not self._is_valid_semantic(seg):\n",
        "                                continue\n",
        "\n",
        "                            mask = self._compute_rule_mask(seg, segments_df)\n",
        "                            supp = mask.sum()\n",
        "                            if supp < self.min_support:\n",
        "                                continue\n",
        "\n",
        "                            p = self._compute_precision(mask, y, cls)\n",
        "                            r = self._compute_recall(mask, y, cls)\n",
        "\n",
        "                            if p < parent._p - self.min_precision_gain:\n",
        "                                continue\n",
        "                            if cls == 1 and r < self.min_recall_subscribe:\n",
        "                                continue\n",
        "                            if cls == 0 and r < self.min_recall_not_subscribe:\n",
        "                                continue\n",
        "\n",
        "                            cov = supp / N\n",
        "                            rule = Rule(rule_id=rule_id, segment=seg, predicted_class=cls,\n",
        "                                       complexity=depth, interpretability=1.0 / depth)\n",
        "                            rule._p, rule._r, rule._c = p, r, cov\n",
        "                            rule._s = self._score(p, r, cov)\n",
        "                            next_rules[cls].append(rule)\n",
        "                            rule_id += 1\n",
        "                            expansions += 1\n",
        "\n",
        "            if expansions == 0:\n",
        "                print(f\"[DEPTH {depth}] No valid expansions â€” stopping early.\")\n",
        "                break\n",
        "\n",
        "            for cls in (0, 1):\n",
        "                next_rules[cls] = sorted(next_rules[cls], key=lambda r: r._s, reverse=True)[:self.beam_width]\n",
        "                if depth >= self.min_complexity:\n",
        "                    all_candidates.extend(next_rules[cls])\n",
        "\n",
        "            print(f\"[DEPTH {depth}] After beam prune: SUB={len(next_rules[1])}, NOT_SUB={len(next_rules[0])}\")\n",
        "            current = next_rules\n",
        "\n",
        "        print(f\"\\nâœ… Generated {len(all_candidates)} candidate rules (k â‰¥ {self.min_complexity})\")\n",
        "        return all_candidates"
      ],
      "metadata": {
        "id": "jdfkRPejffn9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YejeHgYPTSB4"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 15: RULE EVALUATOR\n",
        "# ============================================================\n",
        "class RuleEvaluator:\n",
        "    \"\"\"\n",
        "    Compute validation-based quality metrics for candidate rules.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, segment_builder, min_support=6):\n",
        "        self.segment_builder = segment_builder\n",
        "        self.min_support = min_support\n",
        "\n",
        "    def match_rule(self, rule, segments_df):\n",
        "        mask = pd.Series(True, index=segments_df.index)\n",
        "        for feature, level in rule.segment:\n",
        "            if feature in segments_df.columns:\n",
        "                mask &= (segments_df[feature] == level)\n",
        "            else:\n",
        "                return pd.Series(False, index=segments_df.index)\n",
        "        return mask\n",
        "\n",
        "    def evaluate_candidates(self, candidates, X_val, y_val, ebm_model=None):\n",
        "        segments_val = self.segment_builder.assign_segments(X_val)\n",
        "\n",
        "        ebm_proba = None\n",
        "        if ebm_model is not None:\n",
        "            ebm_proba = ebm_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        evaluated_rules = []\n",
        "\n",
        "        for rule in candidates:\n",
        "            mask = self.match_rule(rule, segments_val)\n",
        "            n_matches = mask.sum()\n",
        "            rule.covered_idx = set(np.flatnonzero(mask.values))\n",
        "\n",
        "            if n_matches < self.min_support // 2:\n",
        "                continue\n",
        "\n",
        "            y_pred = np.full(n_matches, rule.predicted_class)\n",
        "            y_true = y_val[mask]\n",
        "\n",
        "            # âœ… CLASS-SPECIFIC PRECISION\n",
        "            if rule.predicted_class == 1:\n",
        "                rule.precision = precision_score(y_true, y_pred, zero_division=0.0)\n",
        "            else:\n",
        "                rule.precision = (y_true == 0).sum() / len(y_true) if len(y_true) > 0 else 0.0\n",
        "\n",
        "            # âœ… CLASS-SPECIFIC RECALL\n",
        "            if rule.predicted_class == 1:\n",
        "                total_positives = (y_val == 1).sum()\n",
        "                true_positives = ((y_val == 1) & mask).sum()\n",
        "                rule.recall = true_positives / total_positives if total_positives > 0 else 0.0\n",
        "            else:\n",
        "                total_negatives = (y_val == 0).sum()\n",
        "                true_negatives = ((y_val == 0) & mask).sum()\n",
        "                rule.recall = true_negatives / total_negatives if total_negatives > 0 else 0.0\n",
        "\n",
        "            rule.coverage = n_matches / len(X_val)\n",
        "\n",
        "            if rule.predicted_class == 1:\n",
        "                rule.stability = self._estimate_stability(rule, X_val, y_val)\n",
        "            else:\n",
        "                rule.stability = 1.0\n",
        "\n",
        "            if ebm_proba is not None:\n",
        "                ebm_conf_in_segment = np.abs(ebm_proba[mask] - 0.5)\n",
        "                rule.boundary_ambiguity = ebm_conf_in_segment.mean()\n",
        "                rule.ebm_overlap = (ebm_conf_in_segment > 0.20).mean()\n",
        "            else:\n",
        "                rule.boundary_ambiguity = 0.5\n",
        "                rule.ebm_overlap = 0.0\n",
        "\n",
        "            evaluated_rules.append(rule)\n",
        "\n",
        "        print(f\"Evaluated {len(evaluated_rules)} rules \"\n",
        "              f\"(filtered {len(candidates) - len(evaluated_rules)} low-coverage)\")\n",
        "\n",
        "        return evaluated_rules\n",
        "\n",
        "    def _estimate_stability(self, rule, X, y, n_bootstrap=3):\n",
        "        precisions = []\n",
        "        n = len(X)\n",
        "\n",
        "        for _ in range(n_bootstrap):\n",
        "            idx = np.random.choice(n, size=n, replace=True)\n",
        "            X_sample = X.iloc[idx]\n",
        "            y_sample = y.iloc[idx] if hasattr(y, 'iloc') else y[idx]\n",
        "\n",
        "            segments = self.segment_builder.assign_segments(X_sample)\n",
        "            mask = self.match_rule(rule, segments)\n",
        "\n",
        "            if mask.sum() < 10:\n",
        "                continue\n",
        "\n",
        "            y_pred = np.full(mask.sum(), rule.predicted_class)\n",
        "            y_true = y_sample[mask]\n",
        "\n",
        "            if rule.predicted_class == 1:\n",
        "                prec = precision_score(y_true, y_pred, zero_division=0.0)\n",
        "            else:\n",
        "                prec = (y_true == 0).sum() / len(y_true) if len(y_true) > 0 else 0.0\n",
        "\n",
        "            precisions.append(prec)\n",
        "\n",
        "        if len(precisions) < 2:\n",
        "            return 0.0\n",
        "\n",
        "        mean_prec = np.mean(precisions)\n",
        "        std_prec = np.std(precisions)\n",
        "\n",
        "        if mean_prec > 0:\n",
        "            stability = 1.0 - (std_prec / mean_prec)\n",
        "            return max(0.0, stability)\n",
        "        else:\n",
        "            return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 16: ILP SELECTOR - WITH FULL DEBUG\n",
        "# ============================================================\n",
        "\n",
        "class ILPRuleSelector:\n",
        "    def __init__(self, min_rules=5, max_rules=10,\n",
        "                 min_precision_subscribe=0.75, min_precision_not_subscribe=0.75,\n",
        "                 min_recall_subscribe=0.05, min_recall_not_subscribe=0.25,\n",
        "                 min_subscribe_rules=0, max_subscribe_rules=5,\n",
        "                 min_not_subscribe_rules=0, max_not_subscribe_rules=5,\n",
        "                 max_feature_usage=20,\n",
        "                 lambda_boundary=0.10, lambda_overlap=0.25,\n",
        "                 recall_weight=1.0):\n",
        "        self.min_rules = min_rules\n",
        "        self.max_rules = max_rules\n",
        "        self.min_precision_subscribe = min_precision_subscribe\n",
        "        self.min_precision_not_subscribe = min_precision_not_subscribe\n",
        "        self.min_recall_subscribe = min_recall_subscribe\n",
        "        self.min_recall_not_subscribe = min_recall_not_subscribe\n",
        "        self.min_subscribe_rules = min_subscribe_rules\n",
        "        self.max_subscribe_rules = max_subscribe_rules\n",
        "        self.min_not_subscribe_rules = min_not_subscribe_rules\n",
        "        self.max_not_subscribe_rules = max_not_subscribe_rules\n",
        "        self.max_feature_usage = max_feature_usage\n",
        "        self.lambda_boundary = lambda_boundary\n",
        "        self.lambda_overlap = lambda_overlap\n",
        "        self.recall_weight = recall_weight\n",
        "\n",
        "    def select_rules(self, candidates):\n",
        "        from pulp import LpProblem, LpMaximize, LpVariable, lpSum, LpStatus, PULP_CBC_CMD\n",
        "\n",
        "        if not candidates:\n",
        "            print(\"Warning: No candidates provided to ILP selector.\")\n",
        "            return []\n",
        "\n",
        "        # ============================================================\n",
        "        # DEBUG: Show ALL candidates before gating\n",
        "        # ============================================================\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ðŸ” ILP DEBUG: CANDIDATES BEFORE GATING\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        subscribe_cands = [r for r in candidates if r.predicted_class == 1]\n",
        "        not_subscribe_cands = [r for r in candidates if r.predicted_class == 0]\n",
        "\n",
        "        print(f\"\\nTotal candidates: {len(candidates)}\")\n",
        "        print(f\"  SUBSCRIBE candidates: {len(subscribe_cands)}\")\n",
        "        print(f\"  NOT_SUBSCRIBE candidates: {len(not_subscribe_cands)}\")\n",
        "\n",
        "        print(f\"\\nðŸ“Š Top 10 SUBSCRIBE candidates:\")\n",
        "        print(f\"{'Rule':<6} {'Segment':<50} {'Precision':<10} {'Recall':<10} {'Coverage':<10}\")\n",
        "        print(\"-\" * 90)\n",
        "        for i, r in enumerate(sorted(subscribe_cands, key=lambda x: x.precision, reverse=True)[:10], 1):\n",
        "            seg_str = ' AND '.join([f\"{f}={l}\" for f, l in list(r.segment)[:2]])\n",
        "            if len(r.segment) > 2:\n",
        "                seg_str += f\" ... (+{len(r.segment)-2})\"\n",
        "            print(f\"{i:<6} {seg_str:<50} {r.precision:<10.3f} {r.recall:<10.3f} {r.coverage:<10.3f}\")\n",
        "\n",
        "        print(f\"\\nðŸ“Š Top 10 NOT_SUBSCRIBE candidates:\")\n",
        "        print(f\"{'Rule':<6} {'Segment':<50} {'Precision':<10} {'Recall':<10} {'Coverage':<10}\")\n",
        "        print(\"-\" * 90)\n",
        "        for i, r in enumerate(sorted(not_subscribe_cands, key=lambda x: x.precision, reverse=True)[:10], 1):\n",
        "            seg_str = ' AND '.join([f\"{f}={l}\" for f, l in list(r.segment)[:2]])\n",
        "            if len(r.segment) > 2:\n",
        "                seg_str += f\" ... (+{len(r.segment)-2})\"\n",
        "            print(f\"{i:<6} {seg_str:<50} {r.precision:<10.3f} {r.recall:<10.3f} {r.coverage:<10.3f}\")\n",
        "\n",
        "        # ============================================================\n",
        "        # Setup ILP\n",
        "        # ============================================================\n",
        "        max_seen = -1\n",
        "        for r in candidates:\n",
        "            if hasattr(r, \"covered_idx\") and r.covered_idx and len(r.covered_idx) > 0:\n",
        "                max_seen = max(max_seen, max(r.covered_idx))\n",
        "\n",
        "        N = max_seen + 1\n",
        "        if N <= 0:\n",
        "            print(\"Warning: Could not infer validation size.\")\n",
        "            return []\n",
        "\n",
        "        prob = LpProblem(\"GLASS_BRW_Bank_Selection\", LpMaximize)\n",
        "        x = {r.rule_id: LpVariable(f\"x_{r.rule_id}\", cat='Binary') for r in candidates}\n",
        "\n",
        "        # NO MORE z variables - we don't care about coverage!\n",
        "\n",
        "        objective_terms = []\n",
        "        for r in candidates:\n",
        "            # Simple objective: precision^2 * recall * coverage\n",
        "            quality = (r.precision ** 2) * r.recall * r.coverage * r.interpretability\n",
        "            objective_terms.append(x[r.rule_id] * quality)\n",
        "\n",
        "        prob += lpSum(objective_terms), \"Objective\"\n",
        "\n",
        "        # ============================================================\n",
        "        # DEBUG: Apply gates and show results\n",
        "        # ============================================================\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ðŸ” APPLYING PRECISION/RECALL GATES\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"\\nGate thresholds:\")\n",
        "        print(f\"  SUBSCRIBE:     precision â‰¥ {self.min_precision_subscribe:.3f}, recall â‰¥ {self.min_recall_subscribe:.3f}\")\n",
        "        print(f\"  NOT_SUBSCRIBE: precision â‰¥ {self.min_precision_not_subscribe:.3f}, recall â‰¥ {self.min_recall_not_subscribe:.3f}\")\n",
        "\n",
        "        subscribe_valid = []\n",
        "        subscribe_rejected = []\n",
        "        not_subscribe_valid = []\n",
        "        not_subscribe_rejected = []\n",
        "\n",
        "        for r in candidates:\n",
        "            if r.predicted_class == 1:\n",
        "                if r.precision >= self.min_precision_subscribe and r.recall >= self.min_recall_subscribe:\n",
        "                    subscribe_valid.append(r)\n",
        "                else:\n",
        "                    subscribe_rejected.append(r)\n",
        "                    prob += (x[r.rule_id] == 0, f\"Gate_Sub_{r.rule_id}\")\n",
        "            else:\n",
        "                if r.precision >= self.min_precision_not_subscribe and r.recall >= self.min_recall_not_subscribe:\n",
        "                    not_subscribe_valid.append(r)\n",
        "                else:\n",
        "                    not_subscribe_rejected.append(r)\n",
        "                    prob += (x[r.rule_id] == 0, f\"Gate_NotSub_{r.rule_id}\")\n",
        "\n",
        "        print(f\"\\nâœ… PASSED GATES:\")\n",
        "        print(f\"  SUBSCRIBE:     {len(subscribe_valid)}/{len(subscribe_cands)}\")\n",
        "        print(f\"  NOT_SUBSCRIBE: {len(not_subscribe_valid)}/{len(not_subscribe_cands)}\")\n",
        "\n",
        "        print(f\"\\nâŒ REJECTED BY GATES:\")\n",
        "        print(f\"  SUBSCRIBE:     {len(subscribe_rejected)}/{len(subscribe_cands)}\")\n",
        "        print(f\"  NOT_SUBSCRIBE: {len(not_subscribe_rejected)}/{len(not_subscribe_cands)}\")\n",
        "\n",
        "        # Show why SUBSCRIBE rules failed\n",
        "        if len(subscribe_rejected) > 0:\n",
        "            print(f\"\\nâŒ Top 5 REJECTED SUBSCRIBE rules (showing why):\")\n",
        "            for i, r in enumerate(sorted(subscribe_rejected, key=lambda x: x.precision, reverse=True)[:5], 1):\n",
        "                seg_str = ' AND '.join([f\"{f}={l}\" for f, l in list(r.segment)[:2]])\n",
        "                if len(r.segment) > 2:\n",
        "                    seg_str += f\" ... (+{len(r.segment)-2})\"\n",
        "\n",
        "                fail_reasons = []\n",
        "                if r.precision < self.min_precision_subscribe:\n",
        "                    fail_reasons.append(f\"precision {r.precision:.3f} < {self.min_precision_subscribe:.3f}\")\n",
        "                if r.recall < self.min_recall_subscribe:\n",
        "                    fail_reasons.append(f\"recall {r.recall:.3f} < {self.min_recall_subscribe:.3f}\")\n",
        "\n",
        "                print(f\"  {i}. {seg_str}\")\n",
        "                print(f\"     FAILED: {', '.join(fail_reasons)}\")\n",
        "\n",
        "        # Adjust minimums\n",
        "        actual_min_sub = min(self.min_subscribe_rules, len(subscribe_valid))\n",
        "        actual_min_not_sub = min(self.min_not_subscribe_rules, len(not_subscribe_valid))\n",
        "        actual_min_rules = min(self.min_rules, len(subscribe_valid) + len(not_subscribe_valid))\n",
        "\n",
        "        prob += (lpSum(x[r.rule_id] for r in candidates) >= actual_min_rules, \"Min_Rules\")\n",
        "        prob += (lpSum(x[r.rule_id] for r in candidates) <= self.max_rules, \"Max_Rules\")\n",
        "\n",
        "        if subscribe_valid:\n",
        "            prob += (lpSum(x[r.rule_id] for r in subscribe_valid) >= actual_min_sub, \"Min_Sub\")\n",
        "            prob += (lpSum(x[r.rule_id] for r in subscribe_valid) <= self.max_subscribe_rules, \"Max_Sub\")\n",
        "\n",
        "        if not_subscribe_valid:\n",
        "            prob += (lpSum(x[r.rule_id] for r in not_subscribe_valid) >= actual_min_not_sub, \"Min_NotSub\")\n",
        "            prob += (lpSum(x[r.rule_id] for r in not_subscribe_valid) <= self.max_not_subscribe_rules, \"Max_NotSub\")\n",
        "\n",
        "        # NO COVERAGE CONSTRAINT!\n",
        "\n",
        "        feature_usage = defaultdict(list)\n",
        "        for r in candidates:\n",
        "            for feature, _ in r.segment:\n",
        "                feature_usage[feature].append(r.rule_id)\n",
        "\n",
        "        for feature, rule_ids in feature_usage.items():\n",
        "            prob += (lpSum(x[rid] for rid in rule_ids) <= self.max_feature_usage, f\"Div_{feature}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Solving ILP (NO coverage constraint)...\")\n",
        "        solver = PULP_CBC_CMD(msg=0, timeLimit=300)\n",
        "        prob.solve(solver)\n",
        "\n",
        "        status = LpStatus[prob.status]\n",
        "        print(f\"ILP Status: {status}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if status != 'Optimal':\n",
        "            print(\"\\nâš ï¸ ILP FAILED - Using greedy fallback\")\n",
        "\n",
        "            subscribe_valid = sorted(subscribe_valid,\n",
        "                                    key=lambda r: (r.precision ** 2) * r.recall * r.coverage,\n",
        "                                    reverse=True)\n",
        "            not_subscribe_valid = sorted(not_subscribe_valid,\n",
        "                                        key=lambda r: (r.precision ** 2) * r.recall * r.coverage,\n",
        "                                        reverse=True)\n",
        "\n",
        "            selected_subscribe = subscribe_valid[:self.max_subscribe_rules]\n",
        "            selected_not_subscribe = not_subscribe_valid[:self.max_not_subscribe_rules]\n",
        "\n",
        "            selected_rules = selected_subscribe + selected_not_subscribe\n",
        "\n",
        "            print(f\"   Selected {len(selected_subscribe)} SUBSCRIBE rules\")\n",
        "            print(f\"   Selected {len(selected_not_subscribe)} NOT_SUBSCRIBE rules\")\n",
        "            print(f\"   Total: {len(selected_rules)} rules\")\n",
        "\n",
        "            return selected_rules\n",
        "\n",
        "        selected_rules = []\n",
        "        for r in candidates:\n",
        "            if x[r.rule_id].varValue is not None and x[r.rule_id].varValue > 0.5:\n",
        "                selected_rules.append(r)\n",
        "\n",
        "        print(f\"\\nSelected {len(selected_rules)} rules\")\n",
        "        return selected_rules"
      ],
      "metadata": {
        "id": "haLTP5buuYYG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UWdW1SNrlrvJ"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 17: GLASS-BRW CLASSIFIER (ADD RECALL TO PRINTING)\n",
        "# ============================================================\n",
        "\n",
        "class GLASS_BRW:\n",
        "    def __init__(self,\n",
        "                 mode=\"strict\",\n",
        "                 min_precision_subscribe=0.75,\n",
        "                 min_precision_not_subscribe=0.75,\n",
        "                 min_recall_subscribe=0.05,\n",
        "                 min_recall_not_subscribe=0.25,\n",
        "                 min_support=5,\n",
        "                 max_complexity=3,\n",
        "                 min_rules=8,\n",
        "                 max_rules=10,\n",
        "                 max_subscribe_rules=5,\n",
        "                 max_not_subscribe_rules=5):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            mode: Segmentation mode ('strict', 'helpers', 'discover')\n",
        "            min_precision_subscribe: Precision gate for SUBSCRIBE rules\n",
        "            min_precision_not_subscribe: Precision gate for NOT_SUBSCRIBE rules\n",
        "            min_support: Minimum samples for rule generation\n",
        "            max_complexity: Maximum conditions per rule (k â‰¤ 3)\n",
        "            min_rules: Minimum rules to select\n",
        "            max_rules: Maximum rules to select\n",
        "            max_subscribe_rules: Maximum SUBSCRIBE rules\n",
        "            max_not_subscribe_rules: Maximum NOT_SUBSCRIBE rules\n",
        "        \"\"\"\n",
        "        self.mode = mode\n",
        "        self.min_precision_subscribe = min_precision_subscribe\n",
        "        self.min_precision_not_subscribe = min_precision_not_subscribe\n",
        "        self.min_support = min_support\n",
        "        self.max_complexity = max_complexity\n",
        "        self.min_rules = min_rules\n",
        "        self.max_rules = max_rules\n",
        "        self.max_subscribe_rules = max_subscribe_rules\n",
        "        self.max_not_subscribe_rules = max_not_subscribe_rules\n",
        "\n",
        "        # Components\n",
        "        self.segment_builder = BankSegmentBuilder(mode=mode)\n",
        "        self.rule_generator = RuleGenerator(min_support, max_complexity, mode=mode)\n",
        "        self.rule_evaluator = RuleEvaluator(self.segment_builder, min_support)\n",
        "        self.ilp_selector = ILPRuleSelector(\n",
        "            min_rules=min_rules,\n",
        "            max_rules=max_rules,\n",
        "            min_precision_subscribe=min_precision_subscribe,\n",
        "            min_precision_not_subscribe=min_precision_not_subscribe,\n",
        "            min_subscribe_rules=3,\n",
        "            max_subscribe_rules=max_subscribe_rules,\n",
        "            min_not_subscribe_rules=3,\n",
        "            max_not_subscribe_rules=max_not_subscribe_rules\n",
        "        )\n",
        "\n",
        "        # Fitted attributes\n",
        "        self.rules = None\n",
        "        self.is_fitted = False\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val, y_val, ebm_model=None):\n",
        "        \"\"\"\n",
        "        Train GLASS-BRW using ILP optimization.\n",
        "\n",
        "        Args:\n",
        "            X_train: Training features (with engineered bank features)\n",
        "            y_train: Training labels (0/1)\n",
        "            X_val: Validation features\n",
        "            y_val: Validation labels\n",
        "            ebm_model: Optional EBM model for complementarity\n",
        "\n",
        "        Returns:\n",
        "            self\n",
        "        \"\"\"\n",
        "        print(\"=\"*60)\n",
        "        print(\"GLASS-BRW Training Pipeline (Bank Marketing)\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Mode: {self.mode}\")\n",
        "\n",
        "        # Convert to pandas\n",
        "        if not isinstance(X_train, pd.DataFrame):\n",
        "            X_train = pd.DataFrame(X_train)\n",
        "        if not isinstance(X_val, pd.DataFrame):\n",
        "            X_val = pd.DataFrame(X_val)\n",
        "        if not isinstance(y_train, (pd.Series, np.ndarray)):\n",
        "            y_train = np.array(y_train)\n",
        "        if not isinstance(y_val, (pd.Series, np.ndarray)):\n",
        "            y_val = np.array(y_val)\n",
        "\n",
        "        # Phase 1: Assign segments\n",
        "        print(\"\\nPhase 1: Assigning customer segments...\")\n",
        "        segments_train = self.segment_builder.assign_segments(X_train)\n",
        "        print(f\"  Segment features: {len(segments_train.columns)}\")\n",
        "\n",
        "        # Phase 2: Generate candidates\n",
        "        print(\"\\nPhase 2: Generating candidate rules...\")\n",
        "        candidates = self.rule_generator.generate_candidates(segments_train, y_train)\n",
        "\n",
        "        # Phase 3: Evaluate on validation\n",
        "        print(\"\\nPhase 3: Evaluating rule quality on validation set...\")\n",
        "        evaluated_candidates = self.rule_evaluator.evaluate_candidates(\n",
        "            candidates, X_val, y_val, ebm_model\n",
        "        )\n",
        "\n",
        "        # Phase 4: ILP selection\n",
        "        print(\"\\nPhase 4: Solving ILP for optimal rule subset...\")\n",
        "        selected_rules = self.ilp_selector.select_rules(evaluated_candidates)\n",
        "\n",
        "        # Phase 5: Order rules (SUBSCRIBE first, precision-sorted)\n",
        "        print(\"\\nPhase 5: Ordering rules (SUBSCRIBE â†’ NOT_SUBSCRIBE, precision-sorted)...\")\n",
        "        subscribe_rules = sorted(\n",
        "            [r for r in selected_rules if r.predicted_class == 1],\n",
        "            key=lambda r: r.precision,\n",
        "            reverse=True\n",
        "        )\n",
        "        not_subscribe_rules = sorted(\n",
        "            [r for r in selected_rules if r.predicted_class == 0],\n",
        "            key=lambda r: r.precision,\n",
        "            reverse=True\n",
        "        )\n",
        "        self.rules = subscribe_rules + not_subscribe_rules\n",
        "\n",
        "        # âœ… UPDATED: Print final rules WITH RECALL\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Selected Rules (ordered by precision):\")\n",
        "        print(\"=\"*60)\n",
        "        for i, rule in enumerate(self.rules, 1):\n",
        "            segment_str = ' AND '.join([f\"{f}={l}\" for f, l in rule.segment])\n",
        "            class_str = \"SUBSCRIBE\" if rule.predicted_class == 1 else \"NOT_SUB\"\n",
        "            print(f\"{i}. [{class_str:9s}] {segment_str}\")\n",
        "            print(f\"   Precision: {rule.precision:.1%}, Recall: {rule.recall:.1%}, \"\n",
        "                  f\"Coverage: {rule.coverage:.1%}, Complexity: {rule.complexity}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        self.is_fitted = True\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict using first-match-wins with explicit abstention.\n",
        "\n",
        "        Args:\n",
        "            X: Features (DataFrame with engineered features)\n",
        "\n",
        "        Returns:\n",
        "            predictions: Array of {-1, 0, 1} where -1 = ABSTAIN\n",
        "            explanations: List of explanations\n",
        "            confidences: Array of rule precisions\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Model must be fitted before prediction\")\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            X = pd.DataFrame(X)\n",
        "\n",
        "        n = len(X)\n",
        "        predictions = np.full(n, -1, dtype=int)\n",
        "        explanations = [None] * n\n",
        "        confidences = np.zeros(n)\n",
        "\n",
        "        # Assign segments\n",
        "        segments = self.segment_builder.assign_segments(X)\n",
        "\n",
        "        # First-match-wins\n",
        "        for i in range(n):\n",
        "            for rule in self.rules:\n",
        "                # Check segment match\n",
        "                matches = True\n",
        "                for feature, level in rule.segment:\n",
        "                    if feature not in segments.columns:\n",
        "                        matches = False\n",
        "                        break\n",
        "                    if segments.iloc[i][feature] != level:\n",
        "                        matches = False\n",
        "                        break\n",
        "\n",
        "                if not matches:\n",
        "                    continue\n",
        "\n",
        "                # Optional: enforce precision floor at execution\n",
        "                if rule.predicted_class == 1 and rule.precision < self.min_precision_subscribe:\n",
        "                    continue\n",
        "                if rule.predicted_class == 0 and rule.precision < self.min_precision_not_subscribe:\n",
        "                    continue\n",
        "\n",
        "                predictions[i] = rule.predicted_class\n",
        "                confidences[i] = rule.precision\n",
        "                explanations[i] = self._format_explanation(rule)\n",
        "                break\n",
        "\n",
        "            # No rule matched = abstain\n",
        "            if predictions[i] == -1:\n",
        "                explanations[i] = \"ABSTAIN: No high-precision segment rule applies\"\n",
        "                confidences[i] = 0.0\n",
        "\n",
        "        self.last_predictions = predictions\n",
        "        self.last_explanations = explanations\n",
        "        self.last_confidences = confidences\n",
        "\n",
        "        return predictions, explanations, confidences\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Return probability estimates [P(Not_Subscribe), P(Subscribe)].\n",
        "\n",
        "        Args:\n",
        "            X: Features\n",
        "\n",
        "        Returns:\n",
        "            probas: Array of shape (n_samples, 2)\n",
        "        \"\"\"\n",
        "        predictions, _, confidences = self.predict(X)\n",
        "        n = len(X)\n",
        "        probas = np.zeros((n, 2))\n",
        "\n",
        "        for i in range(n):\n",
        "            if predictions[i] == -1:  # ABSTAIN\n",
        "                probas[i] = [0.5, 0.5]\n",
        "            elif predictions[i] == 1:  # SUBSCRIBE\n",
        "                probas[i] = [1 - confidences[i], confidences[i]]\n",
        "            else:  # NOT_SUBSCRIBE\n",
        "                probas[i] = [confidences[i], 1 - confidences[i]]\n",
        "\n",
        "        return probas\n",
        "\n",
        "    def _format_explanation(self, rule):\n",
        "        \"\"\"Generate human-readable explanation for a rule.\"\"\"\n",
        "        conditions = [f\"{feat}={level}\" for feat, level in rule.segment]\n",
        "        segment_str = ' AND '.join(conditions)\n",
        "        class_name = \"SUBSCRIBE\" if rule.predicted_class == 1 else \"NOT_SUBSCRIBE\"\n",
        "        return f\"Segment: {segment_str} â†’ {class_name} ({rule.precision:.1%} precision)\"\n",
        "\n",
        "    def explain_prediction(self, X, sample_idx=0):\n",
        "        \"\"\"Get explanation for a specific prediction.\"\"\"\n",
        "        if not hasattr(self, 'last_explanations'):\n",
        "            self.predict(X)\n",
        "        if sample_idx < len(self.last_explanations):\n",
        "            return self.last_explanations[sample_idx]\n",
        "        return \"No explanation available\"\n",
        "\n",
        "    def get_coverage_stats(self, X, y):\n",
        "        \"\"\"Compute coverage and performance statistics.\"\"\"\n",
        "        predictions, _, confidences = self.predict(X)\n",
        "\n",
        "        covered = (predictions != -1)\n",
        "        coverage_rate = covered.mean()\n",
        "        abstention_rate = 1 - coverage_rate\n",
        "\n",
        "        if covered.sum() > 0:\n",
        "            covered_precision = precision_score(y[covered], predictions[covered])\n",
        "            covered_recall = recall_score(y[covered], predictions[covered])\n",
        "        else:\n",
        "            covered_precision = 0.0\n",
        "            covered_recall = 0.0\n",
        "\n",
        "        subscribe_covered = covered & (predictions == 1)\n",
        "        not_subscribe_covered = covered & (predictions == 0)\n",
        "\n",
        "        stats = {\n",
        "            'coverage_rate': coverage_rate,\n",
        "            'abstention_rate': abstention_rate,\n",
        "            'covered_precision': covered_precision,\n",
        "            'covered_recall': covered_recall,\n",
        "            'subscribe_coverage': subscribe_covered.mean(),\n",
        "            'not_subscribe_coverage': not_subscribe_covered.mean(),\n",
        "            'avg_confidence': confidences[covered].mean() if covered.sum() > 0 else 0.0,\n",
        "            'n_samples': len(X),\n",
        "            'n_covered': covered.sum(),\n",
        "            'n_abstained': (~covered).sum()\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 18: GLASS-BRW MAIN PIPELINE\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================\n",
        "# 1. FEATURE ENGINEERING\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ” STEP 1: FEATURE ENGINEERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_eng = engineer_features_bank(df_proc)\n",
        "\n",
        "top_15_features = [\n",
        "    \"duration_very_long\", \"duration_short\", \"duration_long\", \"duration_medium\",\n",
        "    \"poutcome_success\", \"month_may_volatile\", \"age_prime_working\", \"age_senior\",\n",
        "    \"contact_not_cellular\", \"campaign_single\", \"month_summer_dead\", \"month_spring_lift\",\n",
        "    \"day_late\", \"day_mid\", \"balance_mid\", \"flag_success_medlong_job\",\n",
        "    \"flag_success_medlong_education\", \"flag_success_medlong_month_late\", \"flag_success_medlong_marital\",\n",
        "    \"flag_success_medlong_housing\", \"flag_success_medlong_loan\",\n",
        "    \"flag_success_medlong_default\", \"flag_success_medlong_contact_not_cell\"\n",
        "]\n",
        "\n",
        "available_features = [f for f in top_15_features if f in df_eng.columns]\n",
        "missing_features = [f for f in top_15_features if f not in df_eng.columns]\n",
        "\n",
        "print(f\"\\nâœ… Available: {len(available_features)}/{len(top_15_features)}\")\n",
        "if missing_features:\n",
        "    raise ValueError(f\"âŒ Missing features: {missing_features}\")\n",
        "\n",
        "y_clean = df_eng['y'].copy()\n",
        "X_clean = df_eng[available_features].copy()\n",
        "\n",
        "print(f\"   Features: {X_clean.shape[1]}, Samples: {X_clean.shape[0]}\")\n",
        "print(f\"   Positive rate: {y_clean.mean():.2%}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. SAFE 70/15/15 SPLIT\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“Š STEP 2: 70/15/15 TRAIN/VAL/TEST SPLIT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_clean, y_clean, test_size=0.15, random_state=42, stratify=y_clean\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.15/0.85, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Split complete:\")\n",
        "print(f\"   Train: {len(X_train)} ({len(X_train)/len(X_clean):.1%}) - pos rate: {y_train.mean():.2%}\")\n",
        "print(f\"   Val:   {len(X_val)} ({len(X_val)/len(X_clean):.1%}) - pos rate: {y_val.mean():.2%}\")\n",
        "print(f\"   Test:  {len(X_test)} ({len(X_test)/len(X_clean):.1%}) - pos rate: {y_test.mean():.2%}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. TRAIN GLASS-BRW\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸš€ STEP 3: TRAINING GLASS-BRW\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "glass = GLASS_BRW(\n",
        "    mode=\"helpers\",\n",
        "    min_precision_subscribe=0.70,\n",
        "    min_precision_not_subscribe=0.50,\n",
        "    min_recall_subscribe=0.05,\n",
        "    min_recall_not_subscribe=0.10,\n",
        "    min_support=5,\n",
        "    max_complexity=3,\n",
        "    min_rules=8,\n",
        "    max_rules=10,\n",
        "    max_subscribe_rules=5,\n",
        "    max_not_subscribe_rules=5\n",
        ")\n",
        "\n",
        "glass.fit(X_train, y_train, X_val, y_val, ebm_model=None)\n",
        "\n",
        "# ============================================================\n",
        "# 4. EVALUATE ON TEST SET\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“Š STEP 4: EVALUATION ON TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "predictions, explanations, confidences = glass.predict(X_test)\n",
        "probas = glass.predict_proba(X_test)\n",
        "\n",
        "covered = (predictions != -1)\n",
        "preds_for_metrics = predictions.copy()\n",
        "preds_for_metrics[preds_for_metrics == -1] = 0\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Coverage:\")\n",
        "print(f\"   Covered:   {covered.sum():5d} ({covered.mean():.1%})\")\n",
        "print(f\"   Abstained: {(~covered).sum():5d} ({(~covered).mean():.1%})\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Overall Performance (abstain â†’ NOT_SUBSCRIBE):\")\n",
        "print(f\"   Accuracy:  {accuracy_score(y_test, preds_for_metrics):.3f}\")\n",
        "print(f\"   Precision: {precision_score(y_test, preds_for_metrics, zero_division=0):.3f}\")\n",
        "print(f\"   Recall:    {recall_score(y_test, preds_for_metrics, zero_division=0):.3f}\")\n",
        "print(f\"   F1 Score:  {f1_score(y_test, preds_for_metrics, zero_division=0):.3f}\")\n",
        "\n",
        "if covered.sum() > 0:\n",
        "    print(f\"\\nðŸ“Š Covered Cases Only:\")\n",
        "    print(f\"   Accuracy:  {accuracy_score(y_test[covered], predictions[covered]):.3f}\")\n",
        "    print(f\"   Precision: {precision_score(y_test[covered], predictions[covered], zero_division=0):.3f}\")\n",
        "    print(f\"   Recall:    {recall_score(y_test[covered], predictions[covered], zero_division=0):.3f}\")\n",
        "    print(f\"   F1 Score:  {f1_score(y_test[covered], predictions[covered], zero_division=0):.3f}\")\n",
        "    print(f\"   Confidence: {confidences[covered].mean():.3f}\")\n",
        "\n",
        "    cm = confusion_matrix(y_test[covered], predictions[covered])\n",
        "    print(f\"\\nðŸ“Š Confusion Matrix:\")\n",
        "    print(f\"                Pred NOT_SUB  Pred SUBSCRIBE\")\n",
        "    print(f\"Actual NOT_SUB      {cm[0,0]:5d}          {cm[0,1]:5d}\")\n",
        "    print(f\"Actual SUBSCRIBE    {cm[1,0]:5d}          {cm[1,1]:5d}\")\n",
        "\n",
        "    print(f\"\\nðŸ“Š Classification Report:\")\n",
        "    print(classification_report(y_test[covered], predictions[covered],\n",
        "                                target_names=['NOT_SUBSCRIBE', 'SUBSCRIBE'], zero_division=0))\n",
        "\n",
        "# ============================================================\n",
        "# 5. RULE ANALYSIS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ” STEP 5: RULE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "subscribe_rules = [r for r in glass.rules if r.predicted_class == 1]\n",
        "not_subscribe_rules = [r for r in glass.rules if r.predicted_class == 0]\n",
        "\n",
        "print(f\"\\nTotal Rules: {len(glass.rules)}\")\n",
        "print(f\"  SUBSCRIBE: {len(subscribe_rules)}\")\n",
        "print(f\"  NOT_SUBSCRIBE: {len(not_subscribe_rules)}\")\n",
        "\n",
        "if subscribe_rules:\n",
        "    print(f\"\\nðŸ” Top 5 SUBSCRIBE Rules:\")\n",
        "    for i, r in enumerate(subscribe_rules[:5], 1):\n",
        "        seg = ' AND '.join([f\"{f}={l}\" for f, l in r.segment])\n",
        "        print(f\"  {i}. {seg}\")\n",
        "        print(f\"     P={r.precision:.1%}, R={r.recall:.1%}, Cov={r.coverage:.1%}, K={r.complexity}\")\n",
        "\n",
        "if not_subscribe_rules:\n",
        "    print(f\"\\nðŸ” Top 5 NOT_SUBSCRIBE Rules:\")\n",
        "    for i, r in enumerate(not_subscribe_rules[:5], 1):\n",
        "        seg = ' AND '.join([f\"{f}={l}\" for f, l in r.segment])\n",
        "        print(f\"  {i}. {seg}\")\n",
        "        print(f\"     P={r.precision:.1%}, R={r.recall:.1%}, Cov={r.coverage:.1%}, K={r.complexity}\")\n",
        "\n",
        "# Feature usage\n",
        "feature_usage = {}\n",
        "for r in glass.rules:\n",
        "    for f, _ in r.segment:\n",
        "        feature_usage[f] = feature_usage.get(f, 0) + 1\n",
        "\n",
        "print(f\"\\nðŸ“Š Feature Usage:\")\n",
        "for f, cnt in sorted(feature_usage.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"   {f:25s}: {cnt:2d} ({cnt/len(glass.rules)*100:5.1f}%)\")\n",
        "\n",
        "unused = set(available_features) - set(feature_usage.keys())\n",
        "if unused:\n",
        "    print(f\"\\nâš ï¸  Unused: {unused}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ… COMPLETE\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G4XKVUjrWI_",
        "outputId": "70964bec-7e77-4bb6-fd89-673e39c1c8f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸ” STEP 1: FEATURE ENGINEERING\n",
            "================================================================================\n",
            "ðŸ” Engineering state-based features for GLASS-BRW...\n",
            "âœ“ All engineered features are binary 0/1\n",
            "âœ… Engineered 49 binary features (+ y)\n",
            "\n",
            "âœ… Available: 23/23\n",
            "   Features: 23, Samples: 45211\n",
            "   Positive rate: 11.70%\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š STEP 2: 70/15/15 TRAIN/VAL/TEST SPLIT\n",
            "================================================================================\n",
            "\n",
            "âœ… Split complete:\n",
            "   Train: 31647 (70.0%) - pos rate: 11.70%\n",
            "   Val:   6782 (15.0%) - pos rate: 11.69%\n",
            "   Test:  6782 (15.0%) - pos rate: 11.69%\n",
            "\n",
            "================================================================================\n",
            "ðŸš€ STEP 3: TRAINING GLASS-BRW\n",
            "================================================================================\n",
            "============================================================\n",
            "GLASS-BRW Training Pipeline (Bank Marketing)\n",
            "============================================================\n",
            "Mode: helpers\n",
            "\n",
            "Phase 1: Assigning customer segments...\n",
            "  Segment features: 23\n",
            "\n",
            "Phase 2: Generating candidate rules...\n",
            "Using 23 binary features\n",
            "Beam width: 300\n",
            "Rule complexity: 1â€“3\n",
            "[DEPTH 1] Seeds after beam prune: SUB=5, NOT_SUB=27\n",
            "[DEPTH 2] After beam prune: SUB=80, NOT_SUB=300\n",
            "[DEPTH 3] After beam prune: SUB=300, NOT_SUB=300\n",
            "\n",
            "âœ… Generated 980 candidate rules (k â‰¥ 1)\n",
            "\n",
            "Phase 3: Evaluating rule quality on validation set...\n",
            "Evaluated 980 rules (filtered 0 low-coverage)\n",
            "\n",
            "Phase 4: Solving ILP for optimal rule subset...\n",
            "\n",
            "================================================================================\n",
            "ðŸ” ILP DEBUG: CANDIDATES BEFORE GATING\n",
            "================================================================================\n",
            "\n",
            "Total candidates: 980\n",
            "  SUBSCRIBE candidates: 380\n",
            "  NOT_SUBSCRIBE candidates: 600\n",
            "\n",
            "ðŸ“Š Top 10 SUBSCRIBE candidates:\n",
            "Rule   Segment                                            Precision  Recall     Coverage  \n",
            "------------------------------------------------------------------------------------------\n",
            "1      flag_success_medlong_loan=1 AND flag_success_medlong_housing=0 0.810      0.086      0.012     \n",
            "2      flag_success_medlong_housing=0 AND flag_success_medlong_default=1 0.798      0.090      0.013     \n",
            "3      flag_success_medlong_job=1 AND flag_success_medlong_housing=0 0.798      0.090      0.013     \n",
            "4      flag_success_medlong_housing=0 AND flag_success_medlong_education=1 0.798      0.090      0.013     \n",
            "5      flag_success_medlong_marital=1 AND flag_success_medlong_housing=0 0.798      0.090      0.013     \n",
            "6      flag_success_medlong_loan=1 AND day_mid=0          0.793      0.082      0.012     \n",
            "7      flag_success_medlong_default=1 AND day_mid=0       0.791      0.086      0.013     \n",
            "8      flag_success_medlong_job=1 AND day_mid=0           0.791      0.086      0.013     \n",
            "9      flag_success_medlong_education=1 AND day_mid=0     0.791      0.086      0.013     \n",
            "10     flag_success_medlong_marital=1 AND day_mid=0       0.791      0.086      0.013     \n",
            "\n",
            "ðŸ“Š Top 10 NOT_SUBSCRIBE candidates:\n",
            "Rule   Segment                                            Precision  Recall     Coverage  \n",
            "------------------------------------------------------------------------------------------\n",
            "1      duration_very_long=0 AND campaign_single=0         0.939      0.594      0.559     \n",
            "2      duration_very_long=0 AND campaign_single=0         0.939      0.594      0.559     \n",
            "3      duration_very_long=0 AND duration_long=0           0.934      0.842      0.796     \n",
            "4      duration_very_long=0 AND duration_long=0           0.934      0.842      0.796     \n",
            "5      duration_very_long=0 AND poutcome_success=0        0.933      0.936      0.885     \n",
            "6      duration_very_long=0 AND poutcome_success=0        0.933      0.936      0.885     \n",
            "7      duration_medium=0 AND duration_very_long=0         0.931      0.661      0.627     \n",
            "8      duration_medium=0 AND duration_very_long=0         0.931      0.661      0.627     \n",
            "9      duration_very_long=0 AND month_spring_lift=0       0.931      0.832      0.790     \n",
            "10     duration_very_long=0 AND age_prime_working=1       0.929      0.550      0.523     \n",
            "\n",
            "================================================================================\n",
            "ðŸ” APPLYING PRECISION/RECALL GATES\n",
            "================================================================================\n",
            "\n",
            "Gate thresholds:\n",
            "  SUBSCRIBE:     precision â‰¥ 0.700, recall â‰¥ 0.050\n",
            "  NOT_SUBSCRIBE: precision â‰¥ 0.500, recall â‰¥ 0.250\n",
            "\n",
            "âœ… PASSED GATES:\n",
            "  SUBSCRIBE:     379/380\n",
            "  NOT_SUBSCRIBE: 600/600\n",
            "\n",
            "âŒ REJECTED BY GATES:\n",
            "  SUBSCRIBE:     1/380\n",
            "  NOT_SUBSCRIBE: 0/600\n",
            "\n",
            "âŒ Top 5 REJECTED SUBSCRIBE rules (showing why):\n",
            "  1. flag_success_medlong_loan=1 AND balance_mid=0\n",
            "     FAILED: recall 0.049 < 0.050\n",
            "\n",
            "================================================================================\n",
            "Solving ILP (NO coverage constraint)...\n",
            "ILP Status: Optimal\n",
            "================================================================================\n",
            "\n",
            "Selected 10 rules\n",
            "\n",
            "Phase 5: Ordering rules (SUBSCRIBE â†’ NOT_SUBSCRIBE, precision-sorted)...\n",
            "\n",
            "============================================================\n",
            "Selected Rules (ordered by precision):\n",
            "============================================================\n",
            "1. [SUBSCRIBE] duration_very_long=0 AND flag_success_medlong_default=1\n",
            "   Precision: 72.7%, Recall: 12.1%, Coverage: 1.9%, Complexity: 2\n",
            "2. [SUBSCRIBE] flag_success_medlong_default=1 AND duration_short=0\n",
            "   Precision: 72.7%, Recall: 12.1%, Coverage: 1.9%, Complexity: 2\n",
            "3. [SUBSCRIBE] flag_success_medlong_default=1 AND poutcome_success=1\n",
            "   Precision: 72.7%, Recall: 12.1%, Coverage: 1.9%, Complexity: 2\n",
            "4. [SUBSCRIBE] flag_success_medlong_job=1 AND flag_success_medlong_default=1\n",
            "   Precision: 72.7%, Recall: 12.1%, Coverage: 1.9%, Complexity: 2\n",
            "5. [SUBSCRIBE] flag_success_medlong_job=1 AND flag_success_medlong_default=1\n",
            "   Precision: 72.7%, Recall: 12.1%, Coverage: 1.9%, Complexity: 2\n",
            "6. [NOT_SUB  ] flag_success_medlong_default=0 AND flag_success_medlong_marital=0\n",
            "   Precision: 89.5%, Recall: 99.4%, Coverage: 98.1%, Complexity: 2\n",
            "7. [NOT_SUB  ] flag_success_medlong_loan=0 AND flag_success_medlong_housing=0\n",
            "   Precision: 89.5%, Recall: 99.4%, Coverage: 98.1%, Complexity: 2\n",
            "8. [NOT_SUB  ] flag_success_medlong_loan=0 AND flag_success_medlong_housing=0\n",
            "   Precision: 89.5%, Recall: 99.4%, Coverage: 98.1%, Complexity: 2\n",
            "9. [NOT_SUB  ] flag_success_medlong_month_late=0 AND flag_success_medlong_contact_not_cell=0\n",
            "   Precision: 88.8%, Recall: 99.8%, Coverage: 99.3%, Complexity: 2\n",
            "10. [NOT_SUB  ] flag_success_medlong_month_late=0 AND flag_success_medlong_contact_not_cell=0\n",
            "   Precision: 88.8%, Recall: 99.8%, Coverage: 99.3%, Complexity: 2\n",
            "============================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š STEP 4: EVALUATION ON TEST SET\n",
            "================================================================================\n",
            "\n",
            "ðŸ“ˆ Coverage:\n",
            "   Covered:    6782 (100.0%)\n",
            "   Abstained:     0 (0.0%)\n",
            "\n",
            "ðŸ“Š Overall Performance (abstain â†’ NOT_SUBSCRIBE):\n",
            "   Accuracy:  0.893\n",
            "   Precision: 0.746\n",
            "   Recall:    0.134\n",
            "   F1 Score:  0.227\n",
            "\n",
            "ðŸ“Š Covered Cases Only:\n",
            "   Accuracy:  0.893\n",
            "   Precision: 0.746\n",
            "   Recall:    0.134\n",
            "   F1 Score:  0.227\n",
            "   Confidence: 0.892\n",
            "\n",
            "ðŸ“Š Confusion Matrix:\n",
            "                Pred NOT_SUB  Pred SUBSCRIBE\n",
            "Actual NOT_SUB       5953             36\n",
            "Actual SUBSCRIBE      687            106\n",
            "\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "NOT_SUBSCRIBE       0.90      0.99      0.94      5989\n",
            "    SUBSCRIBE       0.75      0.13      0.23       793\n",
            "\n",
            "     accuracy                           0.89      6782\n",
            "    macro avg       0.82      0.56      0.58      6782\n",
            " weighted avg       0.88      0.89      0.86      6782\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ” STEP 5: RULE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Total Rules: 10\n",
            "  SUBSCRIBE: 5\n",
            "  NOT_SUBSCRIBE: 5\n",
            "\n",
            "ðŸ” Top 5 SUBSCRIBE Rules:\n",
            "  1. duration_very_long=0 AND flag_success_medlong_default=1\n",
            "     P=72.7%, R=12.1%, Cov=1.9%, K=2\n",
            "  2. flag_success_medlong_default=1 AND duration_short=0\n",
            "     P=72.7%, R=12.1%, Cov=1.9%, K=2\n",
            "  3. flag_success_medlong_default=1 AND poutcome_success=1\n",
            "     P=72.7%, R=12.1%, Cov=1.9%, K=2\n",
            "  4. flag_success_medlong_job=1 AND flag_success_medlong_default=1\n",
            "     P=72.7%, R=12.1%, Cov=1.9%, K=2\n",
            "  5. flag_success_medlong_job=1 AND flag_success_medlong_default=1\n",
            "     P=72.7%, R=12.1%, Cov=1.9%, K=2\n",
            "\n",
            "ðŸ” Top 5 NOT_SUBSCRIBE Rules:\n",
            "  1. flag_success_medlong_default=0 AND flag_success_medlong_marital=0\n",
            "     P=89.5%, R=99.4%, Cov=98.1%, K=2\n",
            "  2. flag_success_medlong_loan=0 AND flag_success_medlong_housing=0\n",
            "     P=89.5%, R=99.4%, Cov=98.1%, K=2\n",
            "  3. flag_success_medlong_loan=0 AND flag_success_medlong_housing=0\n",
            "     P=89.5%, R=99.4%, Cov=98.1%, K=2\n",
            "  4. flag_success_medlong_month_late=0 AND flag_success_medlong_contact_not_cell=0\n",
            "     P=88.8%, R=99.8%, Cov=99.3%, K=2\n",
            "  5. flag_success_medlong_month_late=0 AND flag_success_medlong_contact_not_cell=0\n",
            "     P=88.8%, R=99.8%, Cov=99.3%, K=2\n",
            "\n",
            "ðŸ“Š Feature Usage:\n",
            "   flag_success_medlong_default:  6 ( 60.0%)\n",
            "   flag_success_medlong_job :  2 ( 20.0%)\n",
            "   flag_success_medlong_loan:  2 ( 20.0%)\n",
            "   flag_success_medlong_housing:  2 ( 20.0%)\n",
            "   flag_success_medlong_month_late:  2 ( 20.0%)\n",
            "   flag_success_medlong_contact_not_cell:  2 ( 20.0%)\n",
            "   duration_very_long       :  1 ( 10.0%)\n",
            "   duration_short           :  1 ( 10.0%)\n",
            "   poutcome_success         :  1 ( 10.0%)\n",
            "   flag_success_medlong_marital:  1 ( 10.0%)\n",
            "\n",
            "âš ï¸  Unused: {'month_summer_dead', 'duration_medium', 'flag_success_medlong_education', 'balance_mid', 'age_prime_working', 'duration_long', 'month_spring_lift', 'day_late', 'campaign_single', 'contact_not_cellular', 'month_may_volatile', 'age_senior', 'day_mid'}\n",
            "\n",
            "================================================================================\n",
            "âœ… COMPLETE\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I_nDxcAHi-RK"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 1: IMPORTS\n",
        "# ============================================================\n",
        "\n",
        "# ============================================================\n",
        "# CORE NUMERICAL & DATA HANDLING\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ============================================================\n",
        "# STATISTICAL TESTING\n",
        "# ============================================================\n",
        "from scipy import stats\n",
        "\n",
        "# ============================================================\n",
        "# SKLEARN: MODEL SELECTION & VALIDATION\n",
        "# ============================================================\n",
        "from sklearn.model_selection import (\n",
        "    StratifiedKFold,\n",
        "    train_test_split\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# SKLEARN: MODELS\n",
        "# ============================================================\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ============================================================\n",
        "# SKLEARN: METRICS & FEATURE IMPORTANCE\n",
        "# ============================================================\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    mutual_info_score\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# ============================================================\n",
        "# GRADIENT BOOSTING\n",
        "# ============================================================\n",
        "import xgboost as xgb\n",
        "\n",
        "# ============================================================\n",
        "# RULE / ILP / STRUCTURAL UTILITIES\n",
        "# ============================================================\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple, Set\n",
        "\n",
        "# ============================================================\n",
        "# WARNINGS CONTROL\n",
        "# ============================================================\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "LzxdT8_Mi-Oa",
        "outputId": "9f66b381-cc97-457a-c326-77b6f4a708f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (45211, 17)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 45211,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 18,\n        \"max\": 95,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          35,\n          34,\n          53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"housemaid\",\n          \"unemployed\",\n          \"management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"married\",\n          \"single\",\n          \"divorced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"secondary\",\n          \"primary\",\n          \"tertiary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"default\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3044,\n        \"min\": -8019,\n        \"max\": 102127,\n        \"num_unique_values\": 7168,\n        \"samples\": [\n          3276,\n          43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"unknown\",\n          \"cellular\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 31,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          1,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"apr\",\n          \"mar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 0,\n        \"max\": 4918,\n        \"num_unique_values\": 1573,\n        \"samples\": [\n          835,\n          1135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"campaign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 63,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          41,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdays\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100,\n        \"min\": -1,\n        \"max\": 871,\n        \"num_unique_values\": 559,\n        \"samples\": [\n          249,\n          551\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"previous\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 275,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          17,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"poutcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"failure\",\n          \"success\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1f5d9333-8862-4d6e-9cd3-53604d68d454\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>2143</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>technician</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>29</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1506</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>unknown</td>\n",
              "      <td>single</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f5d9333-8862-4d6e-9cd3-53604d68d454')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f5d9333-8862-4d6e-9cd3-53604d68d454 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f5d9333-8862-4d6e-9cd3-53604d68d454');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4a359cc3-cd78-406a-93f0-25d8150be7fb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a359cc3-cd78-406a-93f0-25d8150be7fb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4a359cc3-cd78-406a-93f0-25d8150be7fb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   age           job  marital  education default  balance housing loan  \\\n",
              "0   58    management  married   tertiary      no     2143     yes   no   \n",
              "1   44    technician   single  secondary      no       29     yes   no   \n",
              "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
              "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
              "4   33       unknown   single    unknown      no        1      no   no   \n",
              "\n",
              "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
              "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
              "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
              "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
              "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
              "4  unknown    5   may       198         1     -1         0  unknown  no  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 2: LOAD & INSPECT DATA\n",
        "# ============================================================\n",
        "\n",
        "# Load dataset\n",
        "path = \"/content/sample_data/bank-full.csv\"\n",
        "df = pd.read_csv(path, sep=\";\")\n",
        "\n",
        "print(f\"Shape: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "uxdTjI_qi-Li",
        "outputId": "e4f7346e-9a2b-4be2-893c-5ccfe1fe54b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Œ COLUMN SCHEMA\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"schema\",\n  \"rows\": 17,\n  \"fields\": [\n    {\n      \"column\": \"column\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"age\",\n          \"job\",\n          \"balance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dtype\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"object\",\n          \"int64\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_unique\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1746,\n        \"min\": 2,\n        \"max\": 7168,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          7168,\n          77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "schema"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-53e9efb8-1ff9-4a8e-8765-ee054de7ab4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column</th>\n",
              "      <th>dtype</th>\n",
              "      <th>n_unique</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>age</td>\n",
              "      <td>int64</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job</th>\n",
              "      <td>job</td>\n",
              "      <td>object</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marital</th>\n",
              "      <td>marital</td>\n",
              "      <td>object</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education</th>\n",
              "      <td>education</td>\n",
              "      <td>object</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>default</th>\n",
              "      <td>default</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>balance</th>\n",
              "      <td>balance</td>\n",
              "      <td>int64</td>\n",
              "      <td>7168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing</th>\n",
              "      <td>housing</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loan</th>\n",
              "      <td>loan</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contact</th>\n",
              "      <td>contact</td>\n",
              "      <td>object</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day</th>\n",
              "      <td>day</td>\n",
              "      <td>int64</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>month</td>\n",
              "      <td>object</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>duration</td>\n",
              "      <td>int64</td>\n",
              "      <td>1573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>campaign</th>\n",
              "      <td>campaign</td>\n",
              "      <td>int64</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pdays</th>\n",
              "      <td>pdays</td>\n",
              "      <td>int64</td>\n",
              "      <td>559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>previous</th>\n",
              "      <td>previous</td>\n",
              "      <td>int64</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poutcome</th>\n",
              "      <td>poutcome</td>\n",
              "      <td>object</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y</th>\n",
              "      <td>y</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53e9efb8-1ff9-4a8e-8765-ee054de7ab4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53e9efb8-1ff9-4a8e-8765-ee054de7ab4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53e9efb8-1ff9-4a8e-8765-ee054de7ab4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-02543671-612b-4a91-ac6f-7e4a9da6dcd4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02543671-612b-4a91-ac6f-7e4a9da6dcd4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-02543671-612b-4a91-ac6f-7e4a9da6dcd4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5023fe54-94c8-4156-9e90-6353f4344f41\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('schema')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5023fe54-94c8-4156-9e90-6353f4344f41 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('schema');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              column   dtype  n_unique\n",
              "age              age   int64        77\n",
              "job              job  object        12\n",
              "marital      marital  object         3\n",
              "education  education  object         4\n",
              "default      default  object         2\n",
              "balance      balance   int64      7168\n",
              "housing      housing  object         2\n",
              "loan            loan  object         2\n",
              "contact      contact  object         3\n",
              "day              day   int64        31\n",
              "month          month  object        12\n",
              "duration    duration   int64      1573\n",
              "campaign    campaign   int64        48\n",
              "pdays          pdays   int64       559\n",
              "previous    previous   int64        41\n",
              "poutcome    poutcome  object         4\n",
              "y                  y  object         2"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 3: CHECK INPUT TYPES\n",
        "# ============================================================\n",
        "print(\"ðŸ“Œ COLUMN SCHEMA\\n\" + \"-\"*60)\n",
        "schema = pd.DataFrame({\n",
        "    \"column\": df.columns,\n",
        "    \"dtype\": df.dtypes.astype(str),\n",
        "    \"n_unique\": [df[c].nunique() for c in df.columns]\n",
        "})\n",
        "schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTkyZXboi-I7",
        "outputId": "acec2bf8-17f3-4fda-f974-6cfe41e1060b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Œ CATEGORICAL COLUMNS\n",
            "------------------------------------------------------------\n",
            "\n",
            "ðŸ”Ž Column: job\n",
            "----------------------------------------\n",
            "job\n",
            "admin.           5171\n",
            "blue-collar      9732\n",
            "entrepreneur     1487\n",
            "housemaid        1240\n",
            "management       9458\n",
            "retired          2264\n",
            "self-employed    1579\n",
            "services         4154\n",
            "student           938\n",
            "technician       7597\n",
            "unemployed       1303\n",
            "unknown           288\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: marital\n",
            "----------------------------------------\n",
            "marital\n",
            "divorced     5207\n",
            "married     27214\n",
            "single      12790\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: education\n",
            "----------------------------------------\n",
            "education\n",
            "primary       6851\n",
            "secondary    23202\n",
            "tertiary     13301\n",
            "unknown       1857\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: default\n",
            "----------------------------------------\n",
            "default\n",
            "no     44396\n",
            "yes      815\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: housing\n",
            "----------------------------------------\n",
            "housing\n",
            "no     20081\n",
            "yes    25130\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: loan\n",
            "----------------------------------------\n",
            "loan\n",
            "no     37967\n",
            "yes     7244\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: contact\n",
            "----------------------------------------\n",
            "contact\n",
            "cellular     29285\n",
            "telephone     2906\n",
            "unknown      13020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: month\n",
            "----------------------------------------\n",
            "month\n",
            "apr     2932\n",
            "aug     6247\n",
            "dec      214\n",
            "feb     2649\n",
            "jan     1403\n",
            "jul     6895\n",
            "jun     5341\n",
            "mar      477\n",
            "may    13766\n",
            "nov     3970\n",
            "oct      738\n",
            "sep      579\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: poutcome\n",
            "----------------------------------------\n",
            "poutcome\n",
            "failure     4901\n",
            "other       1840\n",
            "success     1511\n",
            "unknown    36959\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ”Ž Column: y\n",
            "----------------------------------------\n",
            "y\n",
            "no     39922\n",
            "yes     5289\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 4: EXAMINE CATAGORICAL COLUMNS\n",
        "# ============================================================\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "print(\"ðŸ“Œ CATEGORICAL COLUMNS\\n\" + \"-\"*60)\n",
        "categorical_cols\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nðŸ”Ž Column: {col}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    values = (\n",
        "        df[col]\n",
        "        .astype(str)\n",
        "        .value_counts(dropna=False)\n",
        "        .sort_index()\n",
        "    )\n",
        "\n",
        "    print(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK152GH4i-GD",
        "outputId": "8f69ad3e-2f8a-49a2-e4b4-81dcf3d7f021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸ”§ CLEAN PREPROCESSING\n",
            "================================================================================\n",
            "\n",
            "Original data shape: (45211, 17)\n",
            "Columns: ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
            "\n",
            "========================================\n",
            "1. CREATING CLEAN df_proc\n",
            "========================================\n",
            "\n",
            "Initial shape: (45211, 17)\n",
            "Columns: ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
            "\n",
            "ðŸ” Target column 'y' before conversion:\n",
            "y\n",
            "no     39922\n",
            "yes     5289\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… Target 'y' converted:\n",
            "y\n",
            "0    39922\n",
            "1     5289\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ” Binary columns before conversion:\n",
            "default:\n",
            "default\n",
            "no     44396\n",
            "yes      815\n",
            "Name: count, dtype: int64\n",
            "housing:\n",
            "housing\n",
            "yes    25130\n",
            "no     20081\n",
            "Name: count, dtype: int64\n",
            "loan:\n",
            "loan\n",
            "no     37967\n",
            "yes     7244\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… Binary columns converted:\n",
            "default: [0 1]\n",
            "housing: [1 0]\n",
            "loan: [0 1]\n",
            "\n",
            "ðŸ” Month column before conversion:\n",
            "month\n",
            "apr     2932\n",
            "aug     6247\n",
            "dec      214\n",
            "feb     2649\n",
            "jan     1403\n",
            "jul     6895\n",
            "jun     5341\n",
            "mar      477\n",
            "may    13766\n",
            "nov     3970\n",
            "oct      738\n",
            "sep      579\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… Month converted to ordinal and raw month dropped\n",
            "\n",
            "ðŸ” poutcome column before conversion:\n",
            "poutcome\n",
            "unknown    36959\n",
            "failure     4901\n",
            "other       1840\n",
            "success     1511\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… poutcome converted:\n",
            "poutcome\n",
            "0    36959\n",
            "1     4901\n",
            "2     1840\n",
            "3     1511\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ” contact column before conversion:\n",
            "contact\n",
            "cellular     29285\n",
            "unknown      13020\n",
            "telephone     2906\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… contact converted to ordinal (0=cellular, 1=telephone, 2=unknown):\n",
            "contact\n",
            "0    29285\n",
            "1     2906\n",
            "2    13020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ” Ordinal-encoding remaining categoricals:\n",
            "['job', 'marital', 'education']\n",
            "\n",
            "âœ… ALL COLUMNS ARE NUMERIC\n",
            "\n",
            "ðŸ“Š Data types in df_proc:\n",
            "int64: ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
            "int16: ['job', 'marital', 'education']\n",
            "int8: ['default', 'housing', 'loan', 'contact', 'poutcome', 'y', 'month_ordinal']\n",
            "\n",
            "ðŸ” Checking for null values:\n",
            "âœ… No null values\n",
            "\n",
            "ðŸ” Checking for duplicates:\n",
            "Exact duplicate rows: 0 (0.00%)\n",
            "\n",
            "âœ… df_proc created successfully!\n",
            "Shape: (45211, 17)\n",
            "Memory usage: 2.98 MB\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 5: PREPROCESSING\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ”§ CLEAN PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nOriginal data shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. CREATE CLEAN df_proc FRAME\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"1. CREATING CLEAN df_proc\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "df_proc = df.copy()\n",
        "\n",
        "print(f\"\\nInitial shape: {df_proc.shape}\")\n",
        "print(f\"Columns: {list(df_proc.columns)}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.1 Target encoding\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ” Target column 'y' before conversion:\")\n",
        "print(df_proc['y'].value_counts())\n",
        "\n",
        "df_proc['y'] = df_proc['y'].map({'yes': 1, 'no': 0})\n",
        "assert df_proc['y'].notna().all(), \"âŒ Unexpected values in target y\"\n",
        "df_proc['y'] = df_proc['y'].astype('int8')\n",
        "\n",
        "print(f\"\\nâœ… Target 'y' converted:\")\n",
        "print(df_proc['y'].value_counts())\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.2 Binary categorical encoding\n",
        "# --------------------------------------------------\n",
        "binary_cols = ['default', 'housing', 'loan']\n",
        "binary_map = {'no': 0, 'yes': 1}\n",
        "\n",
        "print(f\"\\nðŸ” Binary columns before conversion:\")\n",
        "for col in binary_cols:\n",
        "    print(f\"{col}:\\n{df_proc[col].value_counts()}\")\n",
        "\n",
        "for col in binary_cols:\n",
        "    df_proc[col] = df_proc[col].map(binary_map)\n",
        "    assert df_proc[col].notna().all(), f\"âŒ Unexpected values in {col}\"\n",
        "    df_proc[col] = df_proc[col].astype('int8')\n",
        "\n",
        "print(f\"\\nâœ… Binary columns converted:\")\n",
        "for col in binary_cols:\n",
        "    print(f\"{col}: {df_proc[col].unique()}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.3 Month â†’ ordinal (DROP RAW MONTH)\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ” Month column before conversion:\")\n",
        "print(df_proc['month'].value_counts().sort_index())\n",
        "\n",
        "month_map = {\n",
        "    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4,\n",
        "    'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,\n",
        "    'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
        "}\n",
        "\n",
        "df_proc['month_ordinal'] = df_proc['month'].map(month_map)\n",
        "assert df_proc['month_ordinal'].notna().all(), \"âŒ Unexpected month values\"\n",
        "df_proc['month_ordinal'] = df_proc['month_ordinal'].astype('int8')\n",
        "\n",
        "# DROP raw month (no objects allowed)\n",
        "df_proc.drop(columns=['month'], inplace=True)\n",
        "\n",
        "print(f\"\\nâœ… Month converted to ordinal and raw month dropped\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.4 POUTCOME - EXPLICIT MAPPING\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ” poutcome column before conversion:\")\n",
        "print(df_proc['poutcome'].value_counts())\n",
        "\n",
        "poutcome_map = {\n",
        "    'unknown': 0,\n",
        "    'failure': 1,\n",
        "    'other': 2,\n",
        "    'success': 3\n",
        "}\n",
        "\n",
        "df_proc['poutcome'] = df_proc['poutcome'].map(poutcome_map)\n",
        "assert df_proc['poutcome'].notna().all(), \"âŒ Unexpected poutcome values\"\n",
        "df_proc['poutcome'] = df_proc['poutcome'].astype('int8')\n",
        "\n",
        "print(f\"\\nâœ… poutcome converted:\")\n",
        "print(df_proc['poutcome'].value_counts())\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.5 CONTACT - ORDINAL MAPPING\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ” contact column before conversion:\")\n",
        "print(df_proc['contact'].value_counts())\n",
        "\n",
        "# Map contact as ORDINAL: cellular=0, telephone=1, unknown=2\n",
        "contact_map = {\n",
        "    'cellular': 0,\n",
        "    'telephone': 1,\n",
        "    'unknown': 2\n",
        "}\n",
        "\n",
        "df_proc['contact'] = df_proc['contact'].map(contact_map)\n",
        "assert df_proc['contact'].notna().all(), \"âŒ Unexpected contact values\"\n",
        "df_proc['contact'] = df_proc['contact'].astype('int8')\n",
        "\n",
        "print(f\"\\nâœ… contact converted to ordinal (0=cellular, 1=telephone, 2=unknown):\")\n",
        "print(df_proc['contact'].value_counts().sort_index())\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.6 Ordinal / Label encoding REMAINING categoricals\n",
        "# --------------------------------------------------\n",
        "categorical_cols = df_proc.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f\"\\nðŸ” Ordinal-encoding remaining categoricals:\")\n",
        "print(categorical_cols)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df_proc[col] = df_proc[col].astype('category').cat.codes\n",
        "    df_proc[col] = df_proc[col].astype('int16')\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.7 HARD TYPE GUARANTEE\n",
        "# --------------------------------------------------\n",
        "non_numeric = df_proc.select_dtypes(exclude=['number']).columns.tolist()\n",
        "assert len(non_numeric) == 0, f\"âŒ NON-NUMERIC COLUMNS REMAIN: {non_numeric}\"\n",
        "\n",
        "print(\"\\nâœ… ALL COLUMNS ARE NUMERIC\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.8 Sanity checks\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nðŸ“Š Data types in df_proc:\")\n",
        "for dtype in df_proc.dtypes.unique():\n",
        "    cols = df_proc.columns[df_proc.dtypes == dtype].tolist()\n",
        "    print(f\"{dtype}: {cols}\")\n",
        "\n",
        "print(f\"\\nðŸ” Checking for null values:\")\n",
        "assert df_proc.isnull().sum().sum() == 0, \"âŒ Nulls detected\"\n",
        "print(\"âœ… No null values\")\n",
        "\n",
        "print(f\"\\nðŸ” Checking for duplicates:\")\n",
        "dup_count = df_proc.duplicated().sum()\n",
        "print(f\"Exact duplicate rows: {dup_count} ({dup_count/len(df_proc)*100:.2f}%)\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1.9 Final confirmation\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nâœ… df_proc created successfully!\")\n",
        "print(f\"Shape: {df_proc.shape}\")\n",
        "print(f\"Memory usage: {df_proc.memory_usage().sum() / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5ltsAxF-ab9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC9boetn-WzO",
        "outputId": "a186b3e4-056f-4963-ecec-0c24aa9a9262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/4.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m178.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m780.1/780.1 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m264.7/264.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for dash-cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install interpret -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sypoxf-8jAX",
        "outputId": "88d0cf30-4b2b-4155-ed42-9665a1f32665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ META-EBM (STAGE 4) - FINAL CASCADE ASSEMBLY\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "ðŸ“‚ 1. LOADING STAGE 1-3 MODELS\n",
            "============================================================\n",
            "\n",
            "ðŸ”¹ Loading Logistic Regression (Stage 1)...\n",
            "âœ… LR model loaded\n",
            "\n",
            "ðŸ”¹ Loading GLASS-BRW (Stage 2)...\n",
            "âœ… GLASS-BRW model loaded - 7 rules\n",
            "âœ… RF model extracted\n",
            "\n",
            "ðŸ”¹ Loading EBM (Stage 3)...\n",
            "âœ… EBM model loaded\n",
            "\n",
            "============================================================\n",
            "ðŸ”§ 2. EXTRACTING PREDICTIONS FROM TRAINED MODELS\n",
            "============================================================\n",
            "âœ… LR predictions extracted from saved model:\n",
            "  Train: (36168,) - mean: 0.3306\n",
            "  Test:  (9043,) - mean: 0.3316\n",
            "âœ… EBM predictions extracted from saved model:\n",
            "  Train: (36168,) - mean: 0.1170\n",
            "  Test:  (9043,) - mean: 0.1157\n",
            "\n",
            "âœ… Consistent split verified:\n",
            "  Train samples: 36168\n",
            "  Test samples: 9043\n",
            "\n",
            "============================================================\n",
            "ðŸŽ² 3. GENERATING GLASS-BRW PREDICTIONS\n",
            "============================================================\n",
            "âœ… Recreated original train/test split\n",
            "  Train: (36168, 16)\n",
            "  Test:  (9043, 16)\n",
            "\n",
            "============================================================\n",
            "ðŸ”¨ 4. ENGINEERING FEATURES FOR GLASS-BRW\n",
            "============================================================\n",
            "âœ… GLASS predictions generated:\n",
            "  Train: (36168,) - mean: 0.0993\n",
            "  Test:  (9043,) - mean: 0.1002\n",
            "\n",
            "============================================================\n",
            "ðŸ”¨ 5. CREATING META-FEATURES\n",
            "============================================================\n",
            "âœ… All models have predictions on same split:\n",
            "  Train: 36168 samples\n",
            "  Test:  9043 samples\n",
            "\n",
            "ðŸ“Š Stage prediction means:\n",
            "  LR:    train=0.3306, test=0.3316\n",
            "  GLASS: train=0.0993, test=0.1002\n",
            "  EBM:   train=0.1170, test=0.1157\n",
            "âœ… Meta-features: (36168, 9)\n",
            "   Features: ['lr_prob', 'rf_prob', 'ebm_prob', 'lr_rf_diff', 'lr_ebm_diff', 'rf_ebm_diff', 'max_confidence', 'min_confidence', 'std_confidence']\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¯ 6. TRAINING META-EBM (10-FOLD CV)\n",
            "============================================================\n",
            "âœ… Meta-EBM trained!\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š 7. EVALUATION\n",
            "============================================================\n",
            "\n",
            "ðŸŽ¯ META-EBM PERFORMANCE:\n",
            "  Accuracy:  0.9079\n",
            "  Precision: 0.6295\n",
            "  Recall:    0.5170\n",
            "  F1-Score:  0.5677\n",
            "  ROC-AUC:   0.9273\n",
            "\n",
            "Confusion Matrix:\n",
            "[[7663  322]\n",
            " [ 511  547]]\n",
            "\n",
            "âœ… Saved: /content/meta_ebm_cascade_checkpoint_20251220_231532.pkl\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ‰ 4-STAGE CASCADE COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL: META-EBM (STAGE 4) - COMPLETE IMPLEMENTATION\n",
        "# Includes all necessary class definitions for unpickling\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ¯ META-EBM (STAGE 4) - FINAL CASCADE ASSEMBLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from interpret.glassbox import ExplainableBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass\n",
        "from typing import Set, Tuple, List, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. LOAD ALL STAGE MODELS\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‚ 1. LOADING STAGE 1-3 MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Stage 1: Logistic Regression (load from dict)\n",
        "print(\"\\nðŸ”¹ Loading Logistic Regression (Stage 1)...\")\n",
        "lr_ensemble_dict = joblib.load('/content/lr_ensemble_joblib_20251220_203823.joblib')\n",
        "lr_model = lr_ensemble_dict['model']\n",
        "print(f\"âœ… LR model loaded\")\n",
        "\n",
        "# Stage 2: GLASS-BRW\n",
        "print(\"\\nðŸ”¹ Loading GLASS-BRW (Stage 2)...\")\n",
        "with open('/content/glass_brw_rf_checkpoint_20251220_211009.pkl', 'rb') as f:\n",
        "    glass_model = pickle.load(f)\n",
        "print(f\"âœ… GLASS-BRW model loaded - {len(glass_model.rules)} rules\")\n",
        "\n",
        "# Extract RF model\n",
        "rf_model = glass_model.rf_model\n",
        "print(f\"âœ… RF model extracted\")\n",
        "\n",
        "# Stage 3: EBM (load from dict)\n",
        "print(\"\\nðŸ”¹ Loading EBM (Stage 3)...\")\n",
        "ebm_ensemble_dict = joblib.load('/content/ebm_ensemble_joblib_20251220_223007.joblib')\n",
        "ebm_model = ebm_ensemble_dict['model']\n",
        "print(f\"âœ… EBM model loaded\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. PREPARE DATA - USE PREDICTIONS FROM SAVED MODELS\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”§ 2. EXTRACTING PREDICTIONS FROM TRAINED MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# The models were already trained on specific train/test splits\n",
        "# We need to use THEIR predictions, not generate new ones\n",
        "\n",
        "# Stage 1: LR predictions (already computed during training)\n",
        "lr_X_train = lr_ensemble_dict['train_predictions']\n",
        "lr_X_test = lr_ensemble_dict['test_predictions']\n",
        "y_train = lr_ensemble_dict['train_labels']\n",
        "y_test = lr_ensemble_dict['test_labels']\n",
        "\n",
        "print(f\"âœ… LR predictions extracted from saved model:\")\n",
        "print(f\"  Train: {lr_X_train.shape} - mean: {lr_X_train.mean():.4f}\")\n",
        "print(f\"  Test:  {lr_X_test.shape} - mean: {lr_X_test.mean():.4f}\")\n",
        "\n",
        "# Stage 3: EBM predictions (already computed during training)\n",
        "ebm_X_train = ebm_ensemble_dict['train_predictions']\n",
        "ebm_X_test = ebm_ensemble_dict['test_predictions']\n",
        "\n",
        "print(f\"âœ… EBM predictions extracted from saved model:\")\n",
        "print(f\"  Train: {ebm_X_train.shape} - mean: {ebm_X_train.mean():.4f}\")\n",
        "print(f\"  Test:  {ebm_X_test.shape} - mean: {ebm_X_test.mean():.4f}\")\n",
        "\n",
        "# Verify shapes match\n",
        "assert len(lr_X_train) == len(ebm_X_train), \"Train set size mismatch!\"\n",
        "assert len(lr_X_test) == len(ebm_X_test), \"Test set size mismatch!\"\n",
        "\n",
        "print(f\"\\nâœ… Consistent split verified:\")\n",
        "print(f\"  Train samples: {len(lr_X_train)}\")\n",
        "print(f\"  Test samples: {len(lr_X_test)}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. GENERATE GLASS-BRW PREDICTIONS ON SAME SPLIT\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ² 3. GENERATING GLASS-BRW PREDICTIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# We need to regenerate GLASS predictions on the SAME split\n",
        "# First, get the original data and recreate the exact split\n",
        "X_all = df_proc.drop(columns=['y'])\n",
        "y_all = df_proc['y']\n",
        "\n",
        "# Use the same split as LR/EBM (they used random_state=42, test_size=0.2)\n",
        "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(\n",
        "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "# Verify this matches our saved predictions\n",
        "assert len(X_train_orig) == len(lr_X_train), \"Train split doesn't match!\"\n",
        "assert len(X_test_orig) == len(lr_X_test), \"Test split doesn't match!\"\n",
        "\n",
        "print(f\"âœ… Recreated original train/test split\")\n",
        "print(f\"  Train: {X_train_orig.shape}\")\n",
        "print(f\"  Test:  {X_test_orig.shape}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. ENGINEER FEATURES FOR GLASS-BRW\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”¨ 4. ENGINEERING FEATURES FOR GLASS-BRW\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def engineer_features_bank(df_proc: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df_proc.copy()\n",
        "    df[\"dur_low\"]  = (df[\"duration\"] <= 200).astype(\"int8\")\n",
        "    df[\"dur_mid\"]  = ((df[\"duration\"] > 200) & (df[\"duration\"] <= 300)).astype(\"int8\")\n",
        "    df[\"dur_high\"] = (df[\"duration\"] > 300).astype(\"int8\")\n",
        "    df[\"pdays_never\"] = (df[\"pdays\"] <= 0).astype(\"int8\")\n",
        "    df[\"pdays_1_5\"]   = ((df[\"pdays\"] > 0) & (df[\"pdays\"] <= 5)).astype(\"int8\")\n",
        "    df[\"month_early\"]      = df[\"month_ordinal\"].isin([1, 2, 3, 4]).astype(\"int8\")\n",
        "    df[\"month_late_spring\"] = df[\"month_ordinal\"].isin([5, 6]).astype(\"int8\")\n",
        "    df[\"month_summer\"]     = df[\"month_ordinal\"].isin([7, 8]).astype(\"int8\")\n",
        "    df[\"month_fall\"]       = df[\"month_ordinal\"].isin([9, 10]).astype(\"int8\")\n",
        "    df[\"month_year_end\"]   = df[\"month_ordinal\"].isin([11, 12]).astype(\"int8\")\n",
        "    df[\"previous_ge1\"] = (df[\"previous\"] >= 1).astype(\"int8\")\n",
        "    df[\"engagement_score\"] = (\n",
        "        df[\"previous_ge1\"] + df[\"pdays_1_5\"] + df[\"dur_high\"] + (df[\"poutcome\"] == 3).astype(\"int8\")\n",
        "    ).astype(\"int8\")\n",
        "    df[\"fatigue_score\"] = (\n",
        "        (df[\"campaign\"] >= 5).astype(\"int8\") + (df[\"campaign\"] >= 8).astype(\"int8\") +\n",
        "        df[\"dur_low\"] + df[\"pdays_never\"]\n",
        "    ).astype(\"int8\")\n",
        "\n",
        "    df_eng = pd.DataFrame(index=df.index)\n",
        "    df_eng[\"dur_low\"]  = df[\"dur_low\"]\n",
        "    df_eng[\"dur_mid\"]  = df[\"dur_mid\"]\n",
        "    df_eng[\"dur_high\"] = df[\"dur_high\"]\n",
        "    df_eng[\"month_summer\"]   = df[\"month_summer\"]\n",
        "    df_eng[\"month_fall\"]     = df[\"month_fall\"]\n",
        "    df_eng[\"month_year_end\"] = df[\"month_year_end\"]\n",
        "    df_eng[\"month_early\"] = df[\"month_early\"]\n",
        "    df_eng[\"month_late_spring\"] = df[\"month_late_spring\"]\n",
        "    df_eng[\"engagement_low\"] = (df[\"engagement_score\"] <= 1).astype(\"int8\")\n",
        "    df_eng[\"fatigue_low\"]    = (df[\"fatigue_score\"] <= 1).astype(\"int8\")\n",
        "    df_eng[\"housing\"]          = df[\"housing\"].astype(\"int8\")\n",
        "    df_eng[\"poutcome_success\"] = (df[\"poutcome\"] == 3).astype(\"int8\")\n",
        "    df_eng[\"pdays_never\"]      = df[\"pdays_never\"]\n",
        "    return df_eng\n",
        "\n",
        "X_train_glass = engineer_features_bank(X_train_orig.copy())\n",
        "X_test_glass = engineer_features_bank(X_test_orig.copy())\n",
        "\n",
        "glass_X_train = glass_model.predict_proba(X_train_glass)[:, 1]\n",
        "glass_X_test = glass_model.predict_proba(X_test_glass)[:, 1]\n",
        "\n",
        "print(f\"âœ… GLASS predictions generated:\")\n",
        "print(f\"  Train: {glass_X_train.shape} - mean: {glass_X_train.mean():.4f}\")\n",
        "print(f\"  Test:  {glass_X_test.shape} - mean: {glass_X_test.mean():.4f}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5. CREATE META-FEATURES (NO DATA LEAKAGE)\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”¨ 5. CREATING META-FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verify all predictions are on the same samples\n",
        "assert len(lr_X_train) == len(glass_X_train) == len(ebm_X_train), \"Train size mismatch!\"\n",
        "assert len(lr_X_test) == len(glass_X_test) == len(ebm_X_test), \"Test size mismatch!\"\n",
        "\n",
        "print(f\"âœ… All models have predictions on same split:\")\n",
        "print(f\"  Train: {len(lr_X_train)} samples\")\n",
        "print(f\"  Test:  {len(lr_X_test)} samples\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Stage prediction means:\")\n",
        "print(f\"  LR:    train={lr_X_train.mean():.4f}, test={lr_X_test.mean():.4f}\")\n",
        "print(f\"  GLASS: train={glass_X_train.mean():.4f}, test={glass_X_test.mean():.4f}\")\n",
        "print(f\"  EBM:   train={ebm_X_train.mean():.4f}, test={ebm_X_test.mean():.4f}\")\n",
        "\n",
        "meta_train = pd.DataFrame({\n",
        "    'lr_prob': lr_X_train,\n",
        "    'rf_prob': glass_X_train,\n",
        "    'ebm_prob': ebm_X_train\n",
        "})\n",
        "\n",
        "meta_test = pd.DataFrame({\n",
        "    'lr_prob': lr_X_test,\n",
        "    'rf_prob': glass_X_test,\n",
        "    'ebm_prob': ebm_X_test\n",
        "})\n",
        "\n",
        "# Disagreement signals\n",
        "meta_train['lr_rf_diff'] = np.abs(meta_train['lr_prob'] - meta_train['rf_prob'])\n",
        "meta_train['lr_ebm_diff'] = np.abs(meta_train['lr_prob'] - meta_train['ebm_prob'])\n",
        "meta_train['rf_ebm_diff'] = np.abs(meta_train['rf_prob'] - meta_train['ebm_prob'])\n",
        "\n",
        "meta_test['lr_rf_diff'] = np.abs(meta_test['lr_prob'] - meta_test['rf_prob'])\n",
        "meta_test['lr_ebm_diff'] = np.abs(meta_test['lr_prob'] - meta_test['ebm_prob'])\n",
        "meta_test['rf_ebm_diff'] = np.abs(meta_test['rf_prob'] - meta_test['ebm_prob'])\n",
        "\n",
        "# Confidence geometry\n",
        "P_train = meta_train[['lr_prob', 'rf_prob', 'ebm_prob']].values\n",
        "meta_train['max_confidence'] = P_train.max(axis=1)\n",
        "meta_train['min_confidence'] = P_train.min(axis=1)\n",
        "meta_train['std_confidence'] = P_train.std(axis=1)\n",
        "\n",
        "P_test = meta_test[['lr_prob', 'rf_prob', 'ebm_prob']].values\n",
        "meta_test['max_confidence'] = P_test.max(axis=1)\n",
        "meta_test['min_confidence'] = P_test.min(axis=1)\n",
        "meta_test['std_confidence'] = P_test.std(axis=1)\n",
        "\n",
        "print(f\"âœ… Meta-features: {meta_train.shape}\")\n",
        "print(f\"   Features: {list(meta_train.columns)}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 6. TRAIN META-EBM\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ¯ 6. TRAINING META-EBM (10-FOLD CV)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "meta_ebm = ExplainableBoostingClassifier(\n",
        "    max_bins=16,\n",
        "    max_interaction_bins=8,\n",
        "    interactions=5,\n",
        "    outer_bags=10,\n",
        "    inner_bags=0,\n",
        "    learning_rate=0.01,\n",
        "    min_samples_leaf=5,\n",
        "    max_leaves=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "meta_ebm.fit(meta_train, y_train)\n",
        "print(\"âœ… Meta-EBM trained!\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 7. EVALUATE\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š 7. EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "meta_pred_test = meta_ebm.predict_proba(meta_test)[:, 1]\n",
        "meta_pred_test_class = (meta_pred_test >= 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, meta_pred_test_class)\n",
        "precision = precision_score(y_test, meta_pred_test_class)\n",
        "recall = recall_score(y_test, meta_pred_test_class)\n",
        "f1 = f1_score(y_test, meta_pred_test_class)\n",
        "roc_auc = roc_auc_score(y_test, meta_pred_test)\n",
        "\n",
        "print(f\"\\nðŸŽ¯ META-EBM PERFORMANCE:\")\n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "print(f\"  F1-Score:  {f1:.4f}\")\n",
        "print(f\"  ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, meta_pred_test_class)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 9. SAVE\n",
        "# --------------------------------------------------\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "checkpoint = {\n",
        "    'meta_ebm_model': meta_ebm,\n",
        "    'performance': {'accuracy': accuracy, 'precision': precision, 'recall': recall,\n",
        "                   'f1_score': f1, 'roc_auc': roc_auc},\n",
        "    'training_date': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "filename = f\"/content/meta_ebm_cascade_checkpoint_{timestamp}.pkl\"\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(checkpoint, f)\n",
        "\n",
        "print(f\"\\nâœ… Saved: {filename}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ‰ 4-STAGE CASCADE COMPLETE!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGn-7_5D8i9n",
        "outputId": "134ce5d5-a888-4a86-a8ce-5ffb359892f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ META-EBM (STAGE 4) - FINAL CASCADE ASSEMBLY\n",
            "================================================================================\n",
            "âœ… Class definitions loaded\n",
            "\n",
            "============================================================\n",
            "ðŸ“‚ 1. LOADING STAGE 1-3 MODELS\n",
            "============================================================\n",
            "âœ… LR model loaded\n",
            "âœ… GLASS-BRW model loaded (7 rules)\n",
            "âœ… EBM model loaded\n",
            "\n",
            "============================================================\n",
            "ðŸ”§ 2. CREATING SINGLE TRAIN/TEST SPLIT\n",
            "============================================================\n",
            "âœ… Single split created:\n",
            "  Train: (36168, 16) samples\n",
            "  Test:  (9043, 16) samples\n",
            "  Train positives: 0.1170\n",
            "  Test positives:  0.1170\n",
            "\n",
            "============================================================\n",
            "ðŸŽ² 3. GENERATING PREDICTIONS FROM ALL STAGES\n",
            "============================================================\n",
            "\n",
            "ðŸ”¹ Stage 1: Logistic Regression\n",
            "  Train: mean=0.3306, std=0.2785\n",
            "  Test:  mean=0.3316, std=0.2785\n",
            "\n",
            "ðŸ”¹ Stage 2: GLASS-BRW\n",
            "  Train: mean=0.0993, std=0.1171\n",
            "  Test:  mean=0.1002, std=0.1191\n",
            "\n",
            "ðŸ”¹ Stage 3: EBM\n",
            "  Train: mean=0.1170, std=0.2092\n",
            "  Test:  mean=0.1157, std=0.2064\n",
            "\n",
            "âœ… All models have predictions on same 36168 train / 9043 test samples\n",
            "\n",
            "============================================================\n",
            "ðŸ”¨ 4. CREATING META-FEATURES\n",
            "============================================================\n",
            "âœ… Meta-features created: (36168, 9)\n",
            "   Features: ['lr_prob', 'rf_prob', 'ebm_prob', 'lr_rf_diff', 'lr_ebm_diff', 'rf_ebm_diff', 'max_confidence', 'min_confidence', 'std_confidence']\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¯ 5. TRAINING META-EBM (10-FOLD CV)\n",
            "============================================================\n",
            "âœ… Meta-EBM trained!\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š 6. META-EBM EVALUATION\n",
            "============================================================\n",
            "\n",
            "ðŸŽ¯ META-EBM PERFORMANCE:\n",
            "  Accuracy:  0.9079\n",
            "  Precision: 0.6295\n",
            "  Recall:    0.5170\n",
            "  F1-Score:  0.5677\n",
            "  ROC-AUC:   0.9273\n",
            "\n",
            "Confusion Matrix:\n",
            "[[7663  322]\n",
            " [ 511  547]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "No Subscribe       0.94      0.96      0.95      7985\n",
            "   Subscribe       0.63      0.52      0.57      1058\n",
            "\n",
            "    accuracy                           0.91      9043\n",
            "   macro avg       0.78      0.74      0.76      9043\n",
            "weighted avg       0.90      0.91      0.90      9043\n",
            "\n",
            "\n",
            "âœ… Saved: /content/meta_ebm_cascade_checkpoint_20251220_232200.pkl\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ‰ 4-STAGE CASCADE COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL: META-EBM (STAGE 4) - PROPER DATA SPLIT\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ¯ META-EBM (STAGE 4) - FINAL CASCADE ASSEMBLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from interpret.glassbox import ExplainableBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass\n",
        "from typing import Set, Tuple, List, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "# Execute class definitions for unpickling\n",
        "exec(\"\"\"\n",
        "@dataclass\n",
        "class Rule:\n",
        "    rule_id: int\n",
        "    segment: Set[Tuple[str, str]]\n",
        "    predicted_class: int\n",
        "    complexity: int\n",
        "    precision: float = 0.0\n",
        "    recall: float = 0.0\n",
        "    coverage: float = 0.0\n",
        "    stability: float = 0.0\n",
        "    interpretability: float = 0.0\n",
        "    boundary_ambiguity: float = 0.0\n",
        "    rf_alignment: float = 0.0\n",
        "    def __hash__(self):\n",
        "        return hash((self.rule_id, frozenset(self.segment), self.predicted_class))\n",
        "    def __eq__(self, other):\n",
        "        return self.rule_id == other.rule_id\n",
        "\n",
        "class BankSegmentBuilder:\n",
        "    SEGMENT_FEATURES = [\n",
        "        \"dur_low\", \"dur_mid\", \"dur_high\",\n",
        "        \"month_early\", \"month_late_spring\", \"month_summer\", \"month_fall\", \"month_year_end\",\n",
        "        \"engagement_low\", \"fatigue_low\", \"poutcome_success\",\n",
        "        \"housing\", \"pdays_never\"\n",
        "    ]\n",
        "    def assign_segments(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        X = X.drop(columns=[\"y\", \"y_bin\"], errors=\"ignore\")\n",
        "        cols = [c for c in self.SEGMENT_FEATURES if c in X.columns]\n",
        "        if len(cols) == 0:\n",
        "            raise ValueError(\"No valid segment features found in input\")\n",
        "        segments = X[cols].copy()\n",
        "        for col in segments.columns:\n",
        "            vals = set(segments[col].dropna().unique())\n",
        "            if not vals.issubset({0, 1}):\n",
        "                raise ValueError(f\"Non-binary segment feature: {col} -> {vals}\")\n",
        "        return segments.astype(\"int8\")\n",
        "\n",
        "class RuleGenerator:\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class RuleEvaluator:\n",
        "    def __init__(self, segment_builder, min_support=30):\n",
        "        self.segment_builder = segment_builder\n",
        "        self.min_support = min_support\n",
        "\n",
        "class ILPRuleSelector:\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class GLASS_BRW:\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "        if not hasattr(self, 'segment_builder'):\n",
        "            self.segment_builder = BankSegmentBuilder()\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not hasattr(self, 'rules') or not self.rules:\n",
        "            n = len(X)\n",
        "            return np.column_stack([np.full(n, 0.5), np.full(n, 0.5)])\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            X = pd.DataFrame(X)\n",
        "\n",
        "        n = len(X)\n",
        "        predictions = np.full(n, -1, dtype=int)\n",
        "        confidences = np.zeros(n)\n",
        "\n",
        "        segments = self.segment_builder.assign_segments(X)\n",
        "\n",
        "        for i in range(n):\n",
        "            for rule in self.rules:\n",
        "                matches = True\n",
        "                for feature, level in rule.segment:\n",
        "                    if feature not in segments.columns:\n",
        "                        matches = False\n",
        "                        break\n",
        "                    if segments.iloc[i][feature] != level:\n",
        "                        matches = False\n",
        "                        break\n",
        "\n",
        "                if not matches:\n",
        "                    continue\n",
        "\n",
        "                predictions[i] = rule.predicted_class\n",
        "                confidences[i] = rule.precision\n",
        "                break\n",
        "\n",
        "        probas = np.zeros((n, 2))\n",
        "        for i in range(n):\n",
        "            if predictions[i] == -1:\n",
        "                probas[i] = [0.5, 0.5]\n",
        "            elif predictions[i] == 1:\n",
        "                probas[i] = [1 - confidences[i], confidences[i]]\n",
        "            else:\n",
        "                probas[i] = [confidences[i], 1 - confidences[i]]\n",
        "\n",
        "        return probas\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… Class definitions loaded\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. LOAD ALL MODELS\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‚ 1. LOADING STAGE 1-3 MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load LR\n",
        "lr_ensemble_dict = joblib.load('/content/lr_ensemble_joblib_20251220_203823.joblib')\n",
        "lr_model = lr_ensemble_dict['model']\n",
        "scaler = lr_ensemble_dict['scaler']\n",
        "print(f\"âœ… LR model loaded\")\n",
        "\n",
        "# Load GLASS-BRW\n",
        "with open('/content/glass_brw_rf_checkpoint_20251220_211009.pkl', 'rb') as f:\n",
        "    glass_model = pickle.load(f)\n",
        "rf_model = glass_model.rf_model\n",
        "print(f\"âœ… GLASS-BRW model loaded ({len(glass_model.rules)} rules)\")\n",
        "\n",
        "# Load EBM\n",
        "ebm_ensemble_dict = joblib.load('/content/ebm_ensemble_joblib_20251220_223007.joblib')\n",
        "ebm_model = ebm_ensemble_dict['model']\n",
        "print(f\"âœ… EBM model loaded\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. CREATE SINGLE TRAIN/TEST SPLIT FOR ALL MODELS\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”§ 2. CREATING SINGLE TRAIN/TEST SPLIT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Split the full dataset\n",
        "X_full = df_proc.drop(columns=['y'])\n",
        "y_full = df_proc['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
        ")\n",
        "\n",
        "print(f\"âœ… Single split created:\")\n",
        "print(f\"  Train: {X_train.shape} samples\")\n",
        "print(f\"  Test:  {X_test.shape} samples\")\n",
        "print(f\"  Train positives: {y_train.mean():.4f}\")\n",
        "print(f\"  Test positives:  {y_test.mean():.4f}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. GENERATE PREDICTIONS FROM ALL STAGES ON SAME SPLIT\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ² 3. GENERATING PREDICTIONS FROM ALL STAGES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Stage 1: Logistic Regression\n",
        "print(\"\\nðŸ”¹ Stage 1: Logistic Regression\")\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lr_X_train = lr_model.predict_proba(X_train_scaled)[:, 1]\n",
        "lr_X_test = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(f\"  Train: mean={lr_X_train.mean():.4f}, std={lr_X_train.std():.4f}\")\n",
        "print(f\"  Test:  mean={lr_X_test.mean():.4f}, std={lr_X_test.std():.4f}\")\n",
        "\n",
        "# Stage 2: GLASS-BRW (needs feature engineering)\n",
        "print(\"\\nðŸ”¹ Stage 2: GLASS-BRW\")\n",
        "\n",
        "def engineer_features_bank(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Engineer features for GLASS-BRW\"\"\"\n",
        "    d = df.copy()\n",
        "    d[\"dur_low\"] = (d[\"duration\"] <= 200).astype(\"int8\")\n",
        "    d[\"dur_mid\"] = ((d[\"duration\"] > 200) & (d[\"duration\"] <= 300)).astype(\"int8\")\n",
        "    d[\"dur_high\"] = (d[\"duration\"] > 300).astype(\"int8\")\n",
        "    d[\"pdays_never\"] = (d[\"pdays\"] <= 0).astype(\"int8\")\n",
        "    d[\"pdays_1_5\"] = ((d[\"pdays\"] > 0) & (d[\"pdays\"] <= 5)).astype(\"int8\")\n",
        "    d[\"month_early\"] = d[\"month_ordinal\"].isin([1, 2, 3, 4]).astype(\"int8\")\n",
        "    d[\"month_late_spring\"] = d[\"month_ordinal\"].isin([5, 6]).astype(\"int8\")\n",
        "    d[\"month_summer\"] = d[\"month_ordinal\"].isin([7, 8]).astype(\"int8\")\n",
        "    d[\"month_fall\"] = d[\"month_ordinal\"].isin([9, 10]).astype(\"int8\")\n",
        "    d[\"month_year_end\"] = d[\"month_ordinal\"].isin([11, 12]).astype(\"int8\")\n",
        "    d[\"previous_ge1\"] = (d[\"previous\"] >= 1).astype(\"int8\")\n",
        "    d[\"engagement_score\"] = (\n",
        "        d[\"previous_ge1\"] + d[\"pdays_1_5\"] + d[\"dur_high\"] + (d[\"poutcome\"] == 3).astype(\"int8\")\n",
        "    ).astype(\"int8\")\n",
        "    d[\"fatigue_score\"] = (\n",
        "        (d[\"campaign\"] >= 5).astype(\"int8\") + (d[\"campaign\"] >= 8).astype(\"int8\") +\n",
        "        d[\"dur_low\"] + d[\"pdays_never\"]\n",
        "    ).astype(\"int8\")\n",
        "\n",
        "    out = pd.DataFrame(index=d.index)\n",
        "    out[\"dur_low\"] = d[\"dur_low\"]\n",
        "    out[\"dur_mid\"] = d[\"dur_mid\"]\n",
        "    out[\"dur_high\"] = d[\"dur_high\"]\n",
        "    out[\"month_summer\"] = d[\"month_summer\"]\n",
        "    out[\"month_fall\"] = d[\"month_fall\"]\n",
        "    out[\"month_year_end\"] = d[\"month_year_end\"]\n",
        "    out[\"month_early\"] = d[\"month_early\"]\n",
        "    out[\"month_late_spring\"] = d[\"month_late_spring\"]\n",
        "    out[\"engagement_low\"] = (d[\"engagement_score\"] <= 1).astype(\"int8\")\n",
        "    out[\"fatigue_low\"] = (d[\"fatigue_score\"] <= 1).astype(\"int8\")\n",
        "    out[\"housing\"] = d[\"housing\"].astype(\"int8\")\n",
        "    out[\"poutcome_success\"] = (d[\"poutcome\"] == 3).astype(\"int8\")\n",
        "    out[\"pdays_never\"] = d[\"pdays_never\"]\n",
        "    return out\n",
        "\n",
        "X_train_glass = engineer_features_bank(X_train)\n",
        "X_test_glass = engineer_features_bank(X_test)\n",
        "\n",
        "glass_X_train = glass_model.predict_proba(X_train_glass)[:, 1]\n",
        "glass_X_test = glass_model.predict_proba(X_test_glass)[:, 1]\n",
        "\n",
        "print(f\"  Train: mean={glass_X_train.mean():.4f}, std={glass_X_train.std():.4f}\")\n",
        "print(f\"  Test:  mean={glass_X_test.mean():.4f}, std={glass_X_test.std():.4f}\")\n",
        "\n",
        "# Stage 3: EBM\n",
        "print(\"\\nðŸ”¹ Stage 3: EBM\")\n",
        "ebm_X_train = ebm_model.predict_proba(X_train)[:, 1]\n",
        "ebm_X_test = ebm_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"  Train: mean={ebm_X_train.mean():.4f}, std={ebm_X_train.std():.4f}\")\n",
        "print(f\"  Test:  mean={ebm_X_test.mean():.4f}, std={ebm_X_test.std():.4f}\")\n",
        "\n",
        "# Verify all predictions are on same samples\n",
        "assert len(lr_X_train) == len(glass_X_train) == len(ebm_X_train)\n",
        "assert len(lr_X_test) == len(glass_X_test) == len(ebm_X_test)\n",
        "print(f\"\\nâœ… All models have predictions on same {len(lr_X_train)} train / {len(lr_X_test)} test samples\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. CREATE META-FEATURES\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”¨ 4. CREATING META-FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "meta_train = pd.DataFrame({\n",
        "    'lr_prob': lr_X_train,\n",
        "    'rf_prob': glass_X_train,\n",
        "    'ebm_prob': ebm_X_train\n",
        "})\n",
        "\n",
        "meta_test = pd.DataFrame({\n",
        "    'lr_prob': lr_X_test,\n",
        "    'rf_prob': glass_X_test,\n",
        "    'ebm_prob': ebm_X_test\n",
        "})\n",
        "\n",
        "# Disagreement signals\n",
        "meta_train['lr_rf_diff'] = np.abs(meta_train['lr_prob'] - meta_train['rf_prob'])\n",
        "meta_train['lr_ebm_diff'] = np.abs(meta_train['lr_prob'] - meta_train['ebm_prob'])\n",
        "meta_train['rf_ebm_diff'] = np.abs(meta_train['rf_prob'] - meta_train['ebm_prob'])\n",
        "\n",
        "meta_test['lr_rf_diff'] = np.abs(meta_test['lr_prob'] - meta_test['rf_prob'])\n",
        "meta_test['lr_ebm_diff'] = np.abs(meta_test['lr_prob'] - meta_test['ebm_prob'])\n",
        "meta_test['rf_ebm_diff'] = np.abs(meta_test['rf_prob'] - meta_test['ebm_prob'])\n",
        "\n",
        "# Confidence geometry\n",
        "P_train = meta_train[['lr_prob', 'rf_prob', 'ebm_prob']].values\n",
        "meta_train['max_confidence'] = P_train.max(axis=1)\n",
        "meta_train['min_confidence'] = P_train.min(axis=1)\n",
        "meta_train['std_confidence'] = P_train.std(axis=1)\n",
        "\n",
        "P_test = meta_test[['lr_prob', 'rf_prob', 'ebm_prob']].values\n",
        "meta_test['max_confidence'] = P_test.max(axis=1)\n",
        "meta_test['min_confidence'] = P_test.min(axis=1)\n",
        "meta_test['std_confidence'] = P_test.std(axis=1)\n",
        "\n",
        "print(f\"âœ… Meta-features created: {meta_train.shape}\")\n",
        "print(f\"   Features: {list(meta_train.columns)}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5. TRAIN META-EBM (10-FOLD CV)\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ¯ 5. TRAINING META-EBM (10-FOLD CV)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "meta_ebm = ExplainableBoostingClassifier(\n",
        "    max_bins=16,\n",
        "    max_interaction_bins=8,\n",
        "    interactions=5,\n",
        "    outer_bags=10,\n",
        "    inner_bags=0,\n",
        "    learning_rate=0.01,\n",
        "    min_samples_leaf=5,\n",
        "    max_leaves=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "meta_ebm.fit(meta_train, y_train)\n",
        "print(\"âœ… Meta-EBM trained!\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 6. EVALUATE\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š 6. META-EBM EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "meta_pred_test = meta_ebm.predict_proba(meta_test)[:, 1]\n",
        "meta_pred_test_class = (meta_pred_test >= 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, meta_pred_test_class)\n",
        "precision = precision_score(y_test, meta_pred_test_class)\n",
        "recall = recall_score(y_test, meta_pred_test_class)\n",
        "f1 = f1_score(y_test, meta_pred_test_class)\n",
        "roc_auc = roc_auc_score(y_test, meta_pred_test)\n",
        "\n",
        "print(f\"\\nðŸŽ¯ META-EBM PERFORMANCE:\")\n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "print(f\"  F1-Score:  {f1:.4f}\")\n",
        "print(f\"  ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, meta_pred_test_class)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, meta_pred_test_class,\n",
        "                          target_names=['No Subscribe', 'Subscribe']))\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 7. SAVE CHECKPOINT\n",
        "# --------------------------------------------------\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "checkpoint = {\n",
        "    'meta_ebm_model': meta_ebm,\n",
        "    'stage_models': {\n",
        "        'lr_model': lr_model,\n",
        "        'glass_model': glass_model,\n",
        "        'rf_model': rf_model,\n",
        "        'ebm_model': ebm_model\n",
        "    },\n",
        "    'performance': {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'roc_auc': roc_auc\n",
        "    },\n",
        "    'training_date': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "filename = f\"/content/meta_ebm_cascade_checkpoint_{timestamp}.pkl\"\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(checkpoint, f)\n",
        "\n",
        "print(f\"\\nâœ… Saved: {filename}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ‰ 4-STAGE CASCADE COMPLETE!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYBB-QmM8i6Y",
        "outputId": "77da1330-2945-43f4-e675-0b21cb7510d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ META-EBM (STAGE 4) - FINAL CASCADE ASSEMBLY\n",
            "================================================================================\n",
            "âœ… Class definitions loaded\n",
            "\n",
            "============================================================\n",
            "ðŸ“‚ 1. LOADING STAGE 1-3 MODELS\n",
            "============================================================\n",
            "âœ… LR model loaded\n",
            "âœ… GLASS-BRW model loaded (7 rules)\n",
            "âœ… EBM model loaded\n",
            "\n",
            "============================================================\n",
            "ðŸ”§ 2. CREATING SINGLE TRAIN/TEST SPLIT\n",
            "============================================================\n",
            "âœ… Single split created:\n",
            "  Train: (36168, 16) samples\n",
            "  Test:  (9043, 16) samples\n",
            "  Train positives: 0.1170\n",
            "  Test positives:  0.1170\n",
            "\n",
            "============================================================\n",
            "ðŸŽ² 3. GENERATING PREDICTIONS FROM ALL STAGES\n",
            "============================================================\n",
            "\n",
            "ðŸ”¹ Stage 1: Logistic Regression\n",
            "  Train: mean=0.3306, std=0.2785\n",
            "  Test:  mean=0.3316, std=0.2785\n",
            "\n",
            "ðŸ”¹ Stage 2: GLASS-BRW\n",
            "  Train: mean=0.0993, std=0.1171\n",
            "  Test:  mean=0.1002, std=0.1191\n",
            "\n",
            "ðŸ”¹ Stage 3: EBM\n",
            "  Train: mean=0.1170, std=0.2092\n",
            "  Test:  mean=0.1157, std=0.2064\n",
            "\n",
            "âœ… All models have predictions on same 36168 train / 9043 test samples\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š 3B. STAGE-BY-STAGE PERFORMANCE METRICS\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š STAGE 1: LOGISTIC REGRESSION\n",
            "============================================================\n",
            "\n",
            "ðŸŽ¯ Overall Metrics:\n",
            "  Accuracy:  0.8236\n",
            "  ROC-AUC:   0.8886\n",
            "\n",
            "ðŸ“‰ Class 0 (No Subscribe) - Support: 7985\n",
            "  Precision: 0.9685  (TN=6605 / TN+FN=6820)\n",
            "  Recall:    0.8272  (TN=6605 / TN+FP=7985)\n",
            "  F1-Score:  0.8923\n",
            "\n",
            "ðŸ“ˆ Class 1 (Subscribe) - Support: 1058\n",
            "  Precision: 0.3792  (TP=843 / TP+FP=2223)\n",
            "  Recall:    0.7968  (TP=843 / TP+FN=1058)\n",
            "  F1-Score:  0.5139\n",
            "\n",
            "ðŸ“Š Confusion Matrix:\n",
            "                 Pred No    Pred Yes\n",
            "  Actual No        6605       1380\n",
            "  Actual Yes        215        843\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š STAGE 2: GLASS-BRW (RF)\n",
            "============================================================\n",
            "\n",
            "ðŸŽ¯ Overall Metrics:\n",
            "  Accuracy:  0.8864\n",
            "  ROC-AUC:   0.6642\n",
            "\n",
            "ðŸ“‰ Class 0 (No Subscribe) - Support: 7985\n",
            "  Precision: 0.9058  (TN=7766 / TN+FN=8574)\n",
            "  Recall:    0.9726  (TN=7766 / TN+FP=7985)\n",
            "  F1-Score:  0.9380\n",
            "\n",
            "ðŸ“ˆ Class 1 (Subscribe) - Support: 1058\n",
            "  Precision: 0.5330  (TP=250 / TP+FP=469)\n",
            "  Recall:    0.2363  (TP=250 / TP+FN=1058)\n",
            "  F1-Score:  0.3274\n",
            "\n",
            "ðŸ“Š Confusion Matrix:\n",
            "                 Pred No    Pred Yes\n",
            "  Actual No        7766        219\n",
            "  Actual Yes        808        250\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š STAGE 3: EBM\n",
            "============================================================\n",
            "\n",
            "ðŸŽ¯ Overall Metrics:\n",
            "  Accuracy:  0.9071\n",
            "  ROC-AUC:   0.9291\n",
            "\n",
            "ðŸ“‰ Class 0 (No Subscribe) - Support: 7985\n",
            "  Precision: 0.9306  (TN=7721 / TN+FN=8297)\n",
            "  Recall:    0.9669  (TN=7721 / TN+FP=7985)\n",
            "  F1-Score:  0.9484\n",
            "\n",
            "ðŸ“ˆ Class 1 (Subscribe) - Support: 1058\n",
            "  Precision: 0.6461  (TP=482 / TP+FP=746)\n",
            "  Recall:    0.4556  (TP=482 / TP+FN=1058)\n",
            "  F1-Score:  0.5344\n",
            "\n",
            "ðŸ“Š Confusion Matrix:\n",
            "                 Pred No    Pred Yes\n",
            "  Actual No        7721        264\n",
            "  Actual Yes        576        482\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š STAGE COMPARISON SUMMARY (TEST SET)\n",
            "================================================================================\n",
            "\n",
            "Metric                              LR    GLASS-BRW          EBM\n",
            "-----------------------------------------------------------------\n",
            "Accuracy                        0.8236       0.8864       0.9071\n",
            "ROC-AUC                         0.8886       0.6642       0.9291\n",
            "\n",
            "CLASS 0 (No Subscribe):  \n",
            "  Precision                     0.9685       0.9058       0.9306\n",
            "  Recall                        0.8272       0.9726       0.9669\n",
            "  F1-Score                      0.8923       0.9380       0.9484\n",
            "\n",
            "CLASS 1 (Subscribe):     \n",
            "  Precision                     0.3792       0.5330       0.6461\n",
            "  Recall                        0.7968       0.2363       0.4556\n",
            "  F1-Score                      0.5139       0.3274       0.5344\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "ðŸ”¨ 4. CREATING META-FEATURES\n",
            "============================================================\n",
            "âœ… Meta-features created: (36168, 9)\n",
            "   Features: ['lr_prob', 'rf_prob', 'ebm_prob', 'lr_rf_diff', 'lr_ebm_diff', 'rf_ebm_diff', 'max_confidence', 'min_confidence', 'std_confidence']\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¯ 5. TRAINING META-EBM (10-FOLD CV)\n",
            "============================================================\n",
            "âœ… Meta-EBM trained!\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š 6. META-EBM EVALUATION\n",
            "============================================================\n",
            "\n",
            "ðŸŽ¯ META-EBM PERFORMANCE:\n",
            "  Accuracy:  0.9079\n",
            "  Precision: 0.6295\n",
            "  Recall:    0.5170\n",
            "  F1-Score:  0.5677\n",
            "  ROC-AUC:   0.9273\n",
            "\n",
            "Confusion Matrix:\n",
            "[[7663  322]\n",
            " [ 511  547]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "No Subscribe       0.94      0.96      0.95      7985\n",
            "   Subscribe       0.63      0.52      0.57      1058\n",
            "\n",
            "    accuracy                           0.91      9043\n",
            "   macro avg       0.78      0.74      0.76      9043\n",
            "weighted avg       0.90      0.91      0.90      9043\n",
            "\n",
            "\n",
            "âœ… Saved: /content/meta_ebm_cascade_checkpoint_20251220_232327.pkl\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ‰ 4-STAGE CASCADE COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL: META-EBM (STAGE 4) - PROPER DATA SPLIT\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ¯ META-EBM (STAGE 4) - FINAL CASCADE ASSEMBLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from interpret.glassbox import ExplainableBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass\n",
        "from typing import Set, Tuple, List, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "# Execute class definitions for unpickling\n",
        "exec(\"\"\"\n",
        "@dataclass\n",
        "class Rule:\n",
        "    rule_id: int\n",
        "    segment: Set[Tuple[str, str]]\n",
        "    predicted_class: int\n",
        "    complexity: int\n",
        "    precision: float = 0.0\n",
        "    recall: float = 0.0\n",
        "    coverage: float = 0.0\n",
        "    stability: float = 0.0\n",
        "    interpretability: float = 0.0\n",
        "    boundary_ambiguity: float = 0.0\n",
        "    rf_alignment: float = 0.0\n",
        "    def __hash__(self):\n",
        "        return hash((self.rule_id, frozenset(self.segment), self.predicted_class))\n",
        "    def __eq__(self, other):\n",
        "        return self.rule_id == other.rule_id\n",
        "\n",
        "class BankSegmentBuilder:\n",
        "    SEGMENT_FEATURES = [\n",
        "        \"dur_low\", \"dur_mid\", \"dur_high\",\n",
        "        \"month_early\", \"month_late_spring\", \"month_summer\", \"month_fall\", \"month_year_end\",\n",
        "        \"engagement_low\", \"fatigue_low\", \"poutcome_success\",\n",
        "        \"housing\", \"pdays_never\"\n",
        "    ]\n",
        "    def assign_segments(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        X = X.drop(columns=[\"y\", \"y_bin\"], errors=\"ignore\")\n",
        "        cols = [c for c in self.SEGMENT_FEATURES if c in X.columns]\n",
        "        if len(cols) == 0:\n",
        "            raise ValueError(\"No valid segment features found in input\")\n",
        "        segments = X[cols].copy()\n",
        "        for col in segments.columns:\n",
        "            vals = set(segments[col].dropna().unique())\n",
        "            if not vals.issubset({0, 1}):\n",
        "                raise ValueError(f\"Non-binary segment feature: {col} -> {vals}\")\n",
        "        return segments.astype(\"int8\")\n",
        "\n",
        "class RuleGenerator:\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class RuleEvaluator:\n",
        "    def __init__(self, segment_builder, min_support=30):\n",
        "        self.segment_builder = segment_builder\n",
        "        self.min_support = min_support\n",
        "\n",
        "class ILPRuleSelector:\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class GLASS_BRW:\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "        if not hasattr(self, 'segment_builder'):\n",
        "            self.segment_builder = BankSegmentBuilder()\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not hasattr(self, 'rules') or not self.rules:\n",
        "            n = len(X)\n",
        "            return np.column_stack([np.full(n, 0.5), np.full(n, 0.5)])\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            X = pd.DataFrame(X)\n",
        "\n",
        "        n = len(X)\n",
        "        predictions = np.full(n, -1, dtype=int)\n",
        "        confidences = np.zeros(n)\n",
        "\n",
        "        segments = self.segment_builder.assign_segments(X)\n",
        "\n",
        "        for i in range(n):\n",
        "            for rule in self.rules:\n",
        "                matches = True\n",
        "                for feature, level in rule.segment:\n",
        "                    if feature not in segments.columns:\n",
        "                        matches = False\n",
        "                        break\n",
        "                    if segments.iloc[i][feature] != level:\n",
        "                        matches = False\n",
        "                        break\n",
        "\n",
        "                if not matches:\n",
        "                    continue\n",
        "\n",
        "                predictions[i] = rule.predicted_class\n",
        "                confidences[i] = rule.precision\n",
        "                break\n",
        "\n",
        "        probas = np.zeros((n, 2))\n",
        "        for i in range(n):\n",
        "            if predictions[i] == -1:\n",
        "                probas[i] = [0.5, 0.5]\n",
        "            elif predictions[i] == 1:\n",
        "                probas[i] = [1 - confidences[i], confidences[i]]\n",
        "            else:\n",
        "                probas[i] = [confidences[i], 1 - confidences[i]]\n",
        "\n",
        "        return probas\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… Class definitions loaded\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. LOAD ALL MODELS\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‚ 1. LOADING STAGE 1-3 MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load LR\n",
        "lr_ensemble_dict = joblib.load('/content/lr_ensemble_joblib_20251220_203823.joblib')\n",
        "lr_model = lr_ensemble_dict['model']\n",
        "scaler = lr_ensemble_dict['scaler']\n",
        "print(f\"âœ… LR model loaded\")\n",
        "\n",
        "# Load GLASS-BRW\n",
        "with open('/content/glass_brw_rf_checkpoint_20251220_211009.pkl', 'rb') as f:\n",
        "    glass_model = pickle.load(f)\n",
        "rf_model = glass_model.rf_model\n",
        "print(f\"âœ… GLASS-BRW model loaded ({len(glass_model.rules)} rules)\")\n",
        "\n",
        "# Load EBM\n",
        "ebm_ensemble_dict = joblib.load('/content/ebm_ensemble_joblib_20251220_223007.joblib')\n",
        "ebm_model = ebm_ensemble_dict['model']\n",
        "print(f\"âœ… EBM model loaded\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. CREATE SINGLE TRAIN/TEST SPLIT FOR ALL MODELS\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”§ 2. CREATING SINGLE TRAIN/TEST SPLIT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Split the full dataset\n",
        "X_full = df_proc.drop(columns=['y'])\n",
        "y_full = df_proc['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
        ")\n",
        "\n",
        "print(f\"âœ… Single split created:\")\n",
        "print(f\"  Train: {X_train.shape} samples\")\n",
        "print(f\"  Test:  {X_test.shape} samples\")\n",
        "print(f\"  Train positives: {y_train.mean():.4f}\")\n",
        "print(f\"  Test positives:  {y_test.mean():.4f}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. GENERATE PREDICTIONS FROM ALL STAGES ON SAME SPLIT\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ² 3. GENERATING PREDICTIONS FROM ALL STAGES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Stage 1: Logistic Regression\n",
        "print(\"\\nðŸ”¹ Stage 1: Logistic Regression\")\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lr_X_train = lr_model.predict_proba(X_train_scaled)[:, 1]\n",
        "lr_X_test = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(f\"  Train: mean={lr_X_train.mean():.4f}, std={lr_X_train.std():.4f}\")\n",
        "print(f\"  Test:  mean={lr_X_test.mean():.4f}, std={lr_X_test.std():.4f}\")\n",
        "\n",
        "# Stage 2: GLASS-BRW (needs feature engineering)\n",
        "print(\"\\nðŸ”¹ Stage 2: GLASS-BRW\")\n",
        "\n",
        "def engineer_features_bank(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Engineer features for GLASS-BRW\"\"\"\n",
        "    d = df.copy()\n",
        "    d[\"dur_low\"] = (d[\"duration\"] <= 200).astype(\"int8\")\n",
        "    d[\"dur_mid\"] = ((d[\"duration\"] > 200) & (d[\"duration\"] <= 300)).astype(\"int8\")\n",
        "    d[\"dur_high\"] = (d[\"duration\"] > 300).astype(\"int8\")\n",
        "    d[\"pdays_never\"] = (d[\"pdays\"] <= 0).astype(\"int8\")\n",
        "    d[\"pdays_1_5\"] = ((d[\"pdays\"] > 0) & (d[\"pdays\"] <= 5)).astype(\"int8\")\n",
        "    d[\"month_early\"] = d[\"month_ordinal\"].isin([1, 2, 3, 4]).astype(\"int8\")\n",
        "    d[\"month_late_spring\"] = d[\"month_ordinal\"].isin([5, 6]).astype(\"int8\")\n",
        "    d[\"month_summer\"] = d[\"month_ordinal\"].isin([7, 8]).astype(\"int8\")\n",
        "    d[\"month_fall\"] = d[\"month_ordinal\"].isin([9, 10]).astype(\"int8\")\n",
        "    d[\"month_year_end\"] = d[\"month_ordinal\"].isin([11, 12]).astype(\"int8\")\n",
        "    d[\"previous_ge1\"] = (d[\"previous\"] >= 1).astype(\"int8\")\n",
        "    d[\"engagement_score\"] = (\n",
        "        d[\"previous_ge1\"] + d[\"pdays_1_5\"] + d[\"dur_high\"] + (d[\"poutcome\"] == 3).astype(\"int8\")\n",
        "    ).astype(\"int8\")\n",
        "    d[\"fatigue_score\"] = (\n",
        "        (d[\"campaign\"] >= 5).astype(\"int8\") + (d[\"campaign\"] >= 8).astype(\"int8\") +\n",
        "        d[\"dur_low\"] + d[\"pdays_never\"]\n",
        "    ).astype(\"int8\")\n",
        "\n",
        "    out = pd.DataFrame(index=d.index)\n",
        "    out[\"dur_low\"] = d[\"dur_low\"]\n",
        "    out[\"dur_mid\"] = d[\"dur_mid\"]\n",
        "    out[\"dur_high\"] = d[\"dur_high\"]\n",
        "    out[\"month_summer\"] = d[\"month_summer\"]\n",
        "    out[\"month_fall\"] = d[\"month_fall\"]\n",
        "    out[\"month_year_end\"] = d[\"month_year_end\"]\n",
        "    out[\"month_early\"] = d[\"month_early\"]\n",
        "    out[\"month_late_spring\"] = d[\"month_late_spring\"]\n",
        "    out[\"engagement_low\"] = (d[\"engagement_score\"] <= 1).astype(\"int8\")\n",
        "    out[\"fatigue_low\"] = (d[\"fatigue_score\"] <= 1).astype(\"int8\")\n",
        "    out[\"housing\"] = d[\"housing\"].astype(\"int8\")\n",
        "    out[\"poutcome_success\"] = (d[\"poutcome\"] == 3).astype(\"int8\")\n",
        "    out[\"pdays_never\"] = d[\"pdays_never\"]\n",
        "    return out\n",
        "\n",
        "X_train_glass = engineer_features_bank(X_train)\n",
        "X_test_glass = engineer_features_bank(X_test)\n",
        "\n",
        "glass_X_train = glass_model.predict_proba(X_train_glass)[:, 1]\n",
        "glass_X_test = glass_model.predict_proba(X_test_glass)[:, 1]\n",
        "\n",
        "print(f\"  Train: mean={glass_X_train.mean():.4f}, std={glass_X_train.std():.4f}\")\n",
        "print(f\"  Test:  mean={glass_X_test.mean():.4f}, std={glass_X_test.std():.4f}\")\n",
        "\n",
        "# Stage 3: EBM\n",
        "print(\"\\nðŸ”¹ Stage 3: EBM\")\n",
        "ebm_X_train = ebm_model.predict_proba(X_train)[:, 1]\n",
        "ebm_X_test = ebm_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"  Train: mean={ebm_X_train.mean():.4f}, std={ebm_X_train.std():.4f}\")\n",
        "print(f\"  Test:  mean={ebm_X_test.mean():.4f}, std={ebm_X_test.std():.4f}\")\n",
        "\n",
        "# Verify all predictions are on same samples\n",
        "assert len(lr_X_train) == len(glass_X_train) == len(ebm_X_train)\n",
        "assert len(lr_X_test) == len(glass_X_test) == len(ebm_X_test)\n",
        "print(f\"\\nâœ… All models have predictions on same {len(lr_X_train)} train / {len(lr_X_test)} test samples\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3B. EVALUATE EACH STAGE MODEL\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š 3B. STAGE-BY-STAGE PERFORMANCE METRICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def evaluate_stage(y_true, y_pred_proba, stage_name, threshold=0.5):\n",
        "    \"\"\"Evaluate a stage model with comprehensive metrics\"\"\"\n",
        "    y_pred_class = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred_class)\n",
        "    prec = precision_score(y_true, y_pred_class, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred_class, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred_class, zero_division=0)\n",
        "    roc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred_class)\n",
        "\n",
        "    # Per-class metrics\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    # Class 0 (No Subscribe) metrics\n",
        "    class0_precision = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
        "    class0_recall = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    class0_f1 = 2 * (class0_precision * class0_recall) / (class0_precision + class0_recall) if (class0_precision + class0_recall) > 0 else 0\n",
        "\n",
        "    # Class 1 (Subscribe) metrics\n",
        "    class1_precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    class1_recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    class1_f1 = 2 * (class1_precision * class1_recall) / (class1_precision + class1_recall) if (class1_precision + class1_recall) > 0 else 0\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ðŸ“Š {stage_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"\\nðŸŽ¯ Overall Metrics:\")\n",
        "    print(f\"  Accuracy:  {acc:.4f}\")\n",
        "    print(f\"  ROC-AUC:   {roc:.4f}\")\n",
        "\n",
        "    print(f\"\\nðŸ“‰ Class 0 (No Subscribe) - Support: {tn + fp}\")\n",
        "    print(f\"  Precision: {class0_precision:.4f}  (TN={tn} / TN+FN={tn + fn})\")\n",
        "    print(f\"  Recall:    {class0_recall:.4f}  (TN={tn} / TN+FP={tn + fp})\")\n",
        "    print(f\"  F1-Score:  {class0_f1:.4f}\")\n",
        "\n",
        "    print(f\"\\nðŸ“ˆ Class 1 (Subscribe) - Support: {tp + fn}\")\n",
        "    print(f\"  Precision: {class1_precision:.4f}  (TP={tp} / TP+FP={tp + fp})\")\n",
        "    print(f\"  Recall:    {class1_recall:.4f}  (TP={tp} / TP+FN={tp + fn})\")\n",
        "    print(f\"  F1-Score:  {class1_f1:.4f}\")\n",
        "\n",
        "    print(f\"\\nðŸ“Š Confusion Matrix:\")\n",
        "    print(f\"                 Pred No    Pred Yes\")\n",
        "    print(f\"  Actual No      {tn:6d}     {fp:6d}\")\n",
        "    print(f\"  Actual Yes     {fn:6d}     {tp:6d}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'roc_auc': roc,\n",
        "        'class0_precision': class0_precision,\n",
        "        'class0_recall': class0_recall,\n",
        "        'class0_f1': class0_f1,\n",
        "        'class1_precision': class1_precision,\n",
        "        'class1_recall': class1_recall,\n",
        "        'class1_f1': class1_f1,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "# Evaluate each stage on TEST set\n",
        "stage1_metrics = evaluate_stage(y_test, lr_X_test, \"STAGE 1: LOGISTIC REGRESSION\")\n",
        "stage2_metrics = evaluate_stage(y_test, glass_X_test, \"STAGE 2: GLASS-BRW (RF)\")\n",
        "stage3_metrics = evaluate_stage(y_test, ebm_X_test, \"STAGE 3: EBM\")\n",
        "\n",
        "# Summary comparison table\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(f\"ðŸ“Š STAGE COMPARISON SUMMARY (TEST SET)\")\n",
        "print(f\"=\"*80)\n",
        "print(f\"\\n{'Metric':<25} {'LR':>12} {'GLASS-BRW':>12} {'EBM':>12}\")\n",
        "print(f\"{'-'*65}\")\n",
        "print(f\"{'Accuracy':<25} {stage1_metrics['accuracy']:>12.4f} {stage2_metrics['accuracy']:>12.4f} {stage3_metrics['accuracy']:>12.4f}\")\n",
        "print(f\"{'ROC-AUC':<25} {stage1_metrics['roc_auc']:>12.4f} {stage2_metrics['roc_auc']:>12.4f} {stage3_metrics['roc_auc']:>12.4f}\")\n",
        "print(f\"\\n{'CLASS 0 (No Subscribe):':<25}\")\n",
        "print(f\"{'  Precision':<25} {stage1_metrics['class0_precision']:>12.4f} {stage2_metrics['class0_precision']:>12.4f} {stage3_metrics['class0_precision']:>12.4f}\")\n",
        "print(f\"{'  Recall':<25} {stage1_metrics['class0_recall']:>12.4f} {stage2_metrics['class0_recall']:>12.4f} {stage3_metrics['class0_recall']:>12.4f}\")\n",
        "print(f\"{'  F1-Score':<25} {stage1_metrics['class0_f1']:>12.4f} {stage2_metrics['class0_f1']:>12.4f} {stage3_metrics['class0_f1']:>12.4f}\")\n",
        "print(f\"\\n{'CLASS 1 (Subscribe):':<25}\")\n",
        "print(f\"{'  Precision':<25} {stage1_metrics['class1_precision']:>12.4f} {stage2_metrics['class1_precision']:>12.4f} {stage3_metrics['class1_precision']:>12.4f}\")\n",
        "print(f\"{'  Recall':<25} {stage1_metrics['class1_recall']:>12.4f} {stage2_metrics['class1_recall']:>12.4f} {stage3_metrics['class1_recall']:>12.4f}\")\n",
        "print(f\"{'  F1-Score':<25} {stage1_metrics['class1_f1']:>12.4f} {stage2_metrics['class1_f1']:>12.4f} {stage3_metrics['class1_f1']:>12.4f}\")\n",
        "print(f\"=\"*80)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. CREATE META-FEATURES\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”¨ 4. CREATING META-FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "meta_train = pd.DataFrame({\n",
        "    'lr_prob': lr_X_train,\n",
        "    'rf_prob': glass_X_train,\n",
        "    'ebm_prob': ebm_X_train\n",
        "})\n",
        "\n",
        "meta_test = pd.DataFrame({\n",
        "    'lr_prob': lr_X_test,\n",
        "    'rf_prob': glass_X_test,\n",
        "    'ebm_prob': ebm_X_test\n",
        "})\n",
        "\n",
        "# Disagreement signals\n",
        "meta_train['lr_rf_diff'] = np.abs(meta_train['lr_prob'] - meta_train['rf_prob'])\n",
        "meta_train['lr_ebm_diff'] = np.abs(meta_train['lr_prob'] - meta_train['ebm_prob'])\n",
        "meta_train['rf_ebm_diff'] = np.abs(meta_train['rf_prob'] - meta_train['ebm_prob'])\n",
        "\n",
        "meta_test['lr_rf_diff'] = np.abs(meta_test['lr_prob'] - meta_test['rf_prob'])\n",
        "meta_test['lr_ebm_diff'] = np.abs(meta_test['lr_prob'] - meta_test['ebm_prob'])\n",
        "meta_test['rf_ebm_diff'] = np.abs(meta_test['rf_prob'] - meta_test['ebm_prob'])\n",
        "\n",
        "# Confidence geometry\n",
        "P_train = meta_train[['lr_prob', 'rf_prob', 'ebm_prob']].values\n",
        "meta_train['max_confidence'] = P_train.max(axis=1)\n",
        "meta_train['min_confidence'] = P_train.min(axis=1)\n",
        "meta_train['std_confidence'] = P_train.std(axis=1)\n",
        "\n",
        "P_test = meta_test[['lr_prob', 'rf_prob', 'ebm_prob']].values\n",
        "meta_test['max_confidence'] = P_test.max(axis=1)\n",
        "meta_test['min_confidence'] = P_test.min(axis=1)\n",
        "meta_test['std_confidence'] = P_test.std(axis=1)\n",
        "\n",
        "print(f\"âœ… Meta-features created: {meta_train.shape}\")\n",
        "print(f\"   Features: {list(meta_train.columns)}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5. TRAIN META-EBM (10-FOLD CV)\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ¯ 5. TRAINING META-EBM (10-FOLD CV)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "meta_ebm = ExplainableBoostingClassifier(\n",
        "    max_bins=16,\n",
        "    max_interaction_bins=8,\n",
        "    interactions=5,\n",
        "    outer_bags=10,\n",
        "    inner_bags=0,\n",
        "    learning_rate=0.01,\n",
        "    min_samples_leaf=5,\n",
        "    max_leaves=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "meta_ebm.fit(meta_train, y_train)\n",
        "print(\"âœ… Meta-EBM trained!\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 6. EVALUATE\n",
        "# --------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š 6. META-EBM EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "meta_pred_test = meta_ebm.predict_proba(meta_test)[:, 1]\n",
        "meta_pred_test_class = (meta_pred_test >= 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, meta_pred_test_class)\n",
        "precision = precision_score(y_test, meta_pred_test_class)\n",
        "recall = recall_score(y_test, meta_pred_test_class)\n",
        "f1 = f1_score(y_test, meta_pred_test_class)\n",
        "roc_auc = roc_auc_score(y_test, meta_pred_test)\n",
        "\n",
        "print(f\"\\nðŸŽ¯ META-EBM PERFORMANCE:\")\n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "print(f\"  F1-Score:  {f1:.4f}\")\n",
        "print(f\"  ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, meta_pred_test_class)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, meta_pred_test_class,\n",
        "                          target_names=['No Subscribe', 'Subscribe']))\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 7. SAVE CHECKPOINT\n",
        "# --------------------------------------------------\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "checkpoint = {\n",
        "    'meta_ebm_model': meta_ebm,\n",
        "    'stage_models': {\n",
        "        'lr_model': lr_model,\n",
        "        'glass_model': glass_model,\n",
        "        'rf_model': rf_model,\n",
        "        'ebm_model': ebm_model\n",
        "    },\n",
        "    'performance': {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'roc_auc': roc_auc\n",
        "    },\n",
        "    'training_date': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "filename = f\"/content/meta_ebm_cascade_checkpoint_{timestamp}.pkl\"\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(checkpoint, f)\n",
        "\n",
        "print(f\"\\nâœ… Saved: {filename}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ‰ 4-STAGE CASCADE COMPLETE!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# TODO: FINAL STAGE â€” GLASS-BOX ENSEMBLE (META LAYER)\n",
        "# ============================================================\n",
        "# NOTE: Upstream models (LR, GLASS-BRW, EBM) will be fine-tuned first.\n",
        "#       This ensemble stage will be revisited and adjusted to reflect\n",
        "#       updated constraints, thresholds, and feature semantics.\n",
        "\n",
        "# TODO: Re-evaluate meta-model feature inputs to ensure alignment with\n",
        "#       updated upstream outputs (probabilities, abstentions, confidence signals).\n",
        "# TODO: Tune ensemble weighting and routing logic to optimize recallâ€“precision\n",
        "#       trade-offs under new upstream specifications.\n",
        "# TODO: Introduce constraint-aware gating (e.g., minimum recall guards,\n",
        "#       confidence thresholds, disagreement signals) to prevent overfitting\n",
        "#       and preserve interpretability.\n",
        "# TODO: Validate ensemble stability via cross-validation and stress tests\n",
        "#       on edge cases where upstream models disagree or abstain.\n",
        "# TODO: Ensure end-to-end glass-box consistency: every ensemble decision\n",
        "#       must be decomposable into transparent upstream contributions.\n",
        "# TODO: Verify that all model objects, classes, and methods are correctly\n",
        "#       instantiated, serialized, and transferred across pipeline stages.\n",
        "#       Current results suggest a potential alignment mismatch; this will\n",
        "#       be diagnosed and resolved when returning to this stage.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

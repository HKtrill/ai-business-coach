{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading\n",
        "### Load the telecom customer churn dataset from local storage.\n"
      ],
      "metadata": {
        "id": "mCsebXSMpGH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWfbK3Hco_mM",
        "outputId": "554cf693-c5e9-4f8d-a63c-95bb6ffca48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ interpret library not found. Install for explainable models...\n",
            "   Run: pip install interpret\n",
            "‚úÖ IMPORTS SUCCESSFUL - CHURN PREDICTION PIPELINE READY\n",
            "   ‚Ä¢ Scikit-learn modules: Complete\n",
            "   ‚Ä¢ Scientific computing: NumPy 2.0.2, Pandas 2.2.2\n",
            "   ‚Ä¢ Visualization: Matplotlib 3.10.0, Seaborn 0.13.2\n",
            "   ‚Ä¢ Interpretable ML: Not installed\n",
            "   ‚Ä¢ Random seed set: 42 (for reproducibility)\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "COMPREHENSIVE IMPORT STATEMENTS FOR CHURN PREDICTION PIPELINE\n",
        "Organized by functionality and usage category\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# 1. SCIKIT-LEARN CORE MODULES\n",
        "# ============================================================================\n",
        "from sklearn.model_selection import (\n",
        "    StratifiedKFold,        # For stratified cross-validation\n",
        "    GridSearchCV,           # Exhaustive hyperparameter search\n",
        "    RandomizedSearchCV,     # Random hyperparameter search\n",
        "    train_test_split        # Train/test splitting\n",
        ")\n",
        "\n",
        "from sklearn.feature_selection import (\n",
        "    mutual_info_classif     # Mutual information for feature selection\n",
        ")\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    # Core classification metrics\n",
        "    fbeta_score,           # F-beta score (F2 for recall focus)\n",
        "    f1_score,              # F1 score (harmonic mean)\n",
        "    make_scorer,           # Custom scoring functions\n",
        "    recall_score,          # Sensitivity/true positive rate\n",
        "    precision_score,       # Positive predictive value\n",
        "    roc_auc_score,         # Area under ROC curve\n",
        "    accuracy_score,        # Overall accuracy\n",
        "    confusion_matrix       # TP, FP, TN, FN matrix\n",
        ")\n",
        "\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler         # Feature standardization (z-score)\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import (\n",
        "    LogisticRegression     # Primary linear model\n",
        ")\n",
        "\n",
        "from sklearn.inspection import (\n",
        "    permutation_importance # Feature importance via permutation\n",
        ")\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier # Ensemble tree model for comparison\n",
        ")\n",
        "\n",
        "from sklearn.tree import (\n",
        "    _tree                  # Internal tree utilities\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. SCIENTIFIC COMPUTING & STATISTICS\n",
        "# ============================================================================\n",
        "from scipy import stats\n",
        "from scipy.stats import randint  # Random integer distributions\n",
        "\n",
        "import numpy as np               # Numerical computing\n",
        "import pandas as pd              # Data manipulation\n",
        "\n",
        "# ============================================================================\n",
        "# 3. VISUALIZATION\n",
        "# ============================================================================\n",
        "import matplotlib.pyplot as plt  # Plotting and visualization\n",
        "import seaborn as sns            # Statistical visualization\n",
        "\n",
        "# ============================================================================\n",
        "# 4. INTERPRETABLE ML (OPTIONAL - INSTALL IF MISSING)\n",
        "# ============================================================================\n",
        "try:\n",
        "    from interpret.glassbox import ExplainableBoostingClassifier\n",
        "    INTERPRET_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"üì¶ interpret library not found. Install for explainable models...\")\n",
        "    print(\"   Run: pip install interpret\")\n",
        "    INTERPRET_AVAILABLE = False\n",
        "    # Define placeholder if not available\n",
        "    ExplainableBoostingClassifier = None\n",
        "\n",
        "# ============================================================================\n",
        "# 5. UTILITIES & SYSTEM\n",
        "# ============================================================================\n",
        "import time          # Timing and profiling\n",
        "import warnings      # Warning control\n",
        "import sys           # System utilities\n",
        "import subprocess    # Subprocess management\n",
        "\n",
        "# ============================================================================\n",
        "# 6. CONFIGURATION\n",
        "# ============================================================================\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# ============================================================================\n",
        "# 7. PRINT IMPORT STATUS\n",
        "# ============================================================================\n",
        "print(\"‚úÖ IMPORTS SUCCESSFUL - CHURN PREDICTION PIPELINE READY\")\n",
        "print(f\"   ‚Ä¢ Scikit-learn modules: Complete\")\n",
        "print(f\"   ‚Ä¢ Scientific computing: NumPy {np.__version__}, Pandas {pd.__version__}\")\n",
        "print(f\"   ‚Ä¢ Visualization: Matplotlib {plt.matplotlib.__version__}, Seaborn {sns.__version__}\")\n",
        "print(f\"   ‚Ä¢ Interpretable ML: {'Available' if INTERPRET_AVAILABLE else 'Not installed'}\")\n",
        "print(f\"   ‚Ä¢ Random seed set: 42 (for reproducibility)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Set global random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading\n",
        "### Load the telecom customer churn dataset from local storage.\n"
      ],
      "metadata": {
        "id": "mY1ngJ4jpDCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "print(\"\\nüìÇ Loading telecom dataset...\\n\")\n",
        "try:\n",
        "    data = pd.read_csv('/content/sample_data/telecom_customer_churn.csv')\n",
        "    print(f\"‚úì Dataset loaded: {data.shape[0]} rows, {data.shape[1]} columns\")\n",
        "\n",
        "    # CHECK FOR NAN VALUES IN ALL COLUMNS\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üîç CHECKING NaN/EMPTY VALUES IN ALL COLUMNS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    total_nan = 0\n",
        "    total_empty = 0\n",
        "\n",
        "    print(\"\\n{:30} {:12} {:15} {:10}\".format(\n",
        "        \"COLUMN NAME\", \"DATA TYPE\", \"NaN COUNT\", \"EMPTY COUNT\"))\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for col in data.columns:\n",
        "        # Count NaN values\n",
        "        nan_count = data[col].isnull().sum()\n",
        "        total_nan += nan_count\n",
        "\n",
        "        # Count empty strings (for string columns)\n",
        "        if data[col].dtype == 'object':\n",
        "            empty_count = (data[col].astype(str).str.strip() == '').sum()\n",
        "            total_empty += empty_count\n",
        "        else:\n",
        "            empty_count = 0\n",
        "\n",
        "        # Only show columns with issues, or all if you want\n",
        "        if nan_count > 0 or empty_count > 0:\n",
        "            print(\"{:30} {:12} {:15} {:10}\".format(\n",
        "                col,\n",
        "                str(data[col].dtype),\n",
        "                str(nan_count),\n",
        "                str(empty_count)\n",
        "            ))\n",
        "\n",
        "            # Show sample values for problematic columns\n",
        "            if nan_count > 0:\n",
        "                print(\"     Sample of NaN rows indices:\",\n",
        "                      data[data[col].isnull()].index[:5].tolist())\n",
        "            if empty_count > 0:\n",
        "                empty_rows = data[data[col].astype(str).str.strip() == ''].index[:3]\n",
        "                if len(empty_rows) > 0:\n",
        "                    print(\"     First 3 empty string rows indices:\", empty_rows.tolist())\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä SUMMARY:\")\n",
        "    print(f\"Total NaN values in dataset: {total_nan}\")\n",
        "    print(f\"Total empty strings in dataset: {total_empty}\")\n",
        "    print(f\"Total rows with ANY missing data: {data.isnull().any(axis=1).sum()}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Optional: Show first few rows for context\n",
        "    print(\"\\nüìã FIRST 5 ROWS OF DATA:\")\n",
        "    print(data.head())\n",
        "\n",
        "    # Optional: Show data types summary\n",
        "    print(\"\\nüìä DATA TYPES SUMMARY:\")\n",
        "    print(data.dtypes.value_counts())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚úó Error loading dataset: {e}\")\n",
        "    print(f\"Error details: {type(e).__name__}\")\n",
        "    data = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXFMhW7BpCv2",
        "outputId": "b0981935-5298-4425-e099-4ba6b0a64869"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Loading telecom dataset...\n",
            "\n",
            "‚úì Dataset loaded: 7043 rows, 37 columns\n",
            "\n",
            "================================================================================\n",
            "üîç CHECKING NaN/EMPTY VALUES IN ALL COLUMNS\n",
            "================================================================================\n",
            "\n",
            "COLUMN NAME                    DATA TYPE    NaN COUNT       EMPTY COUNT\n",
            "----------------------------------------------------------------------\n",
            "Offer                          object       3877            0         \n",
            "     Sample of NaN rows indices: [0, 1, 4, 9, 10]\n",
            "AvgMonthlyLongDistanceCharges  float64      682             0         \n",
            "     Sample of NaN rows indices: [10, 14, 16, 19, 25]\n",
            "MultipleLines                  object       682             0         \n",
            "     Sample of NaN rows indices: [10, 14, 16, 19, 25]\n",
            "InternetType                   object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "AvgMonthlyGBDownload           float64      1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "OnlineSecurity                 object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "OnlineBackup                   object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "DeviceProtectionPlan           object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "PremiumTechSupport             object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "StreamingTV                    object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "StreamingMovies                object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "StreamingMusic                 object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "UnlimitedData                  object       1526            0         \n",
            "     Sample of NaN rows indices: [20, 23, 24, 27, 28]\n",
            "ChurnCategory                  object       5174            0         \n",
            "     Sample of NaN rows indices: [0, 1, 5, 6, 7]\n",
            "ChurnReason                    object       5174            0         \n",
            "     Sample of NaN rows indices: [0, 1, 5, 6, 7]\n",
            "\n",
            "================================================================================\n",
            "üìä SUMMARY:\n",
            "Total NaN values in dataset: 30849\n",
            "Total empty strings in dataset: 0\n",
            "Total rows with ANY missing data: 6362\n",
            "================================================================================\n",
            "\n",
            "üìã FIRST 5 ROWS OF DATA:\n",
            "   CustomerID  Gender  Age Married  NumberofDependents          City  ZipCode  \\\n",
            "0  0002-ORFBO  Female   37     Yes                   0  Frazier Park    93225   \n",
            "1  0003-MKNFE    Male   46      No                   0      Glendale    91206   \n",
            "2  0004-TLHLJ    Male   50      No                   0    Costa Mesa    92627   \n",
            "3  0011-IGKFF    Male   78     Yes                   0      Martinez    94553   \n",
            "4  0013-EXCHZ  Female   75     Yes                   0     Camarillo    93010   \n",
            "\n",
            "   Population  NumberofReferrals  TenureinMonths  ...    PaymentMethod  \\\n",
            "0        4498                  2               9  ...      Credit Card   \n",
            "1       31297                  0               9  ...      Credit Card   \n",
            "2       62069                  0               4  ...  Bank Withdrawal   \n",
            "3       46677                  1              13  ...  Bank Withdrawal   \n",
            "4       42853                  3               3  ...      Credit Card   \n",
            "\n",
            "  MonthlyCharge  TotalCharges TotalRefunds TotalExtraDataCharges  \\\n",
            "0          65.6        593.30         0.00                     0   \n",
            "1          -4.0        542.40        38.33                    10   \n",
            "2          73.9        280.85         0.00                     0   \n",
            "3          98.0       1237.85         0.00                     0   \n",
            "4          83.9        267.40         0.00                     0   \n",
            "\n",
            "  TotalLongDistanceCharges  TotalRevenue    Churn    ChurnCategory  \\\n",
            "0                   381.51        974.81   Stayed              NaN   \n",
            "1                    96.21        610.28   Stayed              NaN   \n",
            "2                   134.60        415.45  Churned       Competitor   \n",
            "3                   361.66       1599.51  Churned  Dissatisfaction   \n",
            "4                    22.14        289.54  Churned  Dissatisfaction   \n",
            "\n",
            "                     ChurnReason  \n",
            "0                            NaN  \n",
            "1                            NaN  \n",
            "2  Competitor had better devices  \n",
            "3        Product dissatisfaction  \n",
            "4            Network reliability  \n",
            "\n",
            "[5 rows x 37 columns]\n",
            "\n",
            "üìä DATA TYPES SUMMARY:\n",
            "object     23\n",
            "int64       7\n",
            "float64     7\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing Notebook\n",
        "\n",
        "## Overview\n",
        "This notebook handles the first stage of our 4-stage cascaded architecture for churn prediction.\n",
        "\n",
        "### Main Objectives:\n",
        "- Data cleaning and preprocessing with distribution preservation\n",
        "- Comprehensive exploratory data analysis (EDA)\n",
        "- Churn distribution analysis across all features\n",
        "- Statistical significance testing\n",
        "\n",
        "### Output:\n",
        "- Preprocessed dataset saved as `churn_data_preprocessed.csv`\n",
        "- Ready for downstream analysis in other notebooks"
      ],
      "metadata": {
        "id": "bu3yL-8jqSKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "# This cell handles the first stage of our 4-stage cascaded architecture:\n",
        "# - Data cleaning and preprocessing with distribution preservation\n",
        "# - Comprehensive exploratory data analysis (EDA)\n",
        "# - Churn distribution analysis across all features\n",
        "# - Statistical significance testing\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 1: DATA PREPROCESSING FUNCTION\n",
        "# =============================================================================\n",
        "# This function performs complete preprocessing while preserving data distributions\n",
        "# Key strategy: Use MODE for categorical variables, MEDIAN for numeric variables\n",
        "# =============================================================================\n",
        "\n",
        "def preprocessing(df):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline that preserves data distributions.\n",
        "    \"\"\"\n",
        "\n",
        "    df_processed = df.copy()\n",
        "    imputation_log = []\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1. TARGET VARIABLE: Churn\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"üìù Processing target variable: Churn\")\n",
        "\n",
        "    if 'Churn' in df_processed.columns:\n",
        "        # Check if Churn is already numeric\n",
        "        if df_processed['Churn'].dtype in ['int64', 'float64']:\n",
        "            print(\"   ‚úì Churn is already numeric\")\n",
        "            df_processed['Churn'] = df_processed['Churn'].astype(int)\n",
        "        else:\n",
        "            churn_map = {'Churned': 1, 'Stayed': 0, 'Joined': 0}\n",
        "            df_processed['Churn'] = df_processed['Churn'].map(churn_map)\n",
        "            df_processed['Churn'] = df_processed['Churn'].fillna(0).astype(int)\n",
        "            print(\"   ‚úì Churn mapped from strings to numeric\")\n",
        "\n",
        "        print(f\"   Churn unique values: {sorted(df_processed['Churn'].unique())}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 2. BINARY CATEGORICAL VARIABLES - SIMPLIFIED\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\nüìù Processing binary categorical variables\")\n",
        "\n",
        "    binary_columns = [\n",
        "        'Married', 'PhoneService', 'MultipleLines', 'OnlineSecurity',\n",
        "        'OnlineBackup', 'DeviceProtectionPlan', 'PremiumTechSupport',\n",
        "        'StreamingTV', 'StreamingMovies', 'StreamingMusic', 'UnlimitedData',\n",
        "        'PaperlessBilling', 'InternetService'\n",
        "    ]\n",
        "\n",
        "    for col in binary_columns:\n",
        "        if col in df_processed.columns:\n",
        "            # SIMPLE: Check if contains Yes/No, then map, else fill with 0\n",
        "            if df_processed[col].isin(['Yes', 'No']).any():\n",
        "                df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0})\n",
        "                print(f\"   ‚úì {col}: Yes/No mapped to 1/0\")\n",
        "            else:\n",
        "                # If not Yes/No, it's probably already numeric or has NaN\n",
        "                print(f\"   ‚ö†Ô∏è {col}: Not a Yes/No column\")\n",
        "\n",
        "            # Convert to numeric and fill NaN with 0\n",
        "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
        "\n",
        "            if df_processed[col].isnull().any():\n",
        "                nan_count = df_processed[col].isnull().sum()\n",
        "                df_processed[col] = df_processed[col].fillna(0)\n",
        "                imputation_log.append(f\"{col}: {nan_count} filled with 0\")\n",
        "\n",
        "            df_processed[col] = df_processed[col].astype(int)\n",
        "            print(f\"   ‚úì {col}: Final values {sorted(df_processed[col].unique())}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3. MULTI-CLASS CATEGORICAL VARIABLES\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\nüìù Processing multi-class categorical variables\")\n",
        "\n",
        "    # Gender: Female=0, Male=1\n",
        "    if 'Gender' in df_processed.columns:\n",
        "        gender_map = {'Female': 0, 'Male': 1}\n",
        "        df_processed['Gender'] = df_processed['Gender'].map(gender_map)\n",
        "        df_processed['Gender'] = df_processed['Gender'].fillna(0).astype(int)\n",
        "        print(f\"   ‚úì Gender: Female=0, Male=1, values: {sorted(df_processed['Gender'].unique())}\")\n",
        "\n",
        "    # Contract: Month-to-Month=0, One Year=1, Two Year=2\n",
        "    if 'Contract' in df_processed.columns:\n",
        "        print(f\"   Contract sample values: {df_processed['Contract'].head(5).tolist()}\")\n",
        "\n",
        "        # Fill empty strings/NaN with 'Month-to-Month' (most common) instead of 0\n",
        "        df_processed['Contract'] = df_processed['Contract'].fillna('Month-to-Month')\n",
        "        df_processed['Contract'] = df_processed['Contract'].replace('', 'Month-to-Month')\n",
        "\n",
        "        contract_map = {\n",
        "            'Month-to-Month': 0,\n",
        "            'One Year': 1,\n",
        "            'Two Year': 2\n",
        "        }\n",
        "        df_processed['Contract'] = df_processed['Contract'].map(contract_map)\n",
        "\n",
        "        # Fill any remaining missing with 0 (Month-to-Month)\n",
        "        df_processed['Contract'] = df_processed['Contract'].fillna(0).astype(int)\n",
        "        print(f\"   ‚úì Contract: Mapped Month-to-Month=0, One Year=1, Two Year=2\")\n",
        "        print(f\"   Contract final values: {sorted(df_processed['Contract'].unique())}\")\n",
        "\n",
        "    # Offer: Fill NaN with 0, then map\n",
        "    if 'Offer' in df_processed.columns:\n",
        "        df_processed['Offer'] = df_processed['Offer'].fillna('No Offer')\n",
        "        offer_map = {\n",
        "            'No Offer': 0, 'None': 0,\n",
        "            'Offer A': 1, 'Offer B': 2, 'Offer C': 3,\n",
        "            'Offer D': 4, 'Offer E': 5\n",
        "        }\n",
        "        df_processed['Offer'] = df_processed['Offer'].map(offer_map)\n",
        "        df_processed['Offer'] = df_processed['Offer'].fillna(0).astype(int)\n",
        "        print(f\"   ‚úì Offer: Mapped with {df_processed['Offer'].nunique()} categories\")\n",
        "\n",
        "    # InternetType: Fill NaN with 0\n",
        "    if 'InternetType' in df_processed.columns:\n",
        "        df_processed['InternetType'] = df_processed['InternetType'].fillna('No Internet')\n",
        "        internet_map = {\n",
        "            'No Internet': 0, 'DSL': 1, 'Cable': 2, 'Fiber Optic': 3\n",
        "        }\n",
        "        df_processed['InternetType'] = df_processed['InternetType'].map(internet_map)\n",
        "        df_processed['InternetType'] = df_processed['InternetType'].fillna(0).astype(int)\n",
        "        print(f\"   ‚úì InternetType: Mapped with {df_processed['InternetType'].nunique()} categories\")\n",
        "\n",
        "    # PaymentMethod\n",
        "    if 'PaymentMethod' in df_processed.columns:\n",
        "        payment_map = {\n",
        "            'Bank Withdrawal': 0,\n",
        "            'Credit Card': 1,\n",
        "            'Mailed Check': 2\n",
        "        }\n",
        "        df_processed['PaymentMethod'] = df_processed['PaymentMethod'].map(payment_map)\n",
        "        df_processed['PaymentMethod'] = df_processed['PaymentMethod'].fillna(0).astype(int)\n",
        "        print(f\"   ‚úì PaymentMethod: Mapped with {df_processed['PaymentMethod'].nunique()} categories\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 4. NUMERIC VARIABLES - SIMPLIFIED\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\nüìù Processing numeric variables\")\n",
        "\n",
        "    numeric_columns = [\n",
        "        'Age', 'NumberofDependents', 'Population', 'NumberofReferrals',\n",
        "        'TenureinMonths', 'AvgMonthlyLongDistanceCharges', 'AvgMonthlyGBDownload',\n",
        "        'MonthlyCharge', 'TotalCharges', 'TotalRefunds', 'TotalExtraDataCharges',\n",
        "        'TotalLongDistanceCharges', 'TotalRevenue'\n",
        "    ]\n",
        "\n",
        "    for col in numeric_columns:\n",
        "        if col in df_processed.columns:\n",
        "            # Convert to numeric, fill NaN with 0\n",
        "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
        "\n",
        "            if df_processed[col].isnull().any():\n",
        "                nan_count = df_processed[col].isnull().sum()\n",
        "                df_processed[col] = df_processed[col].fillna(0)\n",
        "                imputation_log.append(f\"{col}: {nan_count} filled with 0\")\n",
        "\n",
        "            print(f\"   ‚úì {col}: Processed as numeric\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 5. TEXT VARIABLES - DROP UNNECESSARY COLUMNS\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\nüìù Processing text variables\")\n",
        "\n",
        "    text_columns = ['CustomerID', 'City', 'ZipCode', 'ChurnCategory', 'ChurnReason']\n",
        "\n",
        "    for col in text_columns:\n",
        "        if col in df_processed.columns:\n",
        "            df_processed = df_processed.drop(col, axis=1)\n",
        "            print(f\"   ‚úì Dropped {col}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 6. FINAL CLEANUP\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\nüìù Final cleanup: checking for remaining missing values\")\n",
        "\n",
        "    # Fill any remaining NaN with 0\n",
        "    for col in df_processed.columns:\n",
        "        if df_processed[col].isnull().any():\n",
        "            nan_count = df_processed[col].isnull().sum()\n",
        "            df_processed[col] = df_processed[col].fillna(0)\n",
        "            imputation_log.append(f\"{col}: {nan_count} remaining filled with 0\")\n",
        "\n",
        "    # Convert float columns to int where appropriate\n",
        "    for col in df_processed.columns:\n",
        "        if df_processed[col].dtype == 'float64':\n",
        "            if df_processed[col].apply(lambda x: x.is_integer() if not pd.isna(x) else True).all():\n",
        "                df_processed[col] = df_processed[col].astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # IMPUTATION SUMMARY\n",
        "    # -------------------------------------------------------------------------\n",
        "    if imputation_log:\n",
        "        print(\"\\nüìä IMPUTATION SUMMARY:\")\n",
        "        for log_entry in imputation_log:\n",
        "            print(f\"   ‚Ä¢ {log_entry}\")\n",
        "    else:\n",
        "        print(\"\\n‚úÖ No imputation needed - dataset was clean!\")\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# =============================================================================\n",
        "# APPLY PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üîÑ STAGE 1: DATA PREPROCESSING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Apply preprocessing function\n",
        "data = preprocessing(data)\n",
        "\n",
        "# Save the preprocessed data for use in other notebooks\n",
        "data.to_csv('churn_data_preprocessed.csv', index=False)\n",
        "print(\"‚úÖ Preprocessed data saved to 'churn_data_preprocessed.csv'\")\n",
        "\n",
        "print(f\"\\n‚úÖ PREPROCESSING COMPLETE!\")\n",
        "print(f\"   Final Shape: {data.shape}\")\n",
        "print(f\"   Features: {data.shape[1]}\")\n",
        "print(f\"   Samples: {data.shape[0]}\")\n",
        "print(f\"   Overall Churn Rate: {data['Churn'].mean():.2%}\")\n",
        "print(f\"   Missing Values: {data.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2wk4JjEpUb8",
        "outputId": "50832a48-2c4d-4451-976f-f4ebf9bcddd5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üîÑ STAGE 1: DATA PREPROCESSING\n",
            "================================================================================\n",
            "üìù Processing target variable: Churn\n",
            "   ‚úì Churn mapped from strings to numeric\n",
            "   Churn unique values: [np.int64(0), np.int64(1)]\n",
            "\n",
            "üìù Processing binary categorical variables\n",
            "   ‚úì Married: Yes/No mapped to 1/0\n",
            "   ‚úì Married: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì PhoneService: Yes/No mapped to 1/0\n",
            "   ‚úì PhoneService: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì MultipleLines: Yes/No mapped to 1/0\n",
            "   ‚úì MultipleLines: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì OnlineSecurity: Yes/No mapped to 1/0\n",
            "   ‚úì OnlineSecurity: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì OnlineBackup: Yes/No mapped to 1/0\n",
            "   ‚úì OnlineBackup: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì DeviceProtectionPlan: Yes/No mapped to 1/0\n",
            "   ‚úì DeviceProtectionPlan: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì PremiumTechSupport: Yes/No mapped to 1/0\n",
            "   ‚úì PremiumTechSupport: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì StreamingTV: Yes/No mapped to 1/0\n",
            "   ‚úì StreamingTV: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì StreamingMovies: Yes/No mapped to 1/0\n",
            "   ‚úì StreamingMovies: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì StreamingMusic: Yes/No mapped to 1/0\n",
            "   ‚úì StreamingMusic: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì UnlimitedData: Yes/No mapped to 1/0\n",
            "   ‚úì UnlimitedData: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì PaperlessBilling: Yes/No mapped to 1/0\n",
            "   ‚úì PaperlessBilling: Final values [np.int64(0), np.int64(1)]\n",
            "   ‚úì InternetService: Yes/No mapped to 1/0\n",
            "   ‚úì InternetService: Final values [np.int64(0), np.int64(1)]\n",
            "\n",
            "üìù Processing multi-class categorical variables\n",
            "   ‚úì Gender: Female=0, Male=1, values: [np.int64(0), np.int64(1)]\n",
            "   Contract sample values: ['One Year', 'Month-to-Month', 'Month-to-Month', 'Month-to-Month', 'Month-to-Month']\n",
            "   ‚úì Contract: Mapped Month-to-Month=0, One Year=1, Two Year=2\n",
            "   Contract final values: [np.int64(0), np.int64(1), np.int64(2)]\n",
            "   ‚úì Offer: Mapped with 6 categories\n",
            "   ‚úì InternetType: Mapped with 4 categories\n",
            "   ‚úì PaymentMethod: Mapped with 3 categories\n",
            "\n",
            "üìù Processing numeric variables\n",
            "   ‚úì Age: Processed as numeric\n",
            "   ‚úì NumberofDependents: Processed as numeric\n",
            "   ‚úì Population: Processed as numeric\n",
            "   ‚úì NumberofReferrals: Processed as numeric\n",
            "   ‚úì TenureinMonths: Processed as numeric\n",
            "   ‚úì AvgMonthlyLongDistanceCharges: Processed as numeric\n",
            "   ‚úì AvgMonthlyGBDownload: Processed as numeric\n",
            "   ‚úì MonthlyCharge: Processed as numeric\n",
            "   ‚úì TotalCharges: Processed as numeric\n",
            "   ‚úì TotalRefunds: Processed as numeric\n",
            "   ‚úì TotalExtraDataCharges: Processed as numeric\n",
            "   ‚úì TotalLongDistanceCharges: Processed as numeric\n",
            "   ‚úì TotalRevenue: Processed as numeric\n",
            "\n",
            "üìù Processing text variables\n",
            "   ‚úì Dropped CustomerID\n",
            "   ‚úì Dropped City\n",
            "   ‚úì Dropped ZipCode\n",
            "   ‚úì Dropped ChurnCategory\n",
            "   ‚úì Dropped ChurnReason\n",
            "\n",
            "üìù Final cleanup: checking for remaining missing values\n",
            "\n",
            "üìä IMPUTATION SUMMARY:\n",
            "   ‚Ä¢ MultipleLines: 682 filled with 0\n",
            "   ‚Ä¢ OnlineSecurity: 1526 filled with 0\n",
            "   ‚Ä¢ OnlineBackup: 1526 filled with 0\n",
            "   ‚Ä¢ DeviceProtectionPlan: 1526 filled with 0\n",
            "   ‚Ä¢ PremiumTechSupport: 1526 filled with 0\n",
            "   ‚Ä¢ StreamingTV: 1526 filled with 0\n",
            "   ‚Ä¢ StreamingMovies: 1526 filled with 0\n",
            "   ‚Ä¢ StreamingMusic: 1526 filled with 0\n",
            "   ‚Ä¢ UnlimitedData: 1526 filled with 0\n",
            "   ‚Ä¢ AvgMonthlyLongDistanceCharges: 682 filled with 0\n",
            "   ‚Ä¢ AvgMonthlyGBDownload: 1526 filled with 0\n",
            "‚úÖ Preprocessed data saved to 'churn_data_preprocessed.csv'\n",
            "\n",
            "‚úÖ PREPROCESSING COMPLETE!\n",
            "   Final Shape: (7043, 32)\n",
            "   Features: 32\n",
            "   Samples: 7043\n",
            "   Overall Churn Rate: 26.54%\n",
            "   Missing Values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*All data preprocessed and ready for churn analysis and downstream model stages.*"
      ],
      "metadata": {
        "id": "PyDF3KO7qVPv"
      }
    }
  ]
}
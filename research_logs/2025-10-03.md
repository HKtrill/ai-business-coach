**🗓️ Research Log — 2025-10-03**
**Yesterday, I did:**

- Completed initial feature engineering exploration with TenureBucket
- Identified preprocessing issues (double encoding, triple scaling)
- Began investigating UsageSlope calculation methods

**Today, I did:**

- Fixed critical preprocessing pipeline (removed double encoding of categorical variables, eliminated redundant scaling)
- Engineered UsageSlope feature from raw data (TotalCharges / tenure) to capture customer spending rate
- Created UsageSlope_Alternative (deviation from expected charges: TotalCharges - MonthlyCharges × tenure)
- Added TenureBucket feature (tenure grouped into 12-month periods)
- Conducted statistical validation: Mann-Whitney U test showed UsageSlope significantly discriminates churners (p < 0.000001, Cohen's d = 0.44, 27.4% overlap)
- Performed comprehensive feature importance analysis using Mutual Information and Random Forest
- Identified 10 low-signal features to drop (gender, PhoneService, Partner, Dependents, etc.)
- Ran final model comparison: Logistic Regression vs Random Forest with top 13 engineered features
- Results: 5-10% precision improvement over baseline with minimal recall loss

- LR: 51% precision, 79% recall, 66.1% PR-AUC
- RF: 55% precision, 76% recall, 64.8% PR-AUC



**Roadblocks:**

- Initial UsageSlope calculation was incorrect (global regression instead of per-customer ratio)
- Discovered TotalCharges and MonthlyCharges were being log-transformed before UsageSlope calculation, reducing interpretability
- Feature redundancy: raw vs transformed charges, multiple UsageSlope variants
- Needed to reverse log transformation to calculate UsageSlope from true raw values

**Findings:**

- Engineered features dominate: Contract, UsageSlope_Alternative, and tenure are top 3 features by both MI and RF importance
- Churners have 21.5% higher UsageSlope ($74.43 vs $61.27 per month) - indicates they're higher spenders who may perceive poor value
- TenureBucket captures lifecycle effects: Early-tenure customers (0-12 months) have distinct churn patterns
- Feature reduction works: Dropping 10 low-signal categorical features (gender, Partner, demographics, streaming services) maintains performance while - reducing noise
- Precision-recall tradeoff: Can achieve 1.3x lift over baseline at optimal UsageSlope threshold (63.98)
- Domain-driven feature engineering outperforms raw categoricals: Math-based features (ratios, deviations, bucketing) extract more signal than one-hot encoded service flags

**Tomorrow's plan:**

- Apply advanced calculus/geometric transformations to capture non-linear relationships
- Explore rate-of-change features (spending acceleration/deceleration over tenure)
- Investigate interaction terms between engineered features
- Test polynomial features or distance metrics in feature space
- Continue systematic feature engineering to push precision higher while maintaining recall